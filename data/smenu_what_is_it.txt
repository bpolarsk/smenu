#-#ASSM#-#
Set EVENT 44951 up to 1024 (which changes Chunks allocated from 1 on ASSM to 1024)

    ALTER SYSTEM SET EVENT='44951 TRACE NAME CONTEXT FOREVER, LEVEL 1024'   scope=spfile;
#-#ASSM#-#
#-#SYSDBA#-#
sqlplus -prelim "/as sysdba"

When you log on normally (even as SYSDBA), this is what happens:

   1. A new Oracle process is started (either by the listener or by local sqlplus if using the local BEQ connection)
   2. The new process attaches to SGA shared memory segments (so it could access all the needed SGA structures)
   3. The new process allocates process and session state objects and initializes new session structures in SGA

The -prelim option stands for "preliminary connection". What it means is that sqlplus will only complete 2 of the above 3 steps of connection establishment:

   1. A new Oracle process is started (either by the listener or by local sqlplus if using the local BEQ connection)
   2. The new process attaches to SGA shared memory segments (so it could access all the needed SGA structures)

You can't query regular tables nor even V$ views, because you aren't really logged on

#-#SYSDBA#-#
#-#Partition change tracking (PCT)#-#
Oracle9i provides a component known as Partition Change Tracking (PCT) which transparently detects when changes to 
partitions occur and then determines whether the operation has made the data in the materialized view inconsistent. 
For example, a merge partition or add partition operation will not affect the materialized view and can be performed 
without causing the materialized view to be marked as stale.  Partition Change Tracking can also be used to identify 
which materialized view rows are affected by partition operations. For example, if a detail table partition is truncated 
or dropped, PCT will identify the affected rows in the materialized view and delete them.  

The procedure DBMS_MVIEW.EXPLAIN_MVIEW will advise whether a materialized view can use PCT. (shortuct  mw -xpl)
#-#Partition change tracking (PCT)#-#
#-#d_kgl_latch_count#-#
This parameters determines the number of library child latch. You may increase this parmeters if one of you child latch get hot.
A child latch get hot whenever it is significantly more used than any other.
#-#d_kgl_latch_count#-#
#-#db_file_simultaneous_writes#-#
When users are having to wait for free buffers, then either DB_FILE_ SIMULTANEOUS_WRITES needs to be increased of the
number or DBWR processes needs to be increased.

The DB_FILE_SIMULTANEOUS_WRITES initialization parameter determines the number of simultaneous writes to each
database file when written by DBWR. This parameter is also used to determine the number of reads per file in the redo read
ahead when reading redo during recover. This parameter impacts the number of simultaneous I/Os, not just the number of
simultaneous writes.

Consider increasing the DB_FILE_SIMULTANEOUS_WRITES initialization parameter in order to increase the speed at which the
DBWR writes dirty buffers which then decreases the number of times sessions needed to wait for free buffers.

The DB_WRITES initialization parameter controls the number of DBWR processes that are activated at instance startup. It is a
platform specific parameter which is used to avoid DBWR bottlenecks on operating systems which do not support asynchronous
I/O. The DBWR process is responsible for writing dirty buffers in batches from the buffer cache back to the datafiles.

DBWR bottlenecks are most likely on systems which have a high insert, update or delete rate and a large number of disk
devices. Since database writes are not serial, there can be benefit to having multiple DBWR processes, even in a single CPU
database environment.
#-#db_file_simultaneous_writes#-#
#-#buffer pool#-#
#-#buffer_pool_recycle#-#
#-#buffer_pool_keep#-#
Oracle8 introduces a new multiple buffer pool feature. The multiple buffer pool features may help any customer who is 
interested in tuning the buffer cache in Oracle Server V8. 

Using Multiple Buffer Pool Feature
================================== 
The System Global Area (SGA), Oracle's shared memory region, is made up of the database buffer cache, the redo log buffer, 
and the shared pool.  The database buffer cache holds copies of the data blocks read from datafiles.  All user processes 
connected to the instance share access to the database buffer cache. 
  
Its size is determined by the initialization parameter, DB_BLOCK_BUFFERS.  The size of each buffer is determined by the 
initialization parameter  DB_BLOCK_SIZE which can only be set on database creation. Now, the database buffer cache can be 
divided into different pools.  Because objects are accessed in different ways and with different frequency their cache 
behavior may be quite different.  Multiple buffer pools enable you to address these differences.  A "keep" buffer pool can 
be used to maintain an object in the buffer cache, and a "recycle" buffer pool can be used to prevent an object from taking
up unnecessary space in the cache.  A default cache is always maintained for objects which have not been assigned to one 
of the buffer pools.     
 
You can create multiple buffer pools by setting the initialization parameters BUFFER_POOL_KEEP and BUFFER_POOL_RECYCLE. 
The size of each buffer pool is subtracted from the total number of buffers defined for the entire buffer cache.  You set 
these new parameters  = '<the number of db_block_buffers for the pool>, <the number of db_block_lru_latches for the pool>'.
The latches are subtracted from the total number allocated to the instance, just like the buffers.  The minimum number of 
buffers that must be allocated to each buffer pool is 50 times the number of LRU latches.

For example, in the init.ora you could set:      

           -DB_BLOCK_BUFFERS = 1000     
           -DB_BLOCK_LRU_LATCHES = 6      
           -BUFFER_POOL_KEEP = '100,2'   
           -BUFFER_POOL_RECYCLE = '50,1'      

In this example the default pool would be made up of 850 buffers and have 3 latches assigned to it.  The default buffer 
pool always exists and is equivalent to the single buffer cache in Oracle7.  The buffer pool for an object is defined 
with a buffer_pool clause. This clause can be part of a Create or Alter table, cluster, and index statement.  Blocks for 
an object without an explicitly set buffer pool go into the default buffer pool.  When the pool of an object is changed 
using the Alter statement, all blocks of the altered segment that are currently in a buffer pool remain as they were 
before the Alter statement.  Newly loaded blocks and any blocks that have aged out and are reloaded will go into 
the new buffer pool.   
#-#buffer_pool_keep#-#
#-#buffer_pool_recycle#-#
#-#buffer pool#-#
#-#_latch_wait_posting#-#

Short Wait and Long Wait Latches
-------------------------------- 
There are 2 types of latches:short waitlong wait All latches are in one of these predifined categories.  Short wait latches are used where we do not expect to wait for very long.  Long wait latches are used otherwise. 

Short Wait Latches
------------------
Short wait latches are characterised by the expectation that waiters will not have to wait for any excessive duration prior to getting the latch. Because of this, waiters spin on the cpu until the latch is freed.  Once the latch is freed the process grabs the latch and performs whatever operation it was waiting to perform. When a short wait latch is freed by a process no other processes are notified; the latch is simply freed.

Long Wait Latches
-----------------
Long wait latches are expected to be held for longer periods of time, so when an attempt to get the latch is unsuccessful, the process goes to sleep for a period of time, wakes up, and retries the latch get operation, repeating this cycle until the latch get is successfully grabbed. This procedure prevents excessive cpu being used as would be the case if the procedure was to spin on a latch that is being held for a long time. When the latch is freed, all waiters are posted to tell them that the latch 
is free. Among other things this:

     a)  prevents waiters from sleeping unecessarily if the latch is free
     b)  give waiters an equal chance of grabbing the latch 

An example of a long wait latch is the library cache latch since finding matching SQL in a hash chain has the potential to be a long running activity. The parameter _latch_wait_posting changes behavior of short wait and long wait latches. 

#-#_latch_wait_posting#-#
#-#cache buffers chains#-#
#
The cache buffers chains latch is needed when the SGA is scanned for database cache buffers. Contention for this latch can be reduced by increasing the DB_BLOCK_BUFFERS init.ora parameter.

Blocks in the buffer cache are placed on linked lists (cache buffer chains) which hang off a hash table.  The hash chain that a block is placed on is based on the DBA and CLASS of the block. Each hash chain is protected by a single child latch. Processes need to get the relevant latch to allow them the scan a hash chain for a buffer so that the linked list does not change underneath them.

To find the hot block, query V$LATCH_CHILDREN for the address and join it to V$BH to identify the blocks protected by this latch (doing so will show all blocks that are affected by the hot block). You can identify the object by querying DBA_EXTENTS based on the file# and dbablk found from V$BH. Using a reverse-key index—if the hot block is on an index—will move sequential records to other blocks so they are not locked up by the hot block in the chain.

If the hot block is the index root block, a reverse-key index won't help. Setting _DB_BLOCK_HASH_BUCKETS to the prime number just larger than twice the number of buffers (DB_CACHE_SIZE/DB_BLOCK_SIZE) will usually eliminate this problem. Prior to Oracle9i, this parameter had a default that caused tremendous contention for this latch; the default is correctly set to a prime number in Oracle9i. 

Contention:	Contention for these latches can be caused by:
		- Very long buffer chains.		  
		- very very heavy access to a single block.  This would require the application to be reviewed.

To identify the heavily accessed buffer chain look at the latch stats for this latch under <View:V$Latch_Children>
and match this to <View:X$BH>.  Eg: Given ADDR from V$LATCH_CHILDREN for a heavily contended  child latch:

			select dbafil, dbablk, class, state
			   from X$BH where HLADDR='address of latch';

		One of these is 'potentially' a hot block in the database.

#-#cache buffers chains#-#
#-#CBO#-#
Some parameters affecting CBO. May be worth checking out. 

HASH_AREA_SIZE 
SORT_AREA_SIZE 
DB_FILE_MULTIBLOCK_READ_COUNT 
ALWAYS_ANTI_JOIN 
HASH_JOIN_ENABLED 
HASH_MULTIBLOCK_IIO_COUNT 
OPTIMIZER_SEARCH_LIMIT 
BITMAP_MERGE_AREA_SIZE. 

In the case of repeated index accesses to the same index, the most important parameter is optimizer_index_caching. 

ie :       alter session set optimizer_index_caching=100

#-#CBO#-#
#-#about direct read#-#
What are direct reads? 

Now for a twist. You have probably assumed that if your cache hit rate is 85%, then your cache miss rate is 15%. Not so. Oracle actually performs direct reads for certain operations. So it is possible to have an 85% cache hit rate and a 1% cache miss rate, with the remaining 14% being accounted for by direct reads. 

Direct reads are performed for parallel scans, and reads from temporary tablespaces. Blocks are read directly into private buffers in the PGA, rather than into the database buffer cache in the SGA. There are no cache hits, because blocks are not searched for in the cache before being read. And there are no subsequent cache hits, because the blocks are just discarded after use, rather than cached. However, this is no great loss. The possibility of getting enough cache hits in equivalent cached operations to actually save disk reads is almost negligible, while the possibility of losing cache hits because of the additional load on the cache is quite significant. So, direct reads actually improve the cache hit rate. They also improve block access concurrency by removing a significant load from the buffer cache latches. 

#-#about direct read#-#
#-#_kgl_latch_count#-#
It sets the number of child library cache latches. The default is the least prime number greater than or equal to cpu_count. The maximum is 67. It can safely be increased to combat library cache latch contention, as long as you stick to prime numbers. However it is only effective if the activity across the existing child library cache latches is evenly distributed as shown in V$LATCH_CHILDREN. 
adjusting _kgl_latch_count is normally effective to reduce library cache latch contention. But stick to prime numbers less than or equal to 67, and no larger than necessary. 
#-#_kgl_latch_count#-#
#-#BFILE internal seek#-#
The session waits for a positioning call within the external large object (LOB) to complete.

Wait Time: The total elapse time for the seek to complete
p1 session#
p2 waited

#-#BFILE internal seek#-#
#-#BFILE read#-#
If you are using external, file-based LOBs within Oracle you may want to check the times of these events. Long times here indicate high I/O activity where the LOB / LOB Locator lives
The session waits for a read from a external large object (LOB) to complete.

Wait Time: The total elapse time for the read to complete
p1 session#
p2 waited
#-#BFILE read#-#
#-#latch free#-#
#-#spin count#-#
Latches are ORACLE internal locking mechanisms that prevent multiple sessions from simultaneously updating the same 
item within ORACLE shared memory (SGA). If a session needs to acquire a latch that is held by another session, you 
may get a latch free wait.  The process waits for a latch that is currently busy (held by another process).

Wait Time: The wait time increases exponentially and does not include spinning on the latch (active waiting).
           The maximum wait time also depends on the number of latches that the process is holding. There is an 
           incremental wait of up to 2 seconds.

   p1 address    The address of the latch for which the process is waiting
   p2 number     The latch number that indexes in the V$LATCHNAME view.To find more information on the latch, use :
   p3 tries      A count of the number of times the process tried to get the latch (slow with spinning) 
                 and the process has to sleep


If you have quite a few latch free waits, you may have a bottleneck within the SGA. Here are a few guidelines given 
as a useful starting point: 

Use The V$LATCH table to determine which latches are contributing to the majority of SLEEPs. Each sleep translates 
to a latch free wait.  If a database sustains very high physical or logical I/O rates, contention for the cache buffer 
Iru chain and cache buffer chain latches can occur. You can reduce I/O rates by tuning SQL or increasing the size of 
the buffer cache. Increasing the values of db_block_lru_latches or _db_block_hash_buckets may help. 

        | -library cache              : Contention can occur when there is heavy parsing or SQL execution rates.
        | -library cache pin latches  : Misses on the library cache latch is usually a sign of excessive reparsing
                                        of non-sharable SQL. Try using bind variables your SQL. 

        | -redo allocation latch      : You can reduce contention for this latch by lowering log_entry_max_size. 
        | -redo copy latch            : For contention in this latch, increase log_simultaneous_copies. 

shortcut: law, lat, las, latc, latd

spin_count:
===========
If you encounter latch contention and have spare CPU capacity, try increasing the value of spin_count. If CPU resources are at full capacity, try decreasing the value of spin_count. This event occurs whenever one Oracle process is requesting a "willing to wait" latch from another process. The event only occurs if, the spin_count has been exhausted, and the waiting process goes to sleep. Latch free waits can occur for a variety of reasons including library cache issues, operating system process intervention (processes being put to sleep by the OS, Etc.), and so on.

Shortcuts : las, lat
#-#spin count#-#
#-#sys_aux$#-#
#-#iotfrspeed#-#
#-#ioseektim#-#
#-#sreadtim#-#
#-#mreadtim#-#
#-#cpuspeed#-#
#-#cpuspeednw#-#
#-#mbrc#-#
#-#maxthr#-#
#-#slavethr#-#
   * iotfrspeed - I/O transfer speed in bytes for each millisecond
   * ioseektim  - seek time + latency time + operating system overhead time, in milliseconds
   * sreadtim   - average time to read single block (random read), in milliseconds
   * mreadtim   - average time to read an mbrc block at once (sequential read), in milliseconds
   * cpuspeed   - average number of CPU cycles for each second, in millions, captured for the workload 
                  (statistics collected using 'INTERVAL' or 'START' and 'STOP' options)
   * cpuspeednw - average number of CPU cycles for each second, in millions, captured for the noworkload (statistics collected using 'NOWORKLOAD' option.
   * mbrc       - average multiblock read count for sequential read, in blocks
   * maxthr     - maximum I/O system throughput, in bytes/second
   * slavethr   - average slave I/O throughput, in bytes/second

#-#ioseektim#-#
#-#sreadtim#-#
#-#mreadtim#-#
#-#cpuspeed#-#
#-#cpuspeednw#-#
#-#mbrc#-#
#-#maxthr#-#
#-#slavethr#-#
#-#iotfrspeed#-#
#-#sys_aux$#-#
#-#latch free#-#
#-#undo segment extension#-#
Whenever the database must extend or shrink a rollback segment, this wait event occurs while the rollback segment is being manipulated. High wait times here could indicate a problem with the extent size, the value of MINEXTENTS, or possibly I/O related problems.

The undo segment is being extended or shrunk. The session must wait until the operation on the undo segment has finished.

Wait Time: 0.01 seconds

p1   segment#     The ID of the rollback segment that is being extended or shrunk

#-#undo segment extension#-#
#-#statistics#-#
Table statistics           Column statistics                          Index statistics            System statistics

* Number of rows        * Number of distinct values (NDV) in column   * Number of leaf blocks   * I/O perf and utilization
* Number of blocks      * Number of nulls in column                   * Levels                  * CPU perf and utilization
* Average row length    * Data distribution (histogram)               * Clustering factor

Check shortcut 'sta -h' to see how smenu handle statistics

BMS_STATS gathers only statistics needed for cost-based optimization; it does not gather other statistics. For example, the table statistics gathered by DBMS_STATS include the number of rows, number of blocks currently containing data, and average row length, but not the number of chained rows, average free space, or number of unused data blocks.

When statistics do not exist, the optimizer uses the default values shown in Table 3-4 and Table 3-4.
Table 3-3 Default Table Values When Statistics are Missing
Table Statistic 	Default Value Used by Optimizer

TABLE
Cardinality                  : num_of_blocks * (block_size - cache_layer) / avg_row_len
Average row length           : 100 bytes
Number of blocks
Remote cardinality           : 2000 rows
Remote average row length    : 100 bytes

INDEX:
Levels                       : 1
Leaf blocks                  : 25
Leaf blocks/key              : 1
Data blocks/key              : 1
Distinct keys                : 100
Clustering factor            : 800 (8 * number of blocks)
#-#statistics#-#
#-#Hint#-#
Hints apply only to the optimization of the statement block in which they appear. A statement block is any one of the following statements or parts of statements:

    * A simple SELECT, UPDATE, or DELETE statement.
    * A parent statement or subquery of a complex statement.
    * A part of a compound query.

The following syntax shows hints contained in both styles of comments that Oracle supports within a statement block.

{DELETE|INSERT|SELECT|UPDATE} /*+ hint [text] [hint[text]]... */

or

{DELETE|INSERT|SELECT|UPDATE} --+ hint [text] [hint[text]]...

where:

    * DELETE, INSERT, SELECT, and UPDATE are keywords that begin a statement block. 
      Comments containing hints can appear only after these keywords.
    * + causes Oracle to interpret the comment as a list of hints. The plus sign must 
        immediately follow the comment delimiter; no space is permitted.
    * hint is one of the hints discussed in this section. If the comment contains multiple hints, 
      then each hint must be separated from the others by at least one space.
    * text is other commenting text that can be interspersed with the hints.

If you specify hints incorrectly, then Oracle ignores them but does not return an error:

    * Oracle ignores hints if the comment containing them does not follow a DELETE, SELECT, or UPDATE keyword.
    * Oracle ignores hints containing syntax errors, but considers other correctly specified hints within the same comment.
    * Oracle ignores combinations of conflicting hints, but considers other hints within the same comment.

Usinng Hints Against Views:

By default, hints do not propagate inside a complex view. For example, if you specify a hint in a query that selects against 
a complex view, then that hint is not honored, because it is not pushed inside the view.

 Hints by Category :

    * Hints for Optimization Approaches and Goals
    * Hints for Access Paths
    * Hints for Query Transformations
    * Hints for Join Orders
    * Hints for Join Operations
    * Hints for Parallel Execution
    * Additional Hints

Hints for Optimization Approaches and Goals : The following hints let you choose between optimization approaches and goals:
============================================
    * ALL_ROWS
    * FIRST_ROWS(n)

Hints for Access Paths : Each hint suggest an access path for a table.
========================

    * FULL
    * CLUSTER
    * HASH
    * INDEX
    * NO_INDEX
    * INDEX_ASC
    * INDEX_COMBINE
    * INDEX_JOIN
    * INDEX_DESC
    * INDEX_FFS
    * NO_INDEX_FFS
    * INDEX_SS
    * INDEX_SS_ASC
    * INDEX_SS_DESC
    * NO_INDEX_SS

Hints for Query Transformations : Each hint suggests a SQL query transformation.
================================

    * NO_QUERY_TRANSFORMATIO
    * USE_CONCAT
    * NO_EXPAND
    * NO_REWRITE
    * EXPAND_GSET_TO_UNION
    * REWRITE
    * NOREWRITE
    * MERGE
    * NO_MERGE
    * STAR_TRANSFORMATION
    * NO_STAR_TRANSFORMATION
    * FACT
    * NO_FACT
    * UNNEST
    * NO_UNNEST

Hints for Join Orders : The following hints suggest join orders:
=====================
    * LEADING
    * ORDERED

Hints for Join Operations : Each hint here suggests a join operation for a table.
===========================

    * USE_NL
    * NO_USE_NL
    * NO_USE_NL_WITH_INDEX
    * USE_NL_WITH_INDEX
    * USE_HASH
    * NO_USE_HASH
    * USE_MERGE
    * NO_USE_MERGE
    * DRIVING_SITE
    * HASH_AJ, MERGE_AJ, and NL_AJ
    * HASH_SJ, MERGE_SJ, and NL_SJ

Additional Hints : The following are several additional hints:
================
    * APPEND
    * NOAPPEND
    * CACHE
    * NOCACHE
    * PUSH_PRED
    * NO_PUSH_PRED
    * PUSH_SUBQ
    * NO_PUSH_SUBQ
    * QB_NAME
    * CURSOR_SHARING_EXACT
    * DRIVING_SITE
    * DYNAMIC_SAMPLING
    * MODEL_MIN_ANALYSIS

Hints for Parallel Execution : instruct optimizer about how statements are parallelized or not parallelized when using parallel execution:
=============================
    * PARALLEL
    * PQ_DISTRIBUTE
    * PARALLEL_INDEX
    * NO_PARALLEL_INDEX



In the hint you must specify a table exactly the same way it appears in the statement. 
If the statement uses an alias for the table, then you must use the alias rather than 
the table name in the hint. However, the table name within the hint should not include 
the schema name, if the schema name is present in the statement.

Use of the USE_NL and USE_MERGE hints is recommended with the ORDERED hint. Oracle uses these hints when the referenced table is forced 
to be the inner table of a join; the hints are ignored if the referenced table is the outer table.

Using Hints with Views
======================

Oracle does not encourage the use of hints inside or on views (or subqueries). This is because you can define views in one context 
and use them in another. However, such hints can result in unexpected execution plans. In particular, hints inside views or on views 
are handled differently, depending on whether the view is mergeable into the top-level query.

If you decide, nonetheless, to use hints with views, the following sections describe the behavior in each case.

    A)  Hints and Mergeable Views
    B)  Hints and Nonmergeable Views

If you want to specify a hint for a table in a view or subquery, then the global hint syntax is recommended. 
The following section describes this in detail.

    C)  Global Hints

A) Hints and Mergeable Views
============================

This section describes hint behavior with mergeable views.
Optimization Approaches and Goal Hints

Optimization approach and goal hints can occur in a top-level query or inside views.

    * If there is such a hint in the top-level query, then that hint is used regardless of any such hints inside the views.
    * If there is no top-level optimizer mode hint, then mode hints in referenced views are used as long as all mode hints 
      in the views are consistent.
    * If two or more mode hints in the referenced views conflict, then all mode hints in the views are discarded and the 
      session mode is used, whether default or user-specified.


B) Hints and Nonmergeable Views
===============================

With nonmergeable views, optimization approach and goal hints inside the view are ignored; the top-level query decides the optimization mode.

Because nonmergeable views are optimized separately from the top-level query, access path and join hints inside 
the view are preserved. For the same reason, access path hints on the view in the top-level query are ignored.

However, join hints on the view in the top-level query are preserved because, in this case, a nonmergeable view is similar to a table.

C) Global Hints
===============

Table hints (hints that specify a table) normally refer to tables in the DELETE, SELECT, or UPDATE statement in which the hint occurs, not to tables inside any views referenced by the statement. When you want to specify hints for tables that appear inside views, use global hints instead of embedding the hint in the view. You can transform any table hint in this chapter into a global hint by using an extended syntax for the table name, described as follows.

Consider the following view definitions and SELECT statement:

CREATE OR REPLACE VIEW v1 AS
   SELECT *
   FROM employees
   WHERE employee_id < 150;

CREATE OR REPLACE VIEW v2 AS
   SELECT v1.employee_id employee_id, departments.department_id department_id
   FROM v1, departments
   WHERE v1.department_id = departments.department_id;

SELECT /*+ INDEX( v2.v1.employees emp_emp_id_pk ) FULL(v2.departments) */ *
   FROM v2
   WHERE department_id = 30; 

The view V1 retrieves all employees whose employee number is less than 150. The view V2 performs a join between the view V1 and the department table. The SELECT statement retrieves rows from the view V2 restricting it to the department whose number is 30.

There are two global hints in the SELECT statement. The first hint specifies an index scan for the employee table referenced in the view V1, which is referenced in the view V2. The second hint specifies a full table scan for the department table referenced in the view V2. Note the dotted syntax for the view tables.

A hint such as:

INDEX(employees emp_emp_id_pk)

in the SELECT statement is ignored because the employee table does not appear in the FROM clause of the SELECT statement.

The global hint syntax also applies to unmergeable views. Consider the following SELECT statement:

SELECT /*+ NO_MERGE(v2) INDEX(v2.v1.employees emp_emp_id_pk) FULL(v2.departments) */ *
FROM v2 WHERE department_id = 30;

It causes V2 not to be merged and specifies access path hints for the employee and department tables. These hints are pushed down into the (nonmerged) view V2.

If a global hint references a UNION or UNION ALL view, then the hint is applied to the first branch that contains the hinted table. Consider the INDEX hint in the following SELECT statement:

SELECT /*+ INDEX(v.employees emp_emp_id_pk) */ *
FROM (SELECT *
   FROM employees
   WHERE employee_id < 150
   UNION ALL
   SELECT *
   FROM employees
   WHERE employee_id > 175) v
WHERE department_id = 30;

The INDEX hint applies to the employee table in the first branch of the UNION ALL view v, not to the employee table in the second branch.

Access Path and Join Hints on Views
===================================

Access path and join hints on referenced views are ignored, unless the view contains a single table (or references an Additional Hints view with a single table). For such single-table views, an access path hint or a join hint on the view applies to the table inside the view.
Access Path and Join Hints Inside Views

Access path and join hints can appear in a view definition.

    * If the view is a subquery (that is, if it appears in the FROM clause of a SELECT statement), then all access path and join hints inside the view are preserved when the view is merged with the top-level query.
    * For views that are not subqueries, access path and join hints in the view are preserved only if the top-level query references no other tables or views (that is, if the FROM clause of the SELECT statement contains only the view).

Parallel Execution Hints on Views
=================================

PARALLEL, NOPARALLEL, PARALLEL_INDEX, and NOPARALLEL_INDEX hints on views are applied recursively to all the tables in the referenced view. Parallel execution hints in a top-level query override such hints inside a referenced view.
Parallel Execution Hints Inside Views

PARALLEL, NOPARALLEL, PARALLEL_INDEX, and NOPARALLEL_INDEX hints inside views are preserved when the view is merged with the top-level query. Parallel execution hints on the view in a top-level query override such hints inside a referenced view.
#-#Hint#-#

#-#Hint DYNAMIC_SAMPLING#-#
/*+ DYNAMIC_SAMPLING ( [ table ] integer ) */

    * table specifies the name or alias of the table on which the dynamic sampling is to be performed.
    * integer is a value from 0 to 10 indicating the degree of sampling. If the statement does not use aliases, 
      then the table name is the default alias.

The DYNAMIC_SAMPLING hint lets you control dynamic sampling to improve server performance by determining more accurate selectivity and cardinality estimates. You can set the value of DYNAMIC_SAMPLING to a value from 0 to 10. The higher the level, the more effort the compiler puts into dynamic sampling and the more broadly it is applied. Sampling defaults to cursor level unless you specify a table.

For example:

SELECT /*+ dynamic_sampling(1) */ * 
FROM ...

enables dynamic sampling if all of the following conditions are true:

    * There is more than one table in the query.
    * Some table has not been analyzed and has no indexes.
    * The optimizer determines that a relatively expensive table scan would be required for this table that has not been analyzed.

The sampling levels are as follows if the dynamic sampling level used is from a cursor hint or from the optimizer_dynamic_sampling parameter:

    * Level 0: Do not use dynamic sampling.
    * Level 1: Sample all tables that have not been analyzed if the following criteria are met: (1) there is at least 1 unanalyzed table in the query; (2) this unanalyzed table is joined to another table or appears in a subquery or non-mergeable view; (3) this unanalyzed table has no indexes; (4) this unanalyzed table has more blocks than the number of blocks that would be used for dynamic sampling of this table. The number of blocks sampled is the default number of dynamic sampling blocks (32).
    * Level 2: Apply dynamic sampling to all unanalyzed tables. The number of blocks sampled is the default number 
               of dynamic sampling blocks.
    * Level 3: Apply dynamic sampling to all tables that meet Level 2 criteria, plus all tables for which standard 
               selectivity estimation used a guess for some predicate that is a potential dynamic sampling predicate. 
               The number of blocks sampled is the default number of dynamic sampling blocks.
    * Level 4: Apply dynamic sampling to all tables that meet Level 3 criteria, plus all tables that have single-table 
               predicates that reference 2 or more columns. The number of blocks sampled is the default number of dynamic 
               sampling blocks.
    * Level 5: Apply dynamic sampling to all tables that meet the Level 4 criteria using 2 times the default number of 
               dynamic sampling blocks.
    * Level 6: Apply dynamic sampling to all tables that meet the Level 5 criteria using 4 times the default number of
               dynamic sampling blocks.
    * Level 7: Apply dynamic sampling to all tables that meet the Level 6 criteria using 8 times the default number of
               dynamic sampling blocks.
    * Level 8: Apply dynamic sampling to all tables that meet the Level 7 criteria using 32 times the default number of
               dynamic sampling blocks.
    * Level 9: Apply dynamic sampling to all tables that meet the Level 8 criteria using 128 times the default number of
               dynamic sampling blocks.
    * Level 10: Apply dynamic sampling to all tables that meet the Level 9 criteria using all blocks in the table.

The sampling levels are as follows if the dynamic sampling level used is from a table hint:

    * Level 0: Do not use dynamic sampling.
    * Level 1: The number of blocks sampled is the default number of dynamic sampling blocks (32).
    * Level 2: The number of blocks sampled is 2 times the default number of dynamic sampling blocks.
    * Level 3: The number of blocks sampled is 4 times the default number of dynamic sampling blocks.
    * Level 4: The number of blocks sampled is 8 times the default number of dynamic sampling blocks.
    * Level 5: The number of blocks sampled is 16 times the default number of dynamic sampling blocks.
    * Level 6: The number of blocks sampled is 32 times the default number of dynamic sampling blocks.
    * Level 7: The number of blocks sampled is 64 times the default number of dynamic sampling blocks.
    * Level 8: The number of blocks sampled is 128 times the default number of dynamic sampling blocks.
    * Level 9: The number of blocks sampled is 256 times the default number of dynamic sampling blocks.
    * Level 10: Read all blocks in the table.

To apply dynamic sampling to a specific table, use the following form of the hint:

SELECT /*+ dynamic_sampling(employees 1) */ * 
FROM employees WHERE ..,

If there is a table hint, dynamic sampling is used unless the table is analyzed and there are no predicates on the table. For example, the following query will not result in any dynamic sampling if employees is analyzed:

SELECT /*+ dynamic_sampling(e 1) */ count(*) 
FROM employees e;

The cardinality statistic is used, if it exists. If there is a predicate, dynamic sampling is done with a table hint and cardinality is not estimated.

To force cardinality estimation even for an analyzed table, you can use a further hint, dynamic_sampling_est_cdn, as in the following example:

SELECT /*+ dynamic_sampling(e 1) dynamic_sampling_est_cdn(t) */ count(*)
FROM employees e;

This forces cardinality estimation for employees, even if the table is analyzed. The following query does both selectivity and cardinality estimation for employees:

SELECT /*+ dynamic_sampling(e 1) dynamic_sampling_est_cdn(e) */ count(*)
FROM employees e WHERE cols > 3;

#-#Hint GATHER_PLAN_STATISTICS#-#

   select /*+ gather_plan_statistics */  ....

  Need to have grants on v$sql_plan_statistics

#-#Hint GATHER_PLAN_STATISTICS#-#
#-#Hint DYNAMIC_SAMPLING#-#
#-#Hint HASH#-#
The HASH hint instructs the optimizer to use a hash scan to access the specified table. 
This hint applies only to tables stored in a table cluster.
#-#Hint HASH#-#
#-#Hint CURSOR_SHARING_EXACT#-#
/*+ CURSOR_SHARING_EXACT */

Oracle can replace literals in SQL statements with bind variables, if it is safe to do so. 
This is controlled with the CURSOR_SHARING startup parameter. The CURSOR_SHARING_EXACT hint 
causes this behavior to be switched off. In other words, Oracle executes the SQL statement
 without any attempt to replace literals by bind variables.
#-#Hint CURSOR_SHARING_EXACT#-#
#-#Hint ORDERED_PREDICATES#-#
/*+ ORDERED_PREDICATES */

The ORDERED_PREDICATES hint forces the optimizer to preserve the order of predicate evaluation, 
except for predicates used as index keys. Use this hint in the WHERE clause of SELECT statements.

If you do not use the ORDERED_PREDICATES hint, then Oracle evaluates all predicates in the following order:

   1. Predicates without user-defined functions, type methods, or subqueries are evaluated first, 
      in the order specified in the WHERE clause.
   2. Predicates with user-defined functions and type methods that have user-computed costs are 
      evaluated next, in increasing order of their cost.
   3. Predicates with user-defined functions and type methods without user-computed costs are 
      evaluated next, in the order specified in the WHERE clause.
   4. Predicates not specified in the WHERE clause (for example, predicates transitively generated 
      by the optimizer) are evaluated next.
   5. Predicates with subqueries are evaluated last, in the order specified in the WHERE clause.

Note: Remember, you can't use the ORDERED_PREDICATES hint to preserve the order of predicate evaluation on index keys.
#-#Hint ORDERED_PREDICATES#-#
#-#Hint NO_PUSH_SUBQ#-#
/*+ NO_PUSH_SUBQ */

The NO_PUSH_SUBQ hint causes non-merged subqueries to be evaluated as the last step in the execution plan. 
If the subquery is relatively expensive or does not reduce the number of rows significantly, 
then it improves performance to evaluate the subquery last.

#-#Hint NO_PUSH_SUBQ#-#
#-#Hint NO_PX_JOIN_FILTER#-#
#-#Hint NO_QUERY_TRANSFORMATION#-#

The NO_QUERY_TRANSFORMATION hint instructs the optimizer to skip all query transformations, including but not limited 
to OR-expansion, view merging, subquery unnesting, star transformation, and materialized view rewrite. For example:

SELECT /*+ NO_QUERY_TRANSFORMATION */ employee_id, last_name
  FROM (SELECT *
        FROM employees e) v
  WHERE v.last_name = 'Smith';

#-#Hint NO_QUERY_TRANSFORMATION#-#
This hint prevents the optimizer from using parallel join bitmap filtering.
#-#Hint NO_PX_JOIN_FILTER#-#
#-#Hint PUSH_SUBQ#-#
/*+ PUSH_SUBQ */

The PUSH_SUBQ hint causes non-merged subqueries to be evaluated at the earliest possible step in the execution plan. 
Generally, subqueries that are not merged are executed as the last step in the execution plan. If the subquery is 
relatively inexpensive and reduces the number of rows significantly, then it improves performance to evaluate the subquery earlier.

This hint has no effect if the subquery is applied to a remote table or one that is joined using a merge join.
#-#Hint PUSH_SUBQ#-#
#-#Hint QB_NAME#-#
Use the QB_NAME hint to define a name for a query block. This name can then be used in a hint in the outer query 
or even in a hint in an inline view to affect query execution on the tables appearing in the named query block.

If two or more query blocks have the same name, or if the same query block is hinted twice with different names, 
then the optimizer ignores all the names and the hints referencing that query block. Query blocks that are not 
named using this hint have unique system-generated names. These names can be displayed in the plan table and 
can also be used in hints within the query block, or in query block hints. For example:

SELECT /*+ QB_NAME(qb) FULL(@qb e) */ employee_id, last_name
  FROM employees e
  WHERE last_name = 'Smith';

#-#Hint QB_NAME#-#
#-#Hint NO_PUSH_PRED#-#
The NO_PUSH_SUBQ hint instructs the optimizer to evaluate nonmerged subqueries as the last step in the execution plan. 
Doing so can improve performance if the subquery is relatively expensive or does not reduce the number of rows significantly.
#-#Hint NO_PUSH_PRED#-#
#-#Hint RESULT_CACHE#-#
The RESULT_CACHE hint instructs the database to cache the results of the current query or query fragment 
in memory and then to use the cached results in future executions of the query or query fragment. The hint 
is recognized in the top-level query, the subquery_factoring_clause, or FROM clause inline view. The cached 
results reside in the result cache memory portion of the shared pool.

A cached result is automatically invalidated whenever a database object used in its creation is successfully 
modified. This hint takes precedence over settings of the RESULT_CACHE_MODE initialization parameter.

The query is eligible for result caching only if all functions entailed in the query.for example, built-in or 
user-defined functions or virtual columns.are deterministic.

If the query is executed from OCI client and OCI client result cache is enabled, then RESULT_CACHE hint enables 
client caching for the current query.
#-#Hint RESULT_CACHE#-#
#-#Hint NO_RESULT_CACHE#-#
The optimizer caches query results in the result cache if the RESULT_CACHE_MODE initialization parameter 
is set to FORCE. In this case, the NO_RESULT_CACHE hint disables such caching for the current query.

If the query is executed from OCI client and OCI client result cache is enabled, 
then the NO_RESULT_CACHE hint disables caching for the current query.
#-#Hint NO_RESULT_CACHE#-#
#-#Hint PUSH_PRED#-#
/*+ PUSH_PRED ( table ) */

The PUSH_PRED hint forces pushing of a join predicate into the view.

SELECT /*+ PUSH_PRED(v) */ t1.x, v.y
FROM t1 
   (SELECT t2.x, t3.y 
   FROM t2, t3
   WHERE t2.x = t3.x) v 
WHERE t1.x = v.x and t1.y = 1;

#-#Hint PUSH_PRED#-#
#-#Hint UNNEST#-#
/*+ UNNEST */

The UNNEST hint instructs the optimizer to unnest and merge the body of the subquery into the body of the query block 
that contains it, allowing the optimizer to consider them together when evaluating access paths and joins.

Before a subquery is unnested, the optimizer first verifies whether the statement is valid. The statement must then 
must pass heuristic and query optimization tests. The UNNEST hint instructs the optimizer to check the subquery block 
for validity only. If the subquery block is valid, then subquery unnesting is enabled without checking the heuristics or costs.
#-#Hint UNNEST#-#
#-#Hint NOCACHE#-#
/*+ NOCACHE ( table ) */

The NOCACHE hint specifies that the blocks retrieved for the table are placed at the least recently used end 
of the LRU list in the buffer cache when a full table scan is performed. This is the normal behavior of blocks in the buffer cache.

SELECT /*+ FULL(hr_emp) NOCACHE(hr_emp) */ last_name
FROM hr.employees hr_emp;

Note: The CACHE and NOCACHE hints affect system statistics "table scans(long tables)" and "table scans(short tables)", 
as shown in the V$SYSSTAT view.
Starting with Oracle9i, Release 2 (9.2), small tables are automatically cached, according to the criteria

Table Size 	Size Criteria 	                                     Caching
=============== ===================================================  =================
Small           Number of blocks < 20 or 2% of total cached blocks,  Always cached
                whichever is larger  
Medium          Larger than a small table, but < 10% of total        Oracle decides whether to cache a table on the basis 
                cached blocks                                        of its table scan and workload history. It caches the 
                                                                     table only if a future table scan is likely to find 
                                                                     the cached blocks.
Large           > 10% of total cached blocks                         Not cached
Automatic caching of small tables is disabled for tables that are created or altered with the CACHE attribute.
#-#Hint NOCACHE#-#
#-#Hint CACHE#-#
The CACHE hint instructs the optimizer to place the blocks retrieved for the table at the most recently used end 
of the LRU list in the buffer cache when a full table scan is performed. This hint is useful for small lookup tables.

In the following example, the CACHE hint overrides the default caching specification of the table:

SELECT /*+ FULL (hr_emp) CACHE(hr_emp) */ last_name
  FROM employees hr_emp;

The CACHE and NOCACHE hints affect system statistics table scans (long tables) and table scans (short tables), 
as shown in the V$SYSSTAT data dictionary view.

#-#Hint CACHE#-#
#-#Hint NOAPPEND#-#
/*+ NOAPPEND */

The NOAPPEND hint enables conventional INSERT by disabling parallel mode for the duration of the INSERT statement. 
(Conventional INSERT is the default in serial mode, and direct-path INSERT is the default in parallel mode).
#-#Hint NOAPPEND#-#
#-#Hint APPEND#-#
/*+ APPEND */

he APPEND hint instructs the optimizer to use direct-path INSERT.

    * Conventional INSERT is the default in serial mode. In serial mode, direct path can be used only if you include the APPEND hint.
    * Direct-path INSERT is the default in parallel mode. In parallel mode, conventional insert can be used only if you specify the NOAPPEND hint.

The decision whether the INSERT will go parallel or not is independent of the APPEND hint.

In direct-path INSERT, data is appended to the end of the table, rather than using existing space 
currently allocated to the table. As a result, direct-path INSERT can be considerably faster than conventional INSERT.
#-#Hint APPEND#-#
#-#Hint NO_PARALLEL_INDEX#-#
/*+ NO_PARALLEL_INDEX ( table [index [index]...] ) */

The NO_PARALLEL_INDEX hint overrides a PARALLEL attribute setting on an index to avoid a parallel index scan operation.
#-#Hint NO_PARALLEL_INDEX#-#
#-#Hint PARALLEL_INDEX#-#

!! This hint works only on partitioned indexes !!

/*+ PARALLEL_INDEX ( table [index [, index]...] [{ , integer | , DEFAULT | , } [ , integer | , DEFAULT ]] ) */

# table is the name or alias of the table associated with the index to be scanned.
# index is the index on which an index scan is to be performed (optional).

The PARALLEL_INDEX hint specifies the desired number of concurrent servers that can be used to parallelize 
index range scans for partitioned indexes.  The hint can take two values, separated by commas after the table name. 
The first value specifies the degree of parallelism for the given table. The second value specifies how the table 
is to be split among the Oracle Real Application Clusters instances. Specifying DEFAULT or no value signifies the query 
coordinator should examine the settings of the initialization parameters to determine the default degree of parallelism.

For example:

SELECT /*+ PARALLEL_INDEX(table1, index1, 3, 2) +/

In this example, there are three parallel execution processes to be used on each of two instances.
#-#Hint PARALLEL_INDEX#-#
#-#Hint PQ_DISTRIBUTE#-#
/*+ PQ_DISTRIBUTE ( table [,] outer_distribution , inner_distribution ) */

    * table_name is the name or alias of a table to be used as the inner table of a join.
    * outer_distribution is the distribution for the outer table.
    * inner_distribution is the distribution for the inner table.

The PQ_DISTRIBUTE hint improves the performance of parallel join operations. Do this by specifying how rows of joined 
tables should be distributed among producer and consumer query servers. Using this hint overrides decisions the optimizer 
would normally make.

Use the EXPLAIN PLAN statement to identify the distribution chosen by the optimizer. The optimizer ignores 
the distribution hint, if both tables are serial.  There are six combinations for table distribution. 
Only a subset of distribution method combinations for the joined tables is valid:

           Hash, Hash        : Maps the rows of each table to consumer query servers, using a hash function on the join keys. 
                               When mapping is complete, each query server performs the join between a pair of resulting 
                               partitions. This hint is recommended when the tables are comparable in size and the join operation 
                              is implemented by hash-join or sort merge join.

           Broadcast, None   : All rows of the outer table are broadcast to each query server. The inner table rows are randomly 
                               partitioned. This hint is recommended when the outer table is very small compared to the inner 
                               table. As a general rule, use the Broadcast/None hint when inner table size * number of query 
                               servers > outer table size.

          None, Broadcast   : All rows of the inner table are broadcast to each consumer query server. The outer table rows are 
                              randomly partitioned. This hint is recommended when the inner table is very small compared to the 
                              outer table. As a general rule, use the None/Broadcast hint when inner table size * number of 
                              query servers < outer table size.

          Partition, None   : Maps the rows of the outer table, using the partitioning of the inner table. The inner table must be 
                              partitioned on the join keys. This hint is recommended when the number of partitions of the outer 
                              table is equal to or nearly equal to a multiple of the number of query servers; for example, 
                              14 partitions and 15 query servers.  Note: The optimizer ignores this hint if the inner table is not 
                              partitioned or not equijoined on the partitioning key.

          None, Partition   : Maps the rows of the inner table using the partitioning of the outer table. The outer table must be 
                              partitioned on the join keys. This hint is recommended when the number of partitions of the outer 
                              table is equal to or nearly equal to a multiple of the number of query servers; for example, 
                              14 partitions and 15 query servers.  Note: The optimizer ignores this hint if the outer table is not 
                              partitioned or not equijoined on the partitioning key.

          None, None        : Each query server performs the join operation between a pair of matching partitions, one from each table. 
                              Both tables must be equipartitioned on the join keys.

For example: Given two tables, r and s, that are joined using a hash-join, the following query contains a hint to use hash distribution:

SELECT column_list /*+ORDERED PQ_DISTRIBUTE(s HASH, HASH) USE_HASH (s)*/
FROM r,s WHERE r.c=s.c;

To broadcast the outer table r, the query is:

SELECT column list /*+ORDERED PQ_DISTRIBUTE(s BROADCAST, NONE) USE_HASH (s) */
FROM r,s WHERE r.c=s.c;
#-#Hint PQ_DISTRIBUTE#-#
#-#Hint NO_PARALLEL#-#
/*+ NO_PARALLEL ( table ) */

The NO_PARALLEL hint overrides a PARALLEL specification in the table clause. In general, hints take precedence over table clauses.

The following example illustrates the NOPARALLEL hint:

SELECT /*+ NO_PARALLEL(hr_emp) */ last_name
FROM hr.employees hr_emp;
#-#Hint NO_PARALLEL#-#
#-#Hint PARALLEL#-#
/*+ PARALLEL ( table [{ , integer | , DEFAULT) | , } [ , integer | , DEFAULT ] ] ) */

The PARALLEL hint lets you specify the desired number of concurrent servers that can be used for a parallel operation. 
The hint applies to the SELECT, INSERT, UPDATE, and DELETE portions of a statement, as well as to the table scan portion.

Note:     The number of servers that can be used is twice the value in the PARALLEL hint, if sorting or grouping 
          operations also take place.  If any parallel restrictions are violated, then the hint is ignored.

The PARALLEL hint must use the table alias, if an alias is specified in the query. The hint can then take two values, 
separated by commas after the table name. The first value specifies the degree of parallelism for the given table, 
and the second value specifies how the table is to be split among the Oracle Real Application Clusters instances. 
Specifying DEFAULT or no value signifies that the query coordinator should examine the settings of the initialization 
parameters to determine the default degree of parallelism. In the following example, the PARALLEL hint overrides the degree 
of parallelism specified in the employees table definition:

SELECT /*+ FULL(hr_emp) PARALLEL(hr_emp, 5) */ last_name
FROM hr.employees hr_emp;

In the next example, the PARALLEL hint overrides the degree of parallelism specified in the employees table definition 
and tells the optimizer to use the default degree of parallelism determined by the initialization parameters. This hint 
also specifies that the table should be split among all of the available instances, with the of parallelism on each instance.

SELECT /*+ FULL(hr_emp) PARALLEL(hr_emp, DEFAULT,DEFAULT) */ last_name
FROM hr.employees hr_emp;
#-#Hint PARALLEL#-#
#-#Hint HASH_SJ#-#
#-#Hint MERGE_SJ#-#
#-#Hint NL_SJ#-#
For a specific query, place the HASH_SJ, MERGE_SJ, or NL_SJ hint into the EXISTS subquery. HASH_SJ uses a hash semi-join, MERGE_SJ uses a sort merge semi-join, and NL_SJ uses a nested loop semi-join.

For example:

SELECT * FROM departments 
WHERE exists (SELECT /*+HASH_SJ*/ * 
  FROM employees 
  WHERE employees.department_id = departments.department_id 
        AND salary > 200000); 

This converts the subquery into a special type of join between t1 and t2 that preserves the semantics of the subquery. That is, even if there is more than one matching row in t2 for a row in t1, the row in t1 is returned only once.

A subquery is evaluated as a semi-join only with these limitations:

    * There can only be one table in the subquery.
    * The outer query block must not itself be a subquery.
    * The subquery must be correlated with an equality predicate.
    * The subquery must have no GROUP BY, CONNECT BY, or ROWNUM references.
#-#Hint HASH_SJ#-#
#-#Hint MERGE_SJ#-#
#-#Hint NL_SJ#-#
#-#Hint HASH_AJ#-#
#-#Hint MERGE_AJ#-#
#-#Hint NL_AJ#-#
or a specific query, place the MERGE_AJ, HASH_AJ, or NL_AJ hint into the NOT IN subquery. MERGE_AJ uses a sort-merge anti-join, HASH_AJ uses a hash anti-join, and NL_AJ uses a nested loop anti-join.  the SQL IN predicate can be evaluated using a join to intersect two sets. Thus, employees.department_id can be joined to departments.department_id to yield a list of employees in a set of departments.
Alternatively, the SQL predicate NOT IN can be evaluated using an anti-join to subtract two sets. Thus, employees.department_id can be anti-joined to departments.department_id to select all employees who are not in a set of departments, and you can get a list of all employees who are not in the shipping or receiving departments.
#-#Hint HASH_AJ#-#
#-#Hint MERGE_AJ#-#
#-#Hint NL_AJ#-#
#-#Hint LEADING#-#
The LEADING hint instructs the optimizer to use the specified set of tables as the prefix in the execution plan. 
This hint is more versatile than the ORDERED hint. For example:

SELECT /*+ LEADING(e j) */ *
    FROM employees e, departments d, job_history j
    WHERE e.department_id = d.department_id
      AND e.hire_date = j.start_date;

The LEADING hint is ignored if the tables specified cannot be joined first in the order specified 
because of dependencies in the join graph. If you specify two or more conflicting LEADING hints, 
then all of them are ignored. If you specify the ORDERED hint, it overrides all LEADING hints.
#-#Hint LEADING#-#
#-#Hint DRIVING_SITE#-#
/*+ DRIVING_SITE ( table ) */

Where table is the name or alias for the table at which site the execution should take place.
The DRIVING_SITE hint forces query execution to be done at a different site than that selected by Oracle. This hint can be used with either rule-based or cost-based optimization

SELECT /*+DRIVING_SITE(departments)*/ * 
FROM employees, departments@rsite 
WHERE employees.department_id = departments.department_id;

If this query is executed without the hint, then rows from departments are sent to the local site, and the join is executed there. With the hint, the rows from employees are sent to the remote site, and the query is executed there, returning the result to the local site.

This hint is useful if you are using distributed query optimization.
#-#Hint DRIVING_SITE#-#
#-#Hint USE_HASH#-#
The USE_HASH hint causes Oracle to join each specified table with another row source, using a hash join.

SELECT /*+USE_HASH(l l2) */ l.order_date, l.order_id, l2.product_id,
                            SUM(l2.unit_price*quantity)
  FROM orders l, order_items l2
 WHERE l.order_id = l2.order_id
GROUP BY l2.product_id, l.order_date, l.order_id;

Another example:

SELECT /*+use_hash(employees departments)*/ * 
FROM employees, departments 
WHERE employees.department_id = departments.department_id; 
#-#Hint USE_HASH#-#
#-#Hint USE_MERGE#-#
/*+ USE_MERGE ( table [table]... ) */

The USE_MERGE hint causes Oracle to join each specified table with another row source, using a sort-merge join.
For example:

SELECT /*+USE_MERGE(employees departments)*/ * 
FROM employees, departments 
WHERE employees.department_id = departments.department_id; 

The following query shows an inventory usage report in which the optimizer avoids a sort for the GROUP BY operation 
by using the sort merge operation specified by the USE_MERGE hint.

SELECT /*+ USE_MERGE(inv l) */inv.product_id, SUM(l.quantity)
  FROM inventories inv, order_items l
 WHERE inv.product_id = l.product_id(+)
   GROUP BY inv.product_id;

The following is a query applying the USE_MERGE hint with the FULL hint.

SELECT /*+USE_MERGE(h l) FULL(h l) */ h.customer_id, l.unit_price * l.quantity
  FROM orders h ,order_items l
 WHERE l.order_id = h.order_id;
#-#Hint USE_MERGE#-#
#-#Hint USE_NL#-#
/*+ USE_NL ( table [table]... ) */

Where table is the name or alias of a table to be used as the inner table of a nested loops join.
The USE_NL hint causes Oracle to join each specified table to another row source with a nested 
loops join, using the specified table as the inner table.

For example, consider this statement, which joins the accounts and customers tables. 
Assume that these tables are not stored together in a cluster:

SELECT accounts.balance, customers.last_name, customers.first_name
    FROM accounts, customers WHERE accounts.customer_id = customers.customer_id;

Because the default goal of the cost-based approach is best throughput, the optimizer chooses either a nested loops 
operation, a sort-merge operation, or a hash operation to join these tables, depending on which is likely to return 
all the rows selected by the query more quickly.

However, you might want to optimize the statement for best response time or the minimal elapsed time necessary 
to return the first row selected by the query, rather than best throughput. If so, then you can force the optimizer 
to choose a nested loops join by using the USE_NL hint. In this statement, the USE_NL hint explicitly chooses 
a nested loops join with the customers table as the inner table:

SELECT /*+ ORDERED USE_NL(customers) to get first row faster */          accounts.balance, customers.last_name, 
       customers.first_name FROM accounts, customers WHERE accounts.customer_id = customers.customer_id;

In many cases, a nested loops join returns the first row faster than a sort merge join. 
A nested loops join can return the first row after reading the first selected row from one table and the first 
matching row from the other and combining them, while a sort merge join cannot return the first row until after 
reading and sorting all selected rows of both tables and then combining the first rows of each sorted row source.

In the following statement where a nested loop is forced through a hint, orders is accessed through a full table scan 
and the filter condition l.order_id = h.order_id is applied to every row. For every row that meets the filter condition,
order_items is accessed through the index order_id.

SELECT /*+ USE_NL(l h) */ h.customer_id, l.unit_price * l.quantity
  FROM orders h ,order_items l WHERE l.order_id = h.order_id;

Adding an INDEX hint to the query could avoid the full table scan on orders, resulting in an execution plan similar 
to one used on larger systems, even though it might not be particularly efficient here.
#-#Hint USE_NL#-#
#-#Hint USE_NL_WITH_INDEX#-#
The USE_NL_WITH_INDEX hint instructs the optimizer to join the specified table to another row source with a nested loops 
join using the specified table as the inner table. For example:

SELECT /*+ USE_NL_WITH_INDEX(l item_product_ix) */ *
  FROM orders h, order_items l
  WHERE l.order_id = h.order_id
    AND l.order_id > 3500;

The following conditions apply:

    * If no index is specified, then the optimizer must be able to use some index with at least one join predicate as the index key.
    * If an index is specified, then the optimizer must be able to use that index with at least one join predicate as the index key.

#-#Hint USE_NL_WITH_INDEX#-#
#-#Hint STAR#-#
/*+ STAR */

The STAR hint forces a star query plan to be used, if possible. A star plan has the largest table in the query last 
in the join order and joins it with a nested loops join on a concatenated index. The STAR hint applies when there are 
at least three tables, the large table's concatenated index has at least three columns, and there are no conflicting 
access or join method hints. The optimizer also considers different permutations of the small tables.

Usually, if you analyze the tables, then the optimizer selects an efficient star plan. You can also use hints to improve 
the plan. The most precise method is to order the tables in the FROM clause in the order of the keys in the index, 
with the large table last. Then use the following hints:

/*+ ORDERED USE_NL(FACTS) INDEX(facts fact_concat) */

where facts is the table and fact_concat is the index. A more general method is to use the STAR hint.
#-#Hint STAR#-#
#-#Hint NO_SWAP_JOIN_INPUTS#-#

  select /*+ use_hash(t1) swap_join_input(t1)   */
    * from t1, t2

      force t1 the be the probe table. t1 will be the build table

#-#Hint NO_SWAP_JOIN_INPUTS#-#
#-#Hint SWAP_JOIN_INPUTS#-#

  select /*+ use_hash(t1) swap_join_input(t1)   */
    * from t1, t2

      makes t1 the build table. t2 will be the probe table

#-#Hint SWAP_JOIN_INPUTS#-#
#-#Hint ORDERED#-#
/*+ ORDERED */

The ORDERED hint causes Oracle to join tables in the order in which they appear in the FROM clause.
Oracle recommends that you use the LEADING hint, which is more versatile than the ORDERED hint.

If you omit the ORDERED hint from a SQL statement performing a join, then the optimizer chooses the order in which 
to join the tables. You might want to use the ORDERED hint to specify a join order if you know something about the number 
of rows selected from each table that the optimizer does not. Such information lets you choose an inner and outer 
table better than the optimizer could.

SELECT  /*+ORDERED */ o.order_id, c.customer_id, l.unit_price * l.quantity
  FROM customers c, order_items l, orders o
 WHERE c.cust_last_name = :b1
   AND o.customer_id = c.customer_id
   AND o.order_id = l.order_id;
#-#Hint ORDERED#-#
#-#Hint NO_FACT#-#
/*+ NO_FACT ( table ) */

The NO_FACT hint is used in the context of the star transformation to indicate to the transformation 
that the hinted table should not be considered as a fact table.
#-#Hint NO_FACT#-#
#-#Hint FACT#-#
/*+ FACT ( table ) */

The FACT hint is used in the context of the star transformation to indicate to the transformation that the hinted table should be considered as a fact table.
#-#Hint FACT#-#
#-#Hint STAR_TRANSFORMATION#-#
/*+ STAR_TRANSFORMATION */

The STAR_TRANSFORMATION hint makes the optimizer use the best plan in which the transformation has been used. Without the hint, the optimizer could make a cost-based decision to use the best plan generated without the transformation, instead of the best plan for the transformed query.

Even if the hint is given, there is no guarantee that the transformation will take place. The optimizer only generates the subqueries if it seems reasonable to do so. If no subqueries are generated, then there is no transformed query, and the best plan for the untransformed query is used, regardless of the hint.
#-#Hint STAR_TRANSFORMATION#-#
#-#Hint NO_MERGE#-#
/*+ NO_MERGE ( table ) */

The NO_MERGE hint causes Oracle not to merge mergeable views.
This hint lets the user have more influence over the way in which the view is accessed.

SELECT /*+NO_MERGE(dallas_dept)*/ e1.last_name, dallas_dept.dname 
FROM employees e1, 
  (SELECT department_id, dname 
   FROM departments 
   WHERE loc = 'DALLAS') dallas_dept 
WHERE e1.department_id = dallas_dept.department_id; 

This causes view dallas_dept not to be merged.

When the NO_MERGE hint is used without an argument, it should be placed in the view query block. 
When NO_MERGE is used with the view name as an argument, it should be placed in the surrounding query.
#-#Hint NO_MERGE#-#
#-#Hint INLINE#-#
If you want to control the optimiser, then the 'materialize' hint makes it create a temporary  table; 
the 'inline' hint makes it perform 'macro-substitution'.
#-#Hint INLINE#-#
#-#Hint MATERIALIZE#-#
The Oracle materialize hint is used to ensure that the Oracle cost-based optimizer materializes 
the temporary tables that are created inside the 'WITH' clause.
If you want to control the optimiser, then the 'materialize' hint makes it create a temporary  table; 
the 'inline' hint makes it perform 'macro-substitution'.
#-#Hint MATERIALIZE#-#
#-#Hint MERGE#-#
The MERGE hint lets you merge views in a query.

If a view's query block contains a GROUP BY clause or DISTINCT operator in the SELECT list, then the optimizer 
can merge the view into the accessing statement only if complex view merging is enabled. Complex merging can 
also be used to merge an IN subquery into the accessing statement if the subquery is uncorrelated.

For example:

SELECT /*+ MERGE(v) */ e1.last_name, e1.salary, v.avg_salary
   FROM employees e1,
   (SELECT department_id, avg(salary) avg_salary 
      FROM employees e2
      GROUP BY department_id) v 
   WHERE e1.department_id = v.department_id AND e1.salary > v.avg_salary;

When the MERGE hint is used without an argument, it should be placed in the view query block. 
When MERGE is used with the view name as an argument, it should be placed in the surrounding query.
#-#Hint MERGE#-#
#-#Hint MONITOR#-#
11g hint

The MONITOR hint forces real-time SQL monitoring for the query, even if the statement is not long running. 
This hint is valid only when the parameter CONTROL_MANAGEMENT_PACK_ACCESS is set to DIAGNOSTIC+TUNING.
#-#Hint MONITOR#-#
#-#Hint NATIVE_FULL_OUTER_JOIN#-#
The NATIVE_FULL_OUTER_JOIN hint instructs the optimizer to use native full outer join, 
which is a native execution method based on a hash join.
#-#Hint NATIVE_FULL_OUTER_JOIN#-#
#-#Hint NO_REWRITE#-#
/*+ NO_REWRITE */

The NO_REWRITE hint disables query rewrite for the query block, overriding the setting of 
the parameter QUERY_REWRITE_ENABLED. Use the NOREWRITE hint on any query block of a request.

SELECT /*+ NO_REWRITE */ sum(s.amount_sold) AS dollars
  FROM sales s, times t
  WHERE s.time_id = t.time_id
  GROUP BY t.calendar_month_desc;

#-#Hint NO_REWRITE#-#
#-#Hint NO_STAR_TRANSFORMATION#-#
The NO_STAR_TRANSFORMATION hint instructs the optimizer not to perform star query transformation.
#-#Hint NO_STAR_TRANSFORMATION#-#
#-#Hint NO_USE_HASH#-#
The NO_USE_HASH hint instructs the optimizer to exclude hash joins when joining each specified table 
to another row source using the specified table as the inner table. For example:

SELECT /*+ NO_USE_HASH(e d) */ *
  FROM employees e, departments d
  WHERE e.department_id = d.department_id;

#-#Hint NO_USE_HASH#-#
#-#Hint NO_USE_MERGE#-#
The NO_USE_MERGE hint instructs the optimizer to exclude sort-merge joins when joining each specified table 
to another row source using the specified table as the inner table. For example:

SELECT /*+ NO_USE_MERGE(e d) */ *
   FROM employees e, departments d
   WHERE e.department_id = d.department_id
   ORDER BY d.department_id;

#-#Hint NO_USE_MERGE#-#
#-#Hint NO_USE_NL#-#
The NO_USE_NL hint instructs the optimizer to exclude nested loops joins when joining each specified table 
to another row source using the specified table as the inner table. For example:

SELECT /*+ NO_USE_NL(l h) */ *
  FROM orders h, order_items l
  WHERE l.order_id = h.order_id
    AND l.order_id > 3500;

When this hint is specified, only hash join and sort-merge joins are considered for the specified tables.
However, in some cases tables can be joined only by using nested loops. In such cases, 
the optimizer ignores the hint for those tables.
#-#Hint NO_USE_NL#-#
#-#Hint OPT_PARAM#-#
The OPT_PARAM hint lets you set an initialization parameter for the duration of the current query only. 
This hint is valid only for the following parameters: 
 
         - OPTIMIZER_DYNAMIC_SAMPLING
         - OPTIMIZER_INDEX_CACHING 
         - OPTIMIZER_INDEX_COST_ADJ
         - OPTIMIZER_SECURE_VIEW_MERGING
         - STAR_TRANSFORMATION_ENABLED. 

For example, the following hint sets the parameter STAR_TRANSFORMATION_ENABLED to TRUE for the statement to which it is added:

SELECT /*+ OPT_PARAM('star_transformation_enabled' 'true') */ * FROM ... ;

Parameter values that are strings are enclosed in single quotation marks. Numeric parameter values are specified without quotation marks.
#-#Hint OPT_PARAM#-#
#-#Hint NO_UNNEST#-#
Use of the NO_UNNEST hint turns off unnesting .

select /*+ NO_UNNEST(@query) */ empno from emp 
     where empno in ( select /*+ qb_name(query) */ from dep );
#-#Hint NO_UNNEST#-#
#-#Hint REWRITE#-#
/*+ REWRITE [( view [view]... )] */

The REWRITE hint forces the cost-based optimizer to rewrite a query in terms of materialized views, 
when possible, without cost consideration. Use the REWRITE hint with or without a view list. 
If you use REWRITE with a view list and the list contains an eligible materialized view, 
then Oracle uses that view regardless of its cost.

Oracle does not consider views outside of the list. If you do not specify a view list, then Oracle searches 
for an eligible materialized view and always uses it regardless of its cost.

#-#Hint EXPAND_GSET_TO_UNION#-#
/*+ EXPAND_GSET_TO_UNION */

The EXPAND_GSET_TO_UNION hint is used for queries containing grouping sets (such as queries 
with GROUP BY GROUPING SET or GROUP BY ROLLUP). The hint forces a query to be transformed 
into a corresponding query with UNION ALL of individual groupings.

SELECT year, quarter, month, sum(sales)
FROM T
GROUP BY year, rollup(quarter, month)

is first transformed to

SELECT year, quarter, month, sum(sales)
FROM T
GROUP BY year, quarter, month UNION ALL
SELECT year, quarter, null, sum(sales)
FROM T
GROUP BY year, quarter UNION ALL
SELECT year, null, null, sum(sales)
FROM T
GROUP BY year

Then, for each branch of the UNION ALL, Oracle tries a rewrite with a materialized view. 
The rewrite may do a joinback and rollup of the materialized view. Finally, Oracle looks at 
the branches not rewritten and tries to represent them as a single query block with grouping sets. 
So for example, if only the last branch of the UNION ALL was rewritten with materialized view MV, 
Oracle replaces the first two branches with a the equivalent GROUPING SET query, as follows:

SELECT year, quarter, month, sum(sales)
FROM T
GROUP BY grouping set ( (year, quarter, month), (year, quarter) ) UNION ALL
SELECT year, null, null, sum_sales
FROM MV
#-#Hint EXPAND_GSET_TO_UNION#-#
#-#Hint REWRITE#-#
#-#Hint NO_EXPAND#-#
/*+ NO_EXPAND */

The NO_EXPAND hint prevents the cost-based optimizer from considering OR-expansion for queries having OR conditions 
or IN-lists in the WHERE clause. Usually, the optimizer considers using OR expansion and uses this method 
if it decides that the cost is lower than not using it.

For example:

SELECT /*+NO_EXPAND*/ * 
FROM employees 
WHERE employee_id = 50 OR employee_id = 100; 
#-#Hint NO_EXPAND#-#
#-#Hint USE_CONCAT#-#
/*+ USE_CONCAT */

The USE_CONCAT hint forces combined OR conditions in the WHERE clause of a query to be transformed into 
a compound query using the UNION ALL set operator. Generally, this transformation occurs only if the cost 
of the query using the concatenations is cheaper than the cost without them.

The USE_CONCAT hint turns off IN-list processing and OR-expands all disjunctions, including IN-lists.
For example:

SELECT /*+USE_CONCAT*/ * 
FROM employees 
WHERE employee_id > 50 OR salary < 50000; 
#-#Hint USE_CONCAT#-#
#-#Hint AND_EQUAL#-#
/*+ AND_EQUAL ( table index index [index] [index] [index] ) */

The AND_EQUAL hint explicitly chooses an execution plan that uses an access path that merges the scans 
on several single-column indexes.

    * table specifies the name or alias of the table associated with the indexes to be merged.
    * index specifies an index on which an index scan is to be performed. You must specify at least two indexes. 
      You cannot specify more than five.

#-#Hint AND_EQUAL#-#
#-#Hint NO_INDEX#-#

/*+ NO_INDEX ( table [index [index]...] ) */

The NO_INDEX hint explicitly disallows a set of indexes for the specified table.

    * If this hint specifies a single available index, then the optimizer does not consider a scan on this index.
      Other indexes not specified are still considered.
    * If this hint specifies a list of available indexes, then the optimizer does not consider a scan on any of 
      the specified indexes. Other indexes not specified in the list are still considered.
    * If this hint specifies no indexes, then the optimizer does not consider a scan on any index on the table.
      This behavior is the same as a NO_INDEX hint that specifies a list of all available indexes for the table.

The NO_INDEX hint applies to function-based, B-tree, bitmap, cluster, or domain indexes. If a NO_INDEX hint and 
an index hint (INDEX, INDEX_ASC, INDEX_DESC, INDEX_COMBINE, or INDEX_FFS) both specify the same indexes, 
then both the NO_INDEX hint and the index hint are ignored for the specified indexes and the optimizer 
considers the specified indexes.

SELECT /*+NO_INDEX(employees emp_empid)*/ employee_id 
FROM employees 
WHERE employee_id > 200; 
#-#Hint NO_INDEX#-#
#-#Hint NO_INDEX_FFS#-#
The NO_INDEX_FFS hint instructs the optimizer to exclude a fast full index scan of the specified indexes on the specified table. 
Each parameter serves the same purpose as in the "INDEX Hint". For example:

  SELECT /*+ NO_INDEX_FFS(items item_order_ix) */ 
    order_id
  FROM order_items items;

#-#Hint NO_INDEX_FFS#-#
#-#Hint NO_MONITOR#-#
The NO_MONITOR hint disables real-time SQL monitoring for the query, even if the query is long running.
#-#Hint NO_MONITOR#-#
#-#Hint NO_NATIVE_FULL_OUTER_JOIN#-#
The NO_NATIVE_FULL_OUTER_JOIN hint instructs the optimizer to exclude the native execution method when joining 
each specified table. Instead, the full outer join is executed as a union of left outer join and anti-join.
#-#Hint NO_NATIVE_FULL_OUTER_JOIN#-#
#-#Hint INDEX_FFS#-#


The INDEX_FFS hint causes a fast full index scan to be performed rather than a full table scan.
At least the leading column of an index is required in the predicate list to use an index in a query
(except Index Skip Scan (INDEX_SS): The leading column of an index is not required for an INDEX_SS to be performed).

  SELEC /*+ INDEX_FFS(a ord_order_date_ix) */ 
         a.order_date, a.promotion_id, a.order_id
  FROM 
        orders a
 WHERE 
        a.order_date = :b1;

 CBO can use a Index Fast Full Scan (INDEX_FFS) as long as the index contains all the columns that are needed 
 for the query, and at least one column in the index key has the NOT NULL constraint. The leading column of
  an index is not required for an INDEX_FFS to be performed. Note that the use of an INDEX_FFS does not necessarily 
  return the rows in sorted order. Ordering is dependent on the order that the index blocks are read and rows are 
  only guaranteed to be returned in a sorted order if an 'order by' clause is used.

#-#Hint INDEX_FFS#-#
#-#Hint INDEX_DESC#-#
/*+ INDEX_DESC ( table [index [index]...] ) */

The INDEX_DESC hint explicitly chooses an index scan for the specified table. If the statement uses an index range scan, then Oracle scans the index entries in descending order of their indexed values. In a partitioned index, the results are in descending order within each partition.

SELECT /*+ INDEX_DESC(a ord_order_date_ix) */ 
       a.order_date, a.promotion_id, a.order_id
  FROM orders a
 WHERE a.order_date = :b1;
#-#Hint INDEX_DESC#-#
#-#Hint INDEX_JOIN#-#
  /*+ INDEX_JOIN  ( table [index [index ...]] ) */

The INDEX_JOIN hint explicitly instructs the optimizer to use an index join as an access path. 
For the hint to have a positive effect, a sufficiently small number of indexes must exist that contain 
all the columns required to resolve the query.  Each parameter serves the same purpose as in "INDEX Hint". 

For example, the following query uses an index join to access the employee_id and department_id columns, both of which are indexed in the employees table.

SELECT /*+index_join(employees emp_emp_id_pk emp_department_ix)*/ 
    employee_id, department_id 
    FROM employees 
    WHERE department_id > 50;

#-#Hint INDEX_JOIN#-#
#-#Hint INDEX_SS#-#
The INDEX_SS hint instructs the optimizer to perform an index skip scan for the specified table. 
If the statement uses an index range scan, then Oracle scans the index entries in ascending order 
of their indexed values. In a partitioned index, the results are in ascending order within each partition.

Each parameter serves the same purpose as in "INDEX Hint". For example:

SELECT /*+ INDEX_SS(e emp_name_ix) */ last_name
  FROM employees e
  WHERE first_name = 'Steven';

#-#Hint INDEX_SS#-#
#-#Hint INDEX_SS_ASC#-#
The INDEX_SS_ASC hint instructs the optimizer to perform an index skip scan for the specified table. 
If the statement uses an index range scan, then Oracle Database scans the index entries in ascending 
order of their indexed values. In a partitioned index, the results are in ascending order within each 
partition. Each parameter serves the same purpose as in "INDEX Hint".

The default behavior for a range scan is to scan index entries in ascending order of their indexed values, 
or in descending order for a descending index. This hint does not change the default order of the index, 
and therefore does not specify anything more than the INDEX_SS hint. However, you can use 
the INDEX_SS_ASC hint to specify ascending range scans explicitly should the default behavior change.
#-#Hint INDEX_SS_ASC#-#
#-#Hint INDEX_SS_DESC#-#
The INDEX_SS_DESC hint instructs the optimizer to perform an index skip scan for the specified table. 
If the statement uses an index range scan and the index is ascending, then Oracle scans the index entries 
in descending order of their indexed values. In a partitioned index, the results are in descending order 
within each partition. For a descending index, this hint effectively cancels out the descending order, 
resulting in a scan of the index entries in ascending order.

Each parameter serves the same purpose as in the "INDEX Hint". For example:

SELECT /*+ INDEX_SS_DESC(e emp_name_ix) */ last_name
  FROM employees e
  WHERE first_name = 'Steven';

#-#Hint INDEX_SS_DESC#-#
#-#Hint INDEX_COMBINE#-#
/*+ INDEX_COMBINE ( table [index [index]...] ) */

The INDEX_COMBINE hint explicitly chooses a bitmap access path for the table. If no indexes are given as arguments 
for the INDEX_COMBINE hint, then the optimizer uses whatever Boolean combination of bitmap indexes has 
the best cost estimate for the table. If certain indexes are given as arguments, then the optimizer tries to use 
some Boolean combination of those particular bitmap indexes.

SELECT /*+INDEX_COMBINE(employees salary_bmi hire_date_bmi)*/ * 
FROM employees
WHERE salary < 50000 AND hire_date < '01-JAN-1990';
#-#Hint INDEX_COMBINE#-#
#-#Hint INDEX_RS_ASC#-#

   make explicit demands for an ascending index range scan
  /*+ INDEX_RS_ASC ( table [index [index]...] ) */

#-#Hint INDEX_RS_ASC#-#
#-#Hint INDEX_RS_DESC#-#

  make explicit demands for an descending index range scan
  /*+ INDEX_RS_DESC ( table [index [index]...] ) */

#-#Hint INDEX_RS_DESC#-#
#-#Hint INDEX_ASC#-#

The INDEX_ASC hint explicitly chooses an index scan for the specified table. If the statement uses an index range scan, 
then Oracle scans the index entries in ascending order of their indexed values.

/*+ INDEX_ASC ( table [index [index]...] ) */

Because Oracle's default behavior for a range scan is to scan index entries in ascending order of their indexed values, 
this hint does not specify anything more than the INDEX hint. However, you might want to use the INDEX_ASC hint 
to specify ascending range scans explicitly should the default behavior change.
#-#Hint INDEX_ASC#-#
#-#Hint INDEX#-#
/*+ INDEX ( table [index [index]...] ) */

The INDEX hint explicitly chooses an index scan for the specified table. You can use the INDEX hint for domain, B-tree, bitmap, and bitmap join indexes. However, Oracle recommends using INDEX_COMBINE rather than INDEX for bitmap indexes, because it is a more versatile hint.

/*+ INDEX ( table [index [index]...] ) */

This hint can optionally specify one or more indexes:

    * If this hint specifies a single available index, then the optimizer performs a scan on this index. The optimizer 
      does not consider a full table scan or a scan on another index on the table.
    * If this hint specifies a list of available indexes, then the optimizer considers the cost of a scan on each index 
      in the list and then performs the index scan with the lowest cost. The optimizer can also choose to scan multiple 
      indexes from this list and merge the results, if such an access path has the lowest cost. The optimizer does not 
      consider a full table scan or a scan on an index not listed in the hint.
    * If this hint specifies no indexes, then the optimizer considers the cost of a scan on each available index on the
      table and then performs the index scan with the lowest cost. The optimizer can also choose to scan multiple indexes 
      and merge the results, if such an access path has the lowest cost. The optimizer does not consider a full table scan.

For example, consider this query that selects the name, height, and weight of all male patients in a hospital:

SELECT /*+ INDEX(patients sex_index) use sex_index because there are few male patients  */ name, height, weight
FROM patients WHERE sex = 'm';

The INDEX hint applies to IN-list predicates; it forces the optimizer to use the hinted index, if possible, 
for an IN-list predicate. Multicolumn IN-lists will not use an index.
#-#Hint INDEX#-#
#-#Hint CHOOSE#-#
/*+ CHOOSE */

The CHOOSE hint causes the optimizer to choose between the rule-based and cost-based approaches for a SQL statement. The optimizer bases its selection on the presence of statistics for the tables accessed by the statement. If the data dictionary has statistics for at least one of these tables, then the optimizer uses the cost-based approach and optimizes with the goal of best throughput. If the data dictionary does not have statistics for these tables, then it uses the rule-based approach.
#-#Hint CHOOSE#-#
#-#Hint ROWID#-#
The ROWID hint explicitly chooses a table scan by rowid for the specified table.

SELECT /*+ROWID(employees)*/ * 
FROM employees WHERE rowid > 'AAAAtkAABAAAFNTAAA' AND employee_id = 155; 
#-#Hint ROWID#-#
#-#Hint CLUSTER#-#
/*+ CLUSTER ( table ) */

The CLUSTER hint explicitly chooses a cluster scan to access the specified table. It applies only to clustered objects.

SELECT /*+ CLUSTER */ employees.last_name, department_id 
      FROM employees, departments WHERE department_id = 10 
             AND employees.department_id = departments.department_id;
#-#Hint CLUSTER#-#
#-#Hint FULL#-#
The FULL hint explicitly chooses a full table scan for the specified table.
where table specifies the name or alias of the table on which the full table scan is to be performed. If the statement does not use aliases, then the table name is the default alias.

For example:

SELECT /*+ FULL(e) */ employee_id, last_name
  FROM employees e WHERE last_name LIKE :b1;

Oracle performs a full table scan on the employees table to execute this statement, even if there is an index on the last_name column that is made available by the condition in the WHERE clause.

#-#Hint FULL#-#
#-#Hint ALL_ROWS#-#
/*+ ALL_ROWS */

The ALL_ROWS hint explicitly chooses the cost-based approach to optimize a statement block with a goal of best throughput (that is, minimum total resource consumption).

SELECT /*+ ALL_ROWS */ employee_id, last_name, salary, job_id
FROM employees WHERE employee_id = 7566;

The optimizer ignores this hint in DELETE and UPDATE statement blocks and in SELECT statement blocks that contain any of the following syntax:

    * Set operators (UNION, INTERSECT, MINUS, UNION ALL)
    * GROUP BY clause
    * FOR UPDATE clause
    * Aggregate functions
    * DISTINCT operator
    * ORDER BY clauses, when there is no index on the ordering columns

These statements cannot be optimized for best response time, because Oracle must retrieve all rows accessed by the statement before returning the first row. If you specify this hint in any of these statements, then the optimizer uses the cost-based approach and optimizes for best throughput.

#-#Hint ALL_ROWS#-#
#-#Hint FIRST_ROWS#-#
/*+ FIRST_ROWS [integer] */

The hints FIRST_ROWS(n) (where n is any positive integer) or FIRST_ROWS instruct Oracle to optimize an individual SQL statement for fast response. FIRST_ROWS(n) affords greater precision, because it instructs Oracle to choose the plan that returns the first n rows most efficiently. The FIRST_ROWS hint, which optimizes for the best plan to return the first single row, is retained for backward compatibility and plan stability.

SELECT /*+ FIRST_ROWS(10) */ employee_id, last_name, salary, job_id
FROM employees WHERE department_id = 20;
#-#Hint FIRST_ROWS#-#
#-#JOIN Merge#-#

  ===========
  MERGE JOIN:
  ===========

The inputs are two separate sets of row data. Output is the results of the join.  Oracle reads rows from both inputs in an
alternating fashion and merges together matching rows in order to generate output. The two inputs are sorted on join column.

Sort merge joins can perform better than hash joins if both of the following conditions exist:

    * The row sources are sorted already.
    * A sort operation does not have to be done. 

However, if a sort merge join involves choosing a slower access method (an index scan as opposed to a full table scan), 
then the benefit of using a sort merge might be lost.

Sort merge joins are useful when the join condition between two tables is an inequality condition 
(but not a nonequality) like <, <=, >, or >=. Sort merge joins perform better than nested loop joins for large data sets.

The optimizer can choose a sort merge join over a hash join for joining large amounts of data if any of the following conditions are true:

    * The join condition between two tables is not an equi-join.
    * OPTIMIZER_MODE is set to RULE.
    * HASH_JOIN_ENABLED is false.
    * Because of sorts already required by other operations, the optimizer finds it is cheaper to use a sort merge than a hash join.
    * The optimizer thinks that the cost of a hash join is higher, based on the settings of HASH_AREA_SIZE and SORT_AREA_SIZE.
To advise the optimizer to use a sort merge join, apply the USE_MERGE hint.

#-#JOIN Merge#-#
#-#JOIN OUTER#-#
 ===============
   OUTER JOIN 
 ===============

        Its a join condition used where One can query all the rows of one of the tables in the join condition 
        even though they don't satisfy the join condition.

#-#JOIN OUTER#-#
#-#JOIN EQUI-JOIN#-#
   ===============
   Equi-Join
   ===============

  join condition that retrieves rows from one or more tables in which one or more columns in one table 
  are equal to one or more columns in the second table.

#-#JOIN EQUI-JOIN#-#
#-#JOIN Hash#-#

  ===========
  HASH JOIN
  ===========

 Hash joins are used for joining large data sets. The optimizer uses the smaller of two tables or data sources 
 to build a hash table on the join key in memory. It then scans the larger table, probing the hash table to find the joined rows.

 This method is best used when the smaller table fits in available memory. The cost is then limited to a single read pass over the data for the two tables.

 However, if the hash table grows too big to fit into the memory, then the optimizer breaks it up into different partitions. 
 As the partitions exceed allocated memory, parts are written to temporary segments on disk. Larger temporary extent sizes 
 lead to improved I/O when writing the partitions to disk; the recommended temporary extent is about 1 MB. Temporary extent 
 size is specified by INITIAL and NEXT for permanent tablespaces and by UNIFORM SIZE for temporary tablespaces.

After the hash table is complete, the following processes occur:

   1. The second, larger table is scanned.
   2. It is broken up into partitions like the smaller table.
   3. The partitions are written to disk. 

 When the hash table build is complete, it is possible that an entire hash table partition is resident in memory. 
 Then, you do not need to build the corresponding partition for the second (larger) table. When that table is scanned, 
 rows that hash to the resident hash table partition can be joined and returned immediately.

Each hash table partition is then read into memory, and the following processes occur:

   1. The corresponding partition for the second table is scanned.
   2. The hash table is probed to return the joined rows. 

 This process is repeated for the rest of the partitions. The cost can increase to two read passes over the data 
 and one write pass over the data.

 If the hash table does not fit in the memory, it is possible that parts of it may need to be swapped in and out,
 depending on the rows retrieved from the second table. Performance for this scenario can be extremely poor.

The optimizer uses a hash join to join two tables if they are joined using an equijoin and if either 
of the following conditions are true:

    * A large amount of data needs to be joined.
    * A large fraction of the table needs to be joined. 


SELECT o.customer_id, l.unit_price * l.quantity
  FROM orders o ,order_items l
WHERE l.order_id = o.order_id;

 Apply the USE_HASH hint to advise the optimizer to use a hash join when joining two tables together. If you are having 
 trouble getting the optimizer to use hash joins, investigate the values for the HASH_AREA_SIZE and HASH_JOIN_ENABLED parameters.

  The optimizer can choose a sort merge join over a hash join for joining large amounts of data if any of the following conditions are true:

    * The join condition between two tables is not an equi-join. 
    * HASH_JOIN_ENABLED is false.
    * Because of sorts already required by other operations, the optimizer finds it is cheaper to use a sort merge than a hash join.
    * The optimizer thinks that the cost of a hash join is higher, based on the settings of HASH_AREA_SIZE and SORT_AREA_SIZE.

#-#JOIN Hash#-#
#-#JOIN Nested loop#-#
  =================
  NESTED LOOP JOIN
  =================
 
  The nested loop iterates over all rows of the outer table. If there are conditions in the where clause 
  of the SQL statement that apply to the outer table only, it checks whether those apply. If they do, 
  the corresponding rows (from the where condition) in the joined inner table are searched. These rows 
  from the inner table are either found using an index (if a suitable exists) or by doing a full table scan.  

#-#JOIN Nested loop#-#
#-#global stats#-#
For partitioned indexes, YES means statistics are collected for the INDEX as a whole
                         NO means statistics are estimated from statistics on underlying index partitions or subpartitions

Global statistics are gathered statistics that provide information regarding an object as a whole. Global statistics are directly gathered against each level of the object in question at the time of statistic gathering by selecting from the object itself at the desired level to represent the underlying objects.

For example, if a table is partitioned, then statistics at the table level can be gathered directly (and are called Global Statistics) or can be derived from the statistics on the underlying partitions (called Composite, Aggregate or Derived Statistics).  Even though a SubPartition has no underlying objects, the statistics gathered at SubPartition level are called Global Statistics as they are global for that level of the object. 
#-#global stats#-#
#-#clustering factor#-#
- if near the number of blocks, then the table is ordered : 
          index entries in a single leaf block tend to point to rows in same data block
- if near the number of rows, the table is randomly ordered : 
          index entries in a single leaf block are unlikely to point to rows in same data block
#-#clustering factor#-#
#-#SQL*Net more data to dblink#-#
Each time a message is sent via Net8, one or more of these wait events occur. This in itself is not a bad thing  as long as the timeouts and waits are relatively good for your network. If you are experiencing flaky, slow network connections, then check the SQL*Net.to. waits (the SQL*Net.from. waits are normal as the database constantly waits messages to come in) on the databases in question.

The server process (foreground process) is sending a message over a database link to another server process.

Wait Time: The actual time the send takes

p1   driver id    The address of the disconnect function of the driver that is currently being used.
p2   #bytes       The number of bytes sent by the server process to another server process over a database link

#-#SQL*Net more data to dblink#-#
#-#SQL*Net message to dblink#-#
#-#SQL*Net message to client#-#
The server (foreground process) is sending a message to the client.

Wait Time: The actual time the send takes
p1 driver id     The address of the disconnect function of the driver that is currently being used.
p2 #bytes        The number of bytes sent by the server process to the client
#-#SQL*Net message to client#-#
#-#SQL*Net message to dblink#-#
#-#SQL*Net more data to client#-#
The server process is sending more data/messages to the client. The previous operation to the client was also a send.

Wait Time: The actual time it took for the send to complete
p1 driver id     The address of the disconnect function of the driver that is currently being used.
p2 #bytes        The number of bytes that are being sent to the client

#-#SQL*Net more data to client#-#
#-#SQL*Net break/reset to dblink#-#
Same as SQL*Net break/reset to client, but in this case, the break/reset message is sent to another server process over a dat
abase link.

Wait Time: The actual time it takes for the break or reset message to return from the other server process

p1 driver id The address of the disconnect function of the driver that is currently being used.
p2 break If the value for this parameter equals 0, a reset was sent to the client.
#-#SQLNet break/reset to dblink#-#
#-#SQL*Net break/reset to client#-#
The server sends a break or reset message to the client. The session running on the server waits for a reply from the client.

Wait Time: The actual time it takes for the break or reset message to return from the client

p1   driver    id The address of the disconnect function of the driver that is currently being used.
p2   break     If the value for this parameter equals 0, a reset was sent to the client.
               A nonzero value indicates that a break was sent to the client.

#-#SQL*Net break/reset to client#-#
#-#ticks#-#
ticks = is the size of a network tick in seconds. 
#-#ticks#-#
#-#tkprof#-#
SQL Trace Facility Statistics
-----------------------------
TKPROF lists the statistics for a SQL statement returned by the SQL trace facility in rows and columns.  Each row corresponds to one of three steps of SQL statement processing:

         *       PARSE         This step translates the SQL statement into an execution plan.  
                               This includes checks for proper security authorization and checks or 
                               the existence of tables, columns, and other referenced objects.

         *       EXECUTE       This step is the actual execution of the statement by Oracle.  
                               For INSERT, UPDATE, and DELETE statements, this step modifies the data.  
                               For SELECT statements, the step identifies the selected rows.

         *       FETCH         This step retrieves rows returned by a query.  Fetches are only performed for SELECT statements.

The step for which each row contains statistics is identified by the value of the call column.  The other columns of the SQL trace facility output are combined statistics for all parses, all executes, and all fetches of a statement:

         COUNT   Number of times a statement was parsed, executed, or fetched.
         CPU     Total CPU time in seconds for all parse, execute, or fetch calls for the statement.
         ELAPSED Total elapsed time in seconds for all parse, execute, or fetch calls for the statement.
         DISK    Total number of data blocks physically read from the datafiles on disk for all parse, execute, or fetch calls.
         QUERY   Total number of buffers retrieved in consistent mode for all parse, execute, or fetch calls. 
                 Buffers are usually retrieved in consistent mode for queries.
         CURRENT Total number of buffers retrieved in current mode.  
                 Buffers are often retrieved in current mode for INSERT, UPDATE, and DELETE statements.  
                 +  The sum of QUERY & CURRENT is he total number of buffers accessed.
         ROWS    Total number of rows processed by the SQL statement.  
                 This total does not include rows processed by subqueries of the SQL statement.

  -For SELECT statements, the number of rows returned appears for the fetch step.
  -For UPDATE, DELETE, and INSERT statements, the number of rows processed appears for the execute step.
#-#tkprof#-#
#-#timed os statistics#-#
TIMED_OS_STATISTICS specifies (in seconds) the interval at which Oracle collects operating system statistics when a request is made from the client 
to the server or when a request completes.

    * On dedicated servers, Oracle collects operating system statistics at user logon and after each subsequent client invocation through the OCI 
      into the Oracle server as a remote procedure call message.
    * On shared servers, Oracle collects statistics when client calls to Oracle are processed.

A value of zero specifies that operating system statistics are not gathered. To collect statistics, 
set a value meaningful for your application and site needs.
#-#timed os statistics#-#
#-#timed_statistics#-#
Belongs to: init.ora 	Default value: FALSE            range of values: TRUE/FALSE

This parameters enable to gather additional statistics. It does NOT brings significant overhead, despite many reports.

Resolution of Statistics
------------------------
Since timing statistics have a resolution of one hundredth of a second, any operation on a cursor that takes a hundredth of a second or less may not be timed accurately. Keep this in mind when interpreting statistics.  In particular, be careful when interpreting the results from simple queries that execute very quickly.
#-#timed_statistics#-#
#-#db_writer#-#
#-#db_writer_processes#-#
db_writer         : for v7
db_writer_process : for v8
Setting DB_WRITER_PROCESSES parallelises both the gathering and writing of buffers thus parallelising more of the DBWR activity. Multiple DB writers should be able to produce higher throughput that one DBWR with multiple slaves. 
#-#db_writer_processes#-#
#-#db_writer#-#
#-#sequence_cache_hash_buckets#-#
Belongs to: init.ora 	Default value: 10		range of values:  1-SEQUENCE_CACHE_ENTRIES

The number of buckets (at about 8 bytes per bucket) that speed lookup for newly requested sequences in the cache. The cache is arranged as a hash table; a process making its first request for a sequence looks for it in this table.         

This value should be prime; otherwise, the system uses the smallest prime number greater than or equal to the value you specify. Values larger than SEQUENCE_CACHE_ENTRIES are not meaningful.                 
#-#sequence_cache_hash_buckets#-#

#-#sort_area_retained_size#-#
Belongs to: init.ora 	Default value: the value of SORT_AREA_SIZE 
Range of values: from the value equivalent to one database block to the value of SORT_AREA_SIZE

This parameter specifies the maximum amount, in bytes, of Program Global Area (PGA) memory retained after a sort. This memory is released back to the PGA, not to the operating system, after the last row is fetched from the sort space.  If a sort requires more memory, a temporary segment is allocated and the sort becomes an external (disk) sort. The maximum amount of memory to use for the sort is then specified by SORT_AREA_SIZE instead of by this parameter.

Larger values permit more sorts to be performed in memory. However, multiple sort spaces of this size may be allocated. Usually, only one or two sorts occur at one time, even for complex queries. In some cases, though, additional concurrent sorts are required. Each sort occurs in its own memory area, as specified by SORT_AREA_RETAINED_SIZE.
#-#sort_area_retained_size#-#

#-#os_authent_prefix#-#
Belongs to: init.ora	 Default value: operating system-dependent (typically "OPS$")

This parameter is authenticates users attempting to connect to the server with the users' operating system account name and password. The value of this parameter is concatenated to the beginning of every user's operating system account. The prefixed username is compared with the Oracle usernames in the database when a connection request is attempted. The default value of this parameter is OPS$ for backward compatibility with previous versions. However, you might prefer to set the prefix value to "" (a null string), thereby eliminating the addition of any prefix to operating system account names.
#-#os_authent_prefix#-#

#-#optimizer_percent_parallel#-#
Belongs to: init.ora 		Default value: 0 		Range of values: 0 - 100

This parameter defines the amount of parallelism that the optimizer uses in its cost functions. The default of 0 means that the optimizer chooses the best serial plan. A value of 100 means that the optimizer uses each object's degree of parallelism in computing the cost of a full table scan operation.

You can change the value of this parameter without shutting down your Oracle instance by using the ALTER SESSION command. Low values favor indexes, and high values favor table scans.

Cost-based optimization will always be used for any query that references an object with a nonzero degree of parallelism. For such queries a RULE hint or optimizer mode or goal will be ignored. Use of a FIRST_ROWS hint or optimizer mode will override a nonzero setting of OPTIMIZER_PERCENT_PARALLEL.
#-#optimizer_percent_parallel#-#

#-#optimizer_mode#-#
Belongs to: init.ora 		Default value: CHOOSE 		Range of values: RULE/CHOOSE/FIRST_ROWS/ALL_ROWS

When set to RULE, this parameter causes rule-based optimization to be used unless hints are specified in the query. When set to CHOOSE, the optimizer uses the cost-based approach for a SQL statement if there are statistics in the dictionary for at least one table accessed in the statement. (Otherwise, the rule-based approach is used.)

You can set the goal for cost-based optimization by setting this parameter to FIRST_ROWS or ALL_ROWS. FIRST_ROWS causes the optimizer to choose execution plans that minimize response time. ALL_ROWS causes the optimizer to choose execution plans that minimize total execution time. The goal of cost-based optimization can also be set within a session by using ALTER SESSION SET 

	The following init.ora parameters (where present) can affect the costings:

		<Parameter:ALWAYS_ANTI_JOIN>		<Parameter:B_TREE_BITMAP_PLANS>
		<Parameter:COMPLEX_VIEW_MERGING>	<Parameter:DB_FILE_MULTIBLOCK_READ_COUNT>
		<Parameter:FAST_FULL_SCAN_ENABLED>	<Parameter:HASH_AREA_SIZE>
		<Parameter:HASH_JOIN_ENABLED>		<Parameter:HASH_MULTIBLOCK_IO_COUNT>
		<Parameter:OPTIMIZER_FEATURES_ENABLE>	<Parameter:OPTIMIZER_INDEX_CACHING>
		<Parameter:OPTIMIZER_INDEX_COST_ADJ>	<Parameter:OPTIMIZER_MODE> / GOAL
		<Parameter:OPTIMIZER_PERCENT_PARALLEL>	<Parameter:OPTIMIZER_SEARCH_LIMIT>
		<Parameter:PARTITION_VIEW_ENABLED>	<Parameter:PUSH_JOIN_PREDICATE>
		<Parameter:SORT_AREA_SIZE>		<Parameter:SORT_DIRECT_WRITES>
		<Parameter:SORT_WRITE_BUFFER_SIZE>	<Parameter:STAR_TRANSFORMATION_ENABLED>
		<Parameter:V733_PLANS_ENABLED>          <Parameter:CURSOR_SHARING>


General Optimizer Notes, These are general points to be considered when looking	at optimizer issues:

	- ALL_ROWS tends to favor full table scans.
	- FIRST_ROWS tends to favor index access.
	- By default, CBO uses 'ALL_ROWS' costing.
	- CBO does not adjust costs to cater for Parallel Queries until	  Oracle 7.3.
	- CBO assumes column values are evenly distributed between the highest and lowest values until 
          Oracle 7.3 when histogram statistics CAN be stored if requested.
	- All things being equal RBO chooses the driving order by taking the tables in the FROM clause 
          RIGHT to LEFT.  CBO determines join order from costs derived from gathered statistics.  If there are 
          no stats then CBO chooses the driving order of tables from LEFT to RIGHT in the FROM clause.  
          This is OPPOSITE to the RBO.
	- CBO uses ANALYZE information in conjunction with current table high water-mark information.  
          Hence the query plan for a statement *CAN* change over time.
	- Note that TRUNCATE resets the table 'High Water Mark' but does NOT update any table statistics thus 
          leaving OLD information for CBO about the table.
	- When performing many way joins, some join combinations will be 'eliminated' to reduce the overall time spent 
          determining an execution plan.  Generally each join order is compared with the best so far and obviously 
          sub-optimal plans are eliminated.

If any table in a query has a parallel degreee greater than one (including the default degree), Oracle uses the cost-based optimizer for that query--even if OPTIMIZER_MODE = RULE, or if there is a RULE hint in the query itself.
#-#optimizer_mode#-#
#-#optimizer_secure_view_merging#-#
PTIMIZER_SECURE_VIEW_MERGING allows you to enable or disable view merging globally for the database.
Values: 

      FALSE    --> Oracle does not use view merging or predicate move-around.
      TRUE     --> Oracle assesses the query, considering all transformations, and chooses the method with the lowest cost.

To take advantage of query rewrite for a particular query, you must disable the OPTIMIZER_SECURE_VIEW_MERGING parameter.
#-#optimizer_secure_view_merging#-#

#-#log_simultaneous_copies#-#
Belongs to: init.ora 		Default value: CPU_COUNT 	Range of values: 0 - unlimited

The maximum number of redo buffer copy latches available to write log entries simultaneously. For good performance, you can have up to twice as many redo copy latches as CPUs. For a single-processor system, set to zero so that all log entries are copied on the redo allocation latch.  If this parameter is set to 0, redo copy latches are turned off, and the parameters LOG_ENTRY_PREBUILD_THRESHOLD and LOG_SMALL_ENTRY_MAX_SIZE are ignored.
If value > 1%, try decreasing the value of the init.ora parameter LOG_SMALL_ENTRY_MAX_SIZE to force more copies to use the copy latches. For multiple CPU systems, increase the number of redo copy latched by increasing the value of the init.ora parameter LOG_SIMULTANEOUS_COPIES. It may be helpful to have up to twice as many copy latches as CPUs available to the data base instance.

You can change the value of this parameter without shutting down your Oracle instance by using the ALTER SESSION command
#-#log_simultaneous_copies#-#

#-#log_entry_prebuild_threshold#-#
Belongs to: init.ora  		Default value: 0 bytes 		Range of values: 0 - unlimited

Multiple instances: can have different values
The maximum number of bytes of redo data to gather together before copying to the log buffer. A non-zero value forces user processes to prebuild redo information before requesting the redo copy latch. If the value for LOG_SIMULTANEOUS_COPIES is 0, this parameter is ignored.  For multiple-processor systems, it is sometimes beneficial to increase this parameter. Single-processor systems should keep the value at 0.

For systems experiencing latch contention that have fast processors and efficient memory-to-memory copy algorithms, increasing this value will prebuild log entries and reduce the time that the copy latch is held.  Do not increase this value for systems experiencing memory contention.
#-#log_entry_prebuild_threshold#-#

#-#log_archive_buffer_size#-#
Belongs to: init.ora 		Default value: ops system-dependent 	Range of values: 1 - operating 
											system-dependent (in O/S blocks)

Multiple instances: can have different values

The size of each archival buffer, in redo log blocks (operating system blocks). The default should be adequate for most applications.
This parameter, with LOG_ARCHIVE_BUFFERS, can tune archiving so that it runs as fast as necessary, but not so fast that it reduces system performance.
#-#log_archive_buffer_size#-#
#-#session logical reads#-#
This statistic is basically db block gets + consistent gets. 
Reading a block buffer of a table after a index seek, into the buffer will increment of one the following stats:
1) session logical read
2) consistent gets
3) no work - consistent read gets
4) buffer is not pin count
5) table fetch by row id
For more information, see "db block gets" and "consistent getsR
#-#session logical reads#-#
#-#hash_multiblock_io_count#-#
Belongs to: init.ora		Default value: 1 		Range of values: 1 - (65,536/DB_BLOCK_SIZE)

This parameter specifies how many blocks a hash join reads and writes at once to temporary space. This parameter is similar in functionality to DB_MULTIBLOCK_IO_COUNT. When operating in multi-threaded server mode, however, this parameter is ignored (that is, the default value of 1 is used even if you set the parameter to another value).

The value of DB_BLOCK_SIZE multiplied by the value of HASH_MULTIBLOCK_IO_COUNT should be less than 64 KB. 
This parameter strongly affects performance because it controls the number of partitions into which the input is divided. If you change the parameter value, make sure that the following formula remains true:

		R / M < Po2(M/C)
	where: 

		R = sizeof(left input to the join)
		M = HASH_AREA_SIZE * 0.9
		Po2(n) = largest power of 2 that is smaller than n
		C = HASH_MULTIBLOCK_IO_COUNT * DB_BLOCK_SIZE

You can change the value of this parameter without shutting down your Oracle instance by using the ALTER SESSION or ALTER SYSTEM commands.
Typically, for a DB_BLOCK_SIZE = 8129, then HASH_MULTIBLOCK_IO_COUNT --> 8. After increasing this value, checks if there is no inc. in sorts to disk!
#-#hash_multiblock_io_count#-#
#-#hash_join_enable#-#
Belongs to: init.ora 		Default value: TRUE 			Range of values: TRUE/FALSE

This parameter enables or disables the hash join feature. Set this parameter to TRUE to use hash joins. Set this parameter to FALSE to disable hash joins. You can change the value of this parameter without shutting down your Oracle instance by using the ALTER SESSION command.
Performance considerations:
===========================
Hash joins are generally CPU bound, while sort-merge joins tend to be I/O bound.  This is due to the algorithm used which builds temporary hash tables in memory. Systems which are operating near CPU capacity may incur performance degradation from hash joins, particularly when a high degree of parallelism is used.

In Serial execution: 
-------------------- 
      1. The smaller table is hashed into memory. As much of it as can fit in memory (as determined by HASH_AREA_SIZE) stays in memory, the rest goes to TEMP segments.  
      2. Each row of the larger table is read. If the row corresponds to the portion of the smaller table that is in memory, then we do the join and output the row immediately (i.e. nothing goes to TEMP). If the row corresponds to the portion of the smaller table that went to TEMP, then this row also goes to TEMP.   
      3. Each row that went to TEMP is brought back to memory and the join is done.  When you apply this algorithm, it should be noted that if the rows fetched from the smaller table fits in memory (HASH_AREA_SIZE), then nothing ever goes to TEMP.   

If the join is executed in Parallel: 
------------------------------------  
Step 2 (above) is modified in the following manner: Each row of the larger table is read. If the row corresponds to the portion of the smaller table that is in memory, then we do the join but do not output the row until we read the entire table; we keep the row in memory if there is space, otherwise it goes to TEMP. If the row corresponds to the portion of the smaller table that went to TEMP, then this row also goes to TEMP. 
#-#hash_join_enable#-#

#-#hash_area_size#-#
Belongs to: init.ora		Default value:  2 times the value	Range of values: any integer as long as
						of SORT_AREA_SIZE                        there is no disk I/O on TEMP

The first step in a hash join is to determine whether the smaller table, the build input, can fit into the hash area memory of size HASH_AREA_SIZE.  This parameter specifies the maximum amount of memory, in bytes, to be used for the hash join. If this parameter is not set, its value defaults to twice the value of the SORT_AREA_SIZE parameter. You can change the value of this parameter without shutting down your Oracle instance by using the ALTER SESSION command.
#-#hash_area_size#-#

#-#db_file_multiblock_read_count#-#
Belongs to: init.ora 		Default value: operating system-dependent	 Range of values: operating system-dependent

Used for multi-block I/O, this is the maximum number of blocks read in one I/O operation during a sequential scan. The default is a function of DB_BLOCK_BUFFERS and PROCESSES. Values in the range of 4 to 16 or even 32 are reasonable.

The actual maximums vary by operating system; they are always less than the operating system's maximum I/O size expressed as Oracle blocks (max_IO_size/DB_BLOCK_SIZE), and can never be larger than DB_BLOCK_BUFFERS/4.
#-#db_file_multiblock_read_count#-#

#-#db_block_lru_latches#-#
Belongs to: init.ora		Default value: CPU_COUNT/2 		Range of values: 1 - the number of CPUs

A db block LRU latch manages the replacement of blocks in the buffer cache. 

However, you may set this parameter to a value equal to the desired number of LRU latch sets. The value of this parameter represents the upper bound of the number of LRU latch sets. Oracle decides whether to use this value or reduce it based on a number of internal checks. If the parameter is not set, Oracle calculates a value for the number of sets.
With 7.3.4.2 and higher it is always best to set this to number of CPUs * 2.
#-#db_block_lru_latches#-#

#-#cursor_space_for_time#-#
Belongs to: init.ora		Default value: FALSE		Range of values: TRUE/FALSE

Setting this parameter to TRUE causes the database to use more space for cursors to save time. It affects both the shared SQL area and the client's private SQL area.

Shared SQL areas are kept pinned in the shared pool when this parameter's value is TRUE. As a result, shared SQL areas are not aged out of the pool as long as there is an open cursor that references them. Because each active cursor's SQL area is present in memory, execution is faster. Because the shared SQL areas never leave memory while they are in use, however, you should set this parameter to TRUE only when the shared pool is large enough to hold all cursors simultaneously.

Setting this parameter to TRUE also retains the private SQL area allocated for each cursor between executes instead of discarding it after cursor execution. This saves cursor allocation and initialization time.
#-#cursor_space_for_time#-#

#-#close_cached_open_cursors#-#

Belongs to: init.ora		Default value: FALSE		Range of values: TRUE/FALSE

This parameter controls whether cursors opened and cached in memory by PL/SQL are automatically closed at each COMMIT. A value of FALSE signifies that cursors opened by PL/SQL are held open so that subsequent executions need not open a new cursor. If PL/SQL cursors are reused frequently, setting the parameter to FALSE can cause subsequent executions to be faster.

A value of TRUE causes open cursors to be closed at each COMMIT or ROLLBACK. The cursor can then be reopened as needed. If cursors are rarely reused, setting the parameter to TRUE frees memory used by the cursor when the cursor is no longer in use.
#-#close_cached_open_cursors#-#

#-#always_anti_join#-#

Belongs to: init.ora              Default value: none               Range of values: NESTED_LOOPS/MERGE/HASH

This parameter sets the type of antijoin that the Oracle7 Server uses. The system checks to verify that it is legal to perform an anijoin, and if it is, processes the subquery depending on the value of this parameter. When set to the value NESTED_LOOPS, the Oracle7 Server evaluates the subqueries in the same way as in release 7.2. When set to the value MERGE, the Oracle7 Server uses the sort merge antijoin algorithm. When set to the value HASH, the Oracle7 Server uses the hash antijoin algorithm to evaluate the subquery.
#-#always_anti_join#-#

#-#Parallel Query Dequeue#-#
Parallel query dequeue waits are problematic in that the same wait event is used in both 'idle' and 'busy' situations. This article does not cover the details of parallel query so we assume parallel query dequeue waits are idle waits and ignore them in calculations. This is not a bad assumption as any query slave waiting on a message is dependent on the supplier/s of that message - the supplying process/es should either be working (using CPU) or waiting for some other wait event (Eg: IO) so the overview seen in the bstat/estat output should still give an indication of the source of any wasted time. 

Actions :

If your site makes significant use of parallel query for the periods being looked at then it is best to tune the queries independently.
#-#Parallel Query Dequeue#-#
#-#enqueue#-#


The session is waiting for a local enqueue. The wait is dependent on the name of the enqueue

Wait Time: Depends on the enqueue name

p1   name   The name or "type" of the enqueue or global lock can be determined by looking at the two high order bytes of P1
            select chr(bitand(p1,-16777216)/16777215)|| chr(bitand(p1,16711680)/65535) "Lock" from v$session_wait
            where event = 'DFS enqueue lock acquisition';
p1   mode   select chr(bitand(p1,-16777216)/16777215)|| chr(bitand(p1, 16711680)/65535) "Lock", bitand(p1, 65535) "Mode"
            from v$session_wait where event = 'enqueue';

p2  id1
p3  id2

A wait for an enqueue is a wait for a local 'lock'. The count and average wait times for this wait-event can be misleading as "enqueue" waits re-arm every few seconds. To qualify how many waits have really occurred you need the enqueue waits statistic from the statistics section of the estat report. 
To determine which enqueues are causing the most waits system-wide use 'lcku'


Action:

The action to take depends on the lock type which is causing the most problems. It is beyond the scope of this article to look at the reasons for waits on each lock type - the most common lock waits are generally for: 

     TX      Transaction 		Lock Generally due to application or table setup issues

     TM      DML enqueue                 Generally due to application issues, particularly if foreign key constraints have not been indexed.

     ST      Space management enqueue 	Usually caused by too much space management occurring (Eg: small extent sizes, lots of sorting etc..) 
                                        The ST enqueue can be seen in a partitioned environment when a large number of partitions are created simultaneously.

     CF                                 The CF enqueue is a Control File enqueue and happens during parallel access 6to the control files.  
                                        The CF enqueue can be seen during any action that requires reading the control file, such as 
                                        redo log archiving, redo log switches and begin backup commands

     RO Enqueue . The RO enqueue is the Reuse Object enqueue and is a cross-instance enqueue related to truncate table and drop table DDL operations.

     SQ enqueue . The SQ enqueue is the Sequence Cache enqueue (a.k.a. enq: SQ . contention) is used to serialize access to Oracle sequences.

     SS enqueue . The SS enqueue is the Sort Segment enqueue (a.k.a. enq:SS . contention) and these are related to the sorting of large result sets.
 
     TC enqueue . The TC enqueue is related to the DBWR background process and occur when .alter tablespace. commands are issued.  You will also see the TC enqueue when doing parallel full-table scans where rows are accessed directly, without being loaded into the data buffer cache.
 
     TM enqueue . The TM enqueue related to Transaction Management (a.k.a. enq: TM - contention) and can be seen when tables are explicitly locked with reorganization activities that require locking of a table.
 
    TQ enqueue . The TQ enqueue is the Queue Table enqueue (a.k.a. enq: TQ - DDL contention) and happens during Data ump (export import) operations.

    TS enqueue . The TS enqueue is the temporary segment enqueue (a.k.a. enq: TS . contention) and these enqueues happen during disk sort operations.  
 
    TT enqueue . The TT enqueue (a.k.a. enq: TT . contention) is used to avoid deadlocks in parallel tablespace operations.  The TT enqueue can be seen with parallel create tablespace and parallel point in time recovery (PITR)
 
    TX runqueue . The TX enqueue is the transaction enqueue (a.k.a. enq: TX . contention) and is commonly related to buffer busy waits, in conditions where multiple transaction attempt to update the same data blocks.
 

    enq: TX - row lock contention
    enq: TX - allocate ITL entry
    enq: TX - row lock contention


    UL enqueue . The UL enqueue is a User Lock enqueue (a.k.a. enq: UL . contention) and happens when a lock is requested in dbms_lock.request.  The UL enqueue can be seen in Oracle Data Pump.
 
    US Enqueue - The US enqueue happens with Oracle automatic UNDO management was undo segments are moved online and offline.


Other reasons for this wait are : 

      - A session is waiting to obtain a lock on an object / row held by another session, enqueue waits will increase within 
         the database. 
      - A session is attempting to modify a block, but the block has either exceeded its freespace limits for additional ITL entries or the block has reached MAXTRANS. (The space reserved for transactions within a data block is too small. By default, only one transaction slot for tables, or two for indexes, is allocated when the table or index is created. The number of transaction slots is determined by the initrans clause in the create table or index statement. If additional transaction slots are required, they are created if there is free space in the block. However, if all transaction slots are in use and there is no free space in the block, a session wishing to lock a row in the block will encounter an enqueue wait, even if the row in question is not actually locked by another process. This phenomenon can occur if both pctfree and initrans are set too low.)

      - Table locks caused by unindexed foreign keys. If an unindexed foreign key is updated, the parent table is subjected to a table lock until the transaction is complete. 

This type of Wait Event may be an indication that something is either wrong with the code (should multiple sessions be serializing themselves against a common row?) or possibly the physical design (high activity on child tables with unindexed foreign keys, inadequate INITRANS or MAXTRANS values, Etc.


Actions

The appropriate action depends on the type of enqueue.

ST enqueue :
:::::::::::::

If the contended-for enqueue is the ST enqueue, then the problem is most likely to be dynamic space allocation. Oracle dynamically allocates an extent to a segment when there is no more free space available in the segment. This enqueue is only used for dictionary managed tablespaces.

To solve contention on this resource:

    * Check to see whether the temporary (that is, sort) tablespace uses TEMPFILES. If not, then switch to using TEMPFILES.
    * Switch to using locally managed tablespaces if the tablespace that contains segments that are growing dynamically is dictionary managed. 
    * If it is not possible to switch to locally managed tablespaces, then ST enqueue resource usage can be decreased by changing the next extent sizes of the growing objects to be large enough to avoid constant space allocation. To determine which segments are growing constantly, monitor the EXTENTS column of the DBA_SEGMENTS view for all SEGMENT_NAMEs.
    * Preallocate space in the segment, for example, by allocating extents using the ALTER TABLE ALLOCATE EXTENT SQL statement.

HW enqueue
::::::::::::
The HW enqueue is used to serialize the allocation of space beyond the high water mark of a segment.

    * V$SESSION_WAIT.P2 / V$LOCK.ID1 is the tablespace number.
    * V$SESSION_WAIT.P3 / V$LOCK.ID2 is the relative dba of segment header of the object for which space is being allocated.

If this is a point of contention for an object, then manual allocation of extents solves the problem.

TM enqueue
::::::::::
The most common reason for waits on TM locks tend to involve foreign key constraints where the constrained columns are not indexed. Index the foreign key columns to avoid this problem.

TX enqueue
::::::::::
These are acquired exclusive when a transaction initiates its first change and held until the transaction does a COMMIT or ROLLBACK.

    * Waits for TX in mode 6: occurs when a session is waiting for a row level lock that is already held by another session. This occurs when one user is updating or deleting a row, which another session wishes to update or delete. This type of TX enqueue wait corresponds to the wait event enq: TX - row lock contention.

      The solution is to have the first session already holding the lock perform a COMMIT or ROLLBACK.

    * Waits for TX in mode 4 can occur if the session is waiting for an ITL (interested transaction list) slot in a block. This happens when the session wants to lock a row in the block but one or more other sessions have rows locked in the same block, and there is no free ITL slot in the block. Usually, Oracle dynamically adds another ITL slot. This may not be possible if there is insufficient free space in the block to add an ITL. If so, the session waits for a slot with a TX enqueue in mode 4. This type of TX enqueue wait corresponds to the wait event enq: TX - allocate ITL entry.

      The solution is to increase the number of ITLs available, either by changing the INITRANS or MAXTRANS for the table (either by using an ALTER statement, or by re-creating the table with the higher values).
    * Waits for TX in mode 4 can also occur if a session is waiting due to potential duplicates in UNIQUE index. If two sessions try to insert the same key value the second session has to wait to see if an ORA-0001 should be raised or not. This type of TX enqueue wait corresponds to the wait event enq: TX - row lock contention.

      The solution is to have the first session already holding the lock perform a COMMIT or ROLLBACK.
    * Waits for TX in mode 4 is also possible if the session is waiting due to shared bitmap index fragment. Bitmap indexes index key values and a range of ROWIDs. Each 'entry' in a bitmap index can cover many rows in the actual table. If two sessions want to update rows covered by the same bitmap index fragment, then the second session waits for the first transaction to either COMMIT or ROLLBACK by waiting for the TX lock in mode 4. This type of TX enqueue wait corresponds to the wait event enq: TX - row lock contention.
    * Waits for TX in Mode 4 can also occur waiting for a PREPARED transaction.
    * Waits for TX in mode 4 also occur when a transaction inserting a row in an index has to wait for the end of an index block split being done by another transaction. This type of TX enqueue wait corresponds to the wait event enq: TX - index contention. 
#-#enqueue#-#


#-#db file scattered read#-#
Similar to db file sequential read, except that the session is reading multiple data blocks.

Wait Time: The wait time is the actual time it takes to do all of the I/Os
p1 file#
p2 block#
p3 blocks The number of blocks that the session is trying to read from the file# starting at block#

This wait happens when a session is waiting for a multiblock IO to complete. This typically occurs during full table scans or index fast full scans. Oracle reads up to DB_FILE_MULTIBLOCK_READ_COUNT consecutive blocks at a time and scatters them into buffers in the buffer cache. How this is done depends on the value of USE_READV. 

Actions
Ideally you do not want to repeated perform full table scans in online portions of an application when there is a faster more selective way to get at the data. In non online portions of an application table scanning is much more likely to be required so the following points may help: 

	-USE_READV can have a dramatic effect on the performance of table scans. On many platforms USE_READV=FALSE performs better than TRUE but this should be tested. 

	-DB_FILE_MULTIBLOCK_READ_COUNT should generally be made as large as possible. The value is usually capped by Oracle and so it cannot be set too high. The 'capped' value differs between platforms and versions and usually depends on the settings of DB_BLOCK_SIZE and USE_READV. 

	-The table CACHE feature can be used to help cache tables that are frequently scanned. Additionally use of multiple buffer pools and the CACHE option can help in Oracle 8. Take care with the CACHE option as this can cause the buffers in the cache to age more quickly possibly creating problems with the Average Write Queue length. 
#-#db file scattered read#-#

#-#db file sequential read#-#

The session waits while a sequential read from the database is performed. This event is also used for rebuilding the control
file, dumping datafile headers, and getting the database file headers.

Wait Time: The wait time is the actual time it takes to do the I/O
p1 file#
p2 block#
p3 blocks This is the number of blocks that the session is trying to read (should be 1)

This wait happens when a session is waiting for an IO to complete. Typically this indicates single block reads, although reads from a disk sort area may use this wait event when reading several contiguous blocks. Remember IO is a normal activity so you are really interested in unnecessary or slow IO activity. 
Actions :
Block reads are fairly inevitable so the aim should be to minimise un-necessary IO. This is best achieved by good application design and efficient execution plans. Changes to execution plans can yield orders of magnitude changes in performance. Tweaking at system level usually only achieves percentage gains. 
#-#db file sequential read#-#
#-#buffer busy waits#-#
System wide waits for "buffer busy waits"
This wait happens when a session wants to access a database block in the buffer cache but it cannot as the buffer is "busy". The two main cases where this can occur are: 

    - Another session is reading the block into the buffer 
    - Another session holds the buffer in an incompatible mode to our request 

Actions:
 As buffer busy waits are due to contention for particular blocks then you cannot take any action until you know which 
 blocks are being competed for and why. Eliminating the cause of the contention is the best option. Note that "buffer 
 busy waits" for data blocks are often due to several processes repeatedly reading the same blocks (eg: if lots of people 
 scan the same index) - the first session processes the blocks that are in the buffer cache quickly but then a block has 
 to be read from disk - the other sessions (scanning the same index) quickly 'catch up' and want the block which is 
 currently being read from disk - they wait for the buffer as someone is already reading the block in. 
 The following hints may be useful for particular types of contention - these are things that MAY reduce contention 
 for particular situations: 

        Block Type 	Possible Actions 
        ============== 	======================
	data blocks 	Eliminate HOT blocks from the application. Check for repeatedly scanned / unselective indexes. 
			Change PCTFREE and/or PCTUSED. 
			Check for 'right- hand-indexes' (indexes that get inserted into at the same point by many processes)
			Increase INITRANS. Reduce the number of rows per block.  

	segment header 	Increase of number of FREELISTs. 
			Use FREELIST GROUPs (even in single instance this can make a difference).  

	freelist blocks Add more FREELISTS. In case of Parallel Server make sure that each instance has its own 
                        FREELIST GROUP(s).  

	undo header  	Add more rollback segments.  

The session Wait until a buffer becomes available. This event happens because a buffer is either being read into 
the buffer cache by another session (and the session is waiting for that read to complete) or the buffer is the 
buffer cache, but in a incompatible mode (that is, some other session is changing the buffer).

Wait Time: Normal wait time is 1 second. If the session was waiting for a buffer during the last wait, then the next wait 
will be 3 seconds.

p1 file#
p2 block#
p3 9i : reason code  : 0   A block is being read 
                       100 We want to NEW the block but the block is currently being read by another session 
                           (most likely for undo). 

                       110 We want the CURRENT block either shared or exclusive but the Block is being read into cache 
                           by another session, so we have to wait until their read() is completed. 

                       120 We want to get the block in current mode but someone else is currently reading it into 
                           the cache. Wait for them to complete the read. This occurs during buffer lookup. 

                       130 Block is being read by another session and no other suitable block image was found 
                           e.g. CR version, so we wait until the read is completed. This may also occur after a buffer 
                           cache assumed deadlock. The kernel can't get a buffer in a certain amount of time and assumes 
                           a deadlock. Therefore it will read the CR version of the block. This should not have a negative 
                           impact on performance, and basically replaces a read from disk with a wait for another process 
                           to read it from disk, as the block needs to be read one way or another. 

                       200 We want to NEW the block but someone else has is using the current copy so we have 
                           to wait for them to finish. 

                       210 The session wants the block in SCUR or XCUR mode. If this is a buffer exchange or the session 
                           is in discrete TX mode, the session waits for the first time and the second time escalates the 
                           block as a deadlock and so does not show up as waiting very long. In this case the statistic: 
                           "exchange deadlocks" is incremented and we yield the CPU for the "buffer deadlock" wait event. 

                       230 Trying to get a buffer in CR/CRX mode , but a modification has started on the buffer that has 
                           not yet been completed. 

                       220 During buffer lookup for a CURRENT copy of a buffer we have found the buffer but someone holds 
                           it in an incompatible mode so we have to wait. 

   10g+ :         class#   from v$waitstat. It is in fact the type if block. Link this to SQL command type
                           of the HASH_VALUE to find if it is a DML or SQL
#-#buffer busy waits#-#
#-#dbms_scheduler#-#
DBMS_SCHEDULER
**************
Rights  : If you have DBA rights you can do all the scheduling. For administering job scheduling you need
          the privileges belonging to the SCHEDULER_ADMIN role. To create and run jobs in your own schedule
          you need the 'CREATE JOB' privilege.

  With DBMS_JOB you needed to set an initialization parameter to start a job coordinator background process.
  With Oracle 10g DBMS_SCHEDULER this is not needed any more.

  If you want to user resource plans and/or consumer groups you need to set a system parameter:

  ALTER SYSTEM SET RESOURCE_LIMIT = TRUE;

  Job            : A job instructs the scheduler to run a specific program at a specific time on a specific date.
  Programs       : A program contains the code (or reference to the code ) that needs to be run to accomplish a task.
                   It also contains parameters that should be passed to the program at runtime. And it's
                   an independent object that can referenced by many jobs
  Schedules      : A schedule contains a start date, an optional end date, and repeat interval with these elements;
                   an execution schedule can be calculated.
  Windows        : A window identifies a recurring block of time during which a specific resource plan should be enabled
                   to govern resource allocation for the database.
  Job groups     : A job group is a logical method of classifying jobs with similar characteristics.
  Window groups  : A window groups is a logical method of grouping windows. They simplify the management of windows
                   by allowing the members of the group to be manipulated as one object. Unlike job groups, window groups
                   don't set default characteristics for windows that belong to the group.

Using Job Scheduler
   SQL> drop table emp;
   SQL> Create table emp (eno int, esal int);
   SQL > begin
              dbms_scheduler.create_job (
                                          job_name => 'test_abc',
                                          job_type => 'PLSQL_BLOCK',
                                          job_action => 'update emp set esal=esal*10 ;',
                                          start_date => SYSDATE,
                                          repeat_interval => 'FREQ=DAILY; INTERVAL=10',
                                          comments => 'Iam tesing scheduler');
                                          end;

PL/SQL procedure successfully completed.

Verification  : To verify that job was created, the DBA | ALL | USER_SCHEDULER_JOBS view can be queried:

SQL> select job_name,enabled,run_count from user_scheduler_jobs;
JOB_NAME ENABL RUN_COUNT
------------------------------ ----- ----------
TEST_abc FALSE 0


Note : As you can see from the results, the job was indeed created, but is not enabled because the ENABLE attribute
       was not explicitly set in the CREATE_JOB procedure.

Run your job

SQL> begin
        dbms_scheduler.run_job('TEST_abc',TRUE);
end;
/
PL/SQL procedure successfully completed.
#-#dbms_scheduler#-#
#-#rdbms ipc messag#-#
Usually background process waiting for work
#-#rdbms ipc messag#-#
#-#checkpoint#-#
PURPOSE OF CHECKPOINTS
   Database blocks are temporarily stored in Database buffer cache. As blocks are read, they are stored in DB buffer cache so that if any user accesses them later, they are available in memory and need not be read from the disk. When we update any row, the buffer in DB buffer cache corresponding to the block containing that row is updated in memory. Record of the change made is kept in redo log buffer . On commit, the changes we made are written to the disk thereby making them permanent. But where are those changes written? To the datafiles containing data blocks? No !!! The changes are recorded in online redo log files by flushing the contents of redo log buffer to them.This is called write ahead logging.  If the instance crashed right now, the DB buffer cache will be wiped out but on restarting the database, Oracle will apply the changes recorded in redo log files to the datafiles.
    Why doesn't Oracle write the changes to datafiles right away when we commit the transaction? The reason is simple. If it chose to write directly to the datafiles, it will have to physically locate the data block in the datafile first and then update it which means that after committing, user has to wait until DBWR searches for the block and then writes it before he can issue next command. This will bring down the performance drastically. That is where the role of redo logs comes in. The writes to the redo logs are sequential writes - LGWR just dumps the info in redologs to log files sequentially and synchronously so that the user does not have to wait for long. Moreover, DBWR will always write in units of Oracle blocks whereas LGWR will write only the changes made. Hence,  write ahead logging also improves performance by reducing the amount of data written synchronously. When will the changes be applied to the datablocks in datafiles? The data blocks in the datafiles will be updated by the DBWR asynchronously in response to certain triggers. These triggers are called checkpoints.
  Checkpoint is a synchronization event at a specific point in time which causes some / all dirty blocks to be written to disk thereby guaranteeing that blocks dirtied prior to that point in time get written.
  Whenever dirty blocks are written to datafiles, it allows oracle
- to reuse a redo log : A redo log can't be reused until DBWR writes all the dirty blocks protected by that logfile to disk. If we attempt to reuse it before DBWR has finished its checkpoint, we get the following message in alert log : Checkpoint not complete.
- to reduce instance recovery time : As the memory available to a database instance increases, it is possible to have database buffer caches as large as several million buffers. It requires that the database checkpoint advance frequently to limit recovery time, since infrequent checkpoints and large buffer caches can exacerbate crash recovery times significantly.
- to free buffers for reads : Dirtied blocks can't be used to read new data into them until they are written to disk. Thus DBWrR writes dirty blocks from the buffer cache, to make room in the cache.
Various types of checkpoints  in Oracle :
- Full checkpoint

- Thread checkpoint

- File checkpoint
- Parallel Query checkpoint
- Object checkpoint
- Log switch checkpoint
_ Incremental checkpoint
Whenever a checkpoint is triggered :
- DBWR writes some /all dirty blocks to datafiles
- CKPT process updates the control file and datafile headers
                      FULL CHECKPOINT
- Writes block images to  the database for all dirty buffers from all instances.
- Statistics updated
  . DBWR checkpoints
  . DBWR checkpoint buffers written
  . DBWR thread checkpoint buffers written
- Caused by :
  . Alter system checkpoint [global]
  . ALter database begin backup
  . ALter database close
  . Shutdown [immediate]
- Controlfile and datafile headers are updated
  . Checkpoint_change#
                   THREAD CHECKPOINT
- Writes block images to the database for all dirty buffers from one instance
- Statistics updated
  . DBWR checkpoints
  . DBWR checkpoint buffers written
  . DBWR thread checkpoint buffers written
- Caused by :
  . Alter system checkpoint local
- Controlfile and datafile headers are updated
  . Checkpoint_change#
                   FILE CHECKPOINT
  When a tablespace is put into backup mode or take it offline, Oracle writes all the dirty blocks from the tablespace to disk before changing the state of the tablespace.
- Writes block images to the database for all dirty buffers for all files of a tablespace from all instances
- Statistics updated
  . DBWR checkpoints
  . DBWR tablespace checkpoint buffers written
  . DBWR checkpoint buffers written
- Caused by :
  . Alter tablespace xxx offline
  . Alter tablespace xxx begin backup
  . Alter tablespace xxx read only
- Controlfile and datafile headers are updated
  . Checkpoint_change#
                  PARALLEL QUERY CHECKPOINT
   Parallel query often results in direct path reads (Full tablescan or index fast full scan). This means that blocks are read straight into the session's PGA, bypassing the data cache; but that means if there are dirty buffers in the data cache, the session won't see the most recent versions of the blocks unless they are copied to disk before the query starts - so parallel queries start with a checkpoint.
- Writes block images to the database for all dirty buffers belonging to objects accessed by the query from all instances.
- Statistics updated
  . DBWR checkpoints
  . DBWR checkpoint buffers written
- Caused by :
  . Parallel Query
  . Parallel Query component of Parallel DML (PDML) or Parallel DDL (PDDL)
- Mandatory for consistency
- Controlfile and datafile headers are updated
  . Checkpoint_change#
                 OBJECT CHECKPOINT
  When an object is dropped/truncated, the session initiates an object checkpoint telling DBWR to copy any dirty buffers for that object to disk and the state of those buffers is changed to free.
- Writes block images to the database for all dirty buffers belonging to an object from all instances.
- Statistics updated
  . DBWR checkpoints
  . DBWR object drop buffers written
- Caused by dropping or truncating a segment:
  . Drop table XXX
  . Drop table XXX Purge
  . Truncate table xxx
  . Drop index xxx
- Mandatory for media recovery purposes
- Controlfile and datafile headers are updated
  . Checkpoint_change#
                LOG SWITCH CHECKPOINT
 
- Writes the contents of the  dirty buffers whose information is protected by a redo log to the database .
- Statistics updated
  . DBWR checkpoints
  . DBWR checkpoint buffers written
  . background checkpoints started
  . background checkpoints completed
- Caused by log switch
- Controlfile and datafile headers are updated
  . Checkpoint_change#
                  INCREMENTAL CHECKPOINT
  Prior to Oracle 8i, only well known checkpoint was log switch checkpoint. Whenever LGWR filled an online logfile, DBWR would go into a frenzy writing data blocks to disks, and when it had finished, Oracle would update each data file header block with the SCN to show that file was updated up to that point in time.
   Oracle 8i introduced incremental checkpointing which triggered DBWR to write some dirty blocks from time to time so as to advance the checkpoint and reduce the instance recovery time.
Incremental checkpointing has been implemented using two algorithms :
- Ageing algorithm
- LRU/TCH algorithm
                                               AGEING ALGORITHM
This strategy involves writing changed blocks that have been dirty for the longest time and  is called aging writes. This algorithm relies on the CKPT Q running thru the cache and buffers being linked to the end of this list the first time they are made dirty.
   .The LRU list contains all the buffers - free / pinned / dirty. Whenever a buffer in LRU list is dirtied, it is placed in CKPT Q as well i.e. a buffer can  simultaneously have pointers in both LRU list and CKPT Q but the buffers in CKPT Q are arranged in the order in which they were dirtied.Thus,  checkpoint queue contains dirty blocks in the order of SCN# in which they were dirtied
  Every 3 secs DBWR wakes up and checks if there are those many  dirty buffers in CKPT Q which need to br written so as to satisfy instance recovery requirement..
If those many or more dirty buffers are not found,
   DBWR goes to sleep
else (dirty buffers found)
  .CKPT target RBA is calculated based on
   - The most recent RBA
   - log_checkpoint_interval
   - log_checkpoint_timeout
   - fast_start_mttr_target
   - fast_start_io_target
   - 90% of the size of the smallest redo log file
  . DBWR walks the CKPT Q from the low end (dirtied earliest) of the redo log file collecting buffers for writing to disk until it reaches the buffer that is more recent than the target RBA. These buffers are placed in write list-main.
  . DBWR walks the write list-main and checks all the buffers
    - If changes made to the buffer have already been written to redo log files
        . Move those buffers to write-aux list
      else
        . Trigger LGWR to write changes to those buffers to redo logs
        . Move those buffers to write-aux list
  . Write buffers from write-aux list to disk
  . Update checkpoint RBA in SGA
  . Delink those buffers from CKPT Q
  . Delink those buffers from write-aux list
- Statistics Updated :
   . DBWR checkpoint buffers written
- Controlfile updated every 3 secs by CKPT
   . Checkpoint progress record
  As sessions link buffers to one end of the list, DBWR can effectively unlink buffers from the other end and copy them to disk. To reduce contention between DBWR and foreground sessions, there are two linked lists in each working set so that foreground sessions can link buffers to one while DBWR is unlinking them from the other.
                                                          LRU/TCH ALGORITHM
 LRU/TCH algorithm writes the cold dirty blocks to disk that are on the point of being pushed out of cache.
  As per ageing algorithm, DBWR will wake up every 3 seconds to flush dirty blocks to disk. But if blocks get dirtied at a fast pace during those 3 seconds and a server process needs some free buffers, some buffers need to be flushed to the disk to make room. That's when LRU/TCH algorithm is used to write those dirty buffers which are on the cold end of the LRU list.
   Whenever a server process needs some free buffers to read data, it scans the LRU list from its cold end to look for free buffers.
While searching
  If unused buffers found
    Read blocks from disk into the buffers and link them to the corresponding hash bucket
  if it finds some clean buffers (contain data but not dirtied or dirtied and have been flushed to disk),
      if they are the candidates to be aged out (low touch count)
          Read blocks from disk into the buffers and link them to the corresponding hash bucket
      else (have been accessed recently and should not be aged out)
         Move them to MRU end depending upon its touch count.
  If it finds dirty buffers (they are already in CKPT Q),
     Delink them from LRU list
     Link them  to the write-main list (Now these buffers are in CKPT Q and write-main list)
  The server process scans a threshold no. of buffers (_db_block_max_scan_pct = 40(default)). If it does not find required no. of free buffers,
   It triggers DBWR to dirty blocks in write-mainlist to disk
 . DBWR walks the write list-main and checks all the buffers
    - If changes made to the buffer have already been written to redo log files
           . Move those buffers to write-aux list
       else
          . Trigger LGWR to write changes to those buffers to redo logs
          . Move those buffers to write-aux list
  . Write buffers from write-aux list to disk
  . Delink those buffers from CKPT Q and w rite-aux list
  . Link those buffers to LRU list as free buffers
 Note that
- In this algorithm, the dirty blocks are delinked from LRU list before linking them to write-main list in contrast to ageing algorithm where the blocks can be simultaneously be in both CKPT Q and LRU list.
- In this algorithm, checkpoint is not advanced because it may be possible that the dirty blocks on the LRU end may actually not be the ones which were dirtied earliest. They may be there because the server process did not move them to the MRU end earlier. There might be blocks present in CKPT Q which were dirtied earlier than the blocks in question.
I hope the information was usefule. Thanks for your time.
Keep visiting the blog.

#-#log_checkpoint_interval#-#
#-#log_checkpoint_timeout#-#
A Checkpoint is a database event which synchronizes the data blocks in memory with the datafiles on disk.  A checkpoint has two purposes: (1) to establish data consistency, and (2) enable faster database recovery.  How is recovery faster?  Because all database changes up to the checkpoint have been recorded in the datafiles, making it unnecessary to apply redo log entries prior to the checkpoint. 
 
During a checkpoint the following occurs: 
 a)  The database writer (DBWR) writes all modified database blocks in the buffer cache back to datafiles, 
 b)  Log writer (LGWR) updates both the controlfile and the datafiles to indicate when the last checkpoint  
     occurred (SCN) 
 
If the optional background process CKPT, the checkpoint process, is enabled, then CKPT performs the operations of LGWR above.  The advantages of enabling CKPT are discussed below. 
 
A checkpoint occurs when Oracle performs a log switch from one group to another, when the number of operating system blocks specified by LOG_CHECKPOINT_INTERVAL have been written to the redo log, when the time specified by LOG_CHECKPOINT_TIMEOUT has expired, or when a checkpoint has been forced by the DBA. 
#-#checkpoint#-#
#-#log_checkpoint_interval#-#
#-#log_checkpoint_timeout#-#
 
#-#checkpoint_process#-#
The CHECKPOINT_PROCESS init.ora parameter determines whether or not the optional CKPT background process will be started to perform LGWRs tasks during checkpoint operations of updating the datafile headers.  LGWR is then free to perform its' primary function flushing the redo log buffer to the online redo logs. 
The CKPT process can improve performance significantly and decrease the amount of time users have to wait for a checkpoint operation to complete.  The overhead associated with starting another background process is not significant when compared to the performance benefit to be gained by enabling CKPT, therefore, Oracle recommends always enabling the checkpoint process (CKPT). 
#-#checkpoint_process#-#

#-#checkpoint not complete#-#
#-#background_checkpoints_completed#-#
#-#background_checkpoints_started#-#
Depending on the number of datafiles in a database, a checkpoint can be a 
highly resource intensive operation, since all datafile headers are frozen 
during the checkpoint.  
'checkpoint not completed' : This messages indicates that Oracle is ready to 
recycle the redo logs but the checkpoint has not been complete on the redo 
log Oracle needs to accomplish this. You should also check the bstat/estat 
report for the statistics BACKGROUND_CHECKPOINTS_COMPLETED and 
BACKGROUND_CHECKPOINTS_STARTED.  These two numbers should never differ by 
more than 1.  If there is a large difference in these two statistics it 
indicates that checkpoints are starting but not completing, just as 
"checkpoint not complete" messages in the alert log indicate.
The number of checkpoints completed and started as indicated by 
these statistics should be weighed against the duration of the bstat/estat 
report.  Keep in mind the goal of only one log switch per hour, which ideally 
should equate to one checkpoint per hour as well.   
The way to resolve incomplete checkpoints is through tuning checkpoints and 
logs:  
     1) Give the checkpoint process more time to cycle through the logs 
           -add more redo log groups        
           -increase the size of the redo logs 
     2) Reduce the frequency of checkpoints 
           -increase LOG_CHECKPOINT_INTERVAL 
           -increase size of online redo logs  
     3) Improve the efficiency of checkpoints 
          -enable the CKPT process with CHECKPOINT_PROCESS=TRUE 
#-#checkpoint not complete#-#
#-#background_checkpoints_completed#-#
#-#background_checkpoints_started#-#

#-#log file parallel write#-#
This is just LGWR doing the I/O.  Writing redo records to the redo log files from the log buffer.

Wait Time: Time it takes for the I/Os to complete. Even though redo records are written in parallel,
the parallel write is not complete until the last I/O is on disk.

p1 files Number of files to be written
p2 blocks Number of blocks to be written
p3 requests Number of I/O requests

#-#log file parallel write#-#
#-#log file switch completion#-#
The log file switch completion waits happens because redo generation is disabled during a log switch, and so processes that want to generate redo have to wait, even though the log buffer is entirely empty during the switch. If you have too many controlfiles, or if log switches are slow for some other reason, then there can be enough build up of demand for log buffer space so that to get some log buffer space waits shortly after redo generation has been enabled again.
#-#log file switch completion#-#

#-#_db_block_hash_buckets#-#
#-#_db_block_hash_latches#-#
_db_block_hash_buckets is the number of 'hash buckets' or chains in the buffer cache.  Prior to Oracle 8.1, the default value for _db_block_hash_buckets is actually the least prime number greater than or equal to db_block_buffers / 4. There is rarely any benefit in adjusting this parameter.  
_db_block_hash_latches is the number of database block hash latches. 
#-#_db_block_hash_buckets#-#
#-#_db_block_hash_latches#-#


#-#undo block waits#-#
The undo block class waits suggest that the cache (db_block_buffers) is not 
large enough to retain the undo for the most recent changes to hot blocks. 
This mean that there are too many undo class blocks in cache because of 
relatively large number of rollback segments. The optimal number of 
rollback segments is shown by  :

select count(*) from x$ktcxb where ktcxbflg > 0; 

#-#undo block waits#-#

#-#_bump_highwater_mark_count#-#
   1) A process will first check its own transaction freelist, for free space released earlier in the same transaction. Failing that, 
   it goes to the process freelist. If the process freelist is empty, it is populated with up to _bump_highwater_mark_count blocks 
   from the master free list. If the master freelist is empty, then if possible the freelist for a committed transaction will be 
   merged with it, that is all the blocks freed by that transaction are moved to the master free list. 
 
  Otherwise the HWM is raised and the blocks are formatted and placed on the master freelist. The number of blocks formatted is 
  actually the number of process freelists times the _bump_highwater_mark_count setting, or the number of unused blocks in the extent, 
  whichever is less. Once the master freelist is populated, a group of up to _bump_highwater_mark_count blocks is moved to the process 
  freelist, from where a block can be taken for use.  




  2) HW enqueue contention can occur for LOB segments which are ASSM managed as space allocation only acquires one block at a time. 
     With this fix ASSM lobs get a minimum number of chunks based on the value of event 44951 (up to 1024) which should help reduce 
     or eliminate HWM enqueue contention. 

        ALTER SYSTEM SET EVENT='44951 TRACE NAME CONTEXT FOREVER, LEVEL 1024'   scope=spfile;


#-#_bump_highwater_mark_count#-#

#-#transaction allocation#-#
The transaction allocation latch protects the transaction state object free list.
#-#transaction allocation#-#
#-#use_ism#-#
ism = intimate shared memory
This parameters tells Solaris to allow every process using this same segment to share the page table entries instead of creating their own, thus saving kernel memory. The side-effect, due to Sun's implementation of this, is that the segment can not be paged out of memory, thus locking the segment. This is done with a shmat(id,SHM_SHARE_MMU) call. So intimate shared memory is a super sharing of pages in memory
#-#use_ism#-#

#-#lock_sga#-#
LOCK_SGA is a generic parameter used to control whether or not we request that the shared memory segment is locked with a SHM_LOCK flag for the segment. On Solaris, this is done with a shmctl(id,SHM_LOCK) call, but can only be performed by a process with root user privileges.
#-#lock_sga#-#

#-#free buffer waits#-#

This wait happens when a session has to wait for a free buffer in the buffer cache. Eg: A buffer is needed for a session to read a database block from disk into the buffer cache. If the TIME spent waiting for free buffers is significant then it is likely that DBWR is not keeping up with the cache throughput rate. 

 This will happen if:

  - All buffer gets have been suspended. This could happen when a file was read-only and is now read-write.
    All the existing buffers need to be invalidated since they are not linked to lock elements (needed when mounted
    parallel (shared)). So cache buffers are not assigned to data block addresses until the invalidation is finished.

  - The session moved some dirty buffers to the dirty queue and now this dirty queue is full. The dirty queue needs
    to be written first. The session will wait on this event and try again to find a free buffer

  -  This also happens after inspecting free buffer inspected buffers. If no free buffer is found, Oracle waits for one
     second, and then tries to get the buffer again (depends on the context). For more information, see free buffer
     inspected.

Wait Time: 1 second

  p1   file#
  p2   block#

Action: Increate frequency of DBWR by decreasing _DB_LARGE_DIRTY_QUEUE. When the length of the write list is equal to this threshold, DBWR flush the list. The cost of each reduction in this parameter setting is an increase in DBWR CPU usage.


#-#free buffer waits#-#
#-#shared pool#-#
This shared pool latch contention occurs because a latch is held for too long, or because demand for the latch is too high, or both. The normal cause of contention for the shared pool latch is having a shared pool that is too big, and thus long free lists, so that processes hold the latch for a long time. The problem with literal SQL is that a child library cache latch is held for the duration of the parse. Namely, that the latch is held for too long, and too often. Literal SQL does increase the load on both latch types, but the real problem is the duration for which 
the latches are held.  
#-#shared pool#-#

#-#library cache latches#-#
#-#library cache pin#-#
Waits on the "library cache pin" wait event occur if a session wants to use an item in the 
shared pool but someone else has the item pinned in an incompatible mode. This is normally 
only seen if there is heavy contention for a particular object or statement in the shared pool. 

This event manages library cache concurrency. Pinning an object causes the heaps to be loaded into memory. If a client wan
to modify or examine the object, the client must acquire a pin after the lock.

Wait Time: 3 seconds (1 second for PMON)

p1 handle address    Address of the object being loaded
p2 address           Address of the load lock being used. This is not the same thing as a latch or an enqueue,
                     it is basically a State Object.
p3 mode              Indicates which data pieces of the object that needs to be loaded

    Contention for the shared pool, library cache pin, or library cache latches primarily occur when the shared pool is too 
    small or when statements are not reused. Statements are not usually reused when bind variables are not used and 
    common but not exact SQL floods the shared pool. Increasing the size of the shared pool only makes the latch problem 
    worse, because the user who flooded the shared pool with the large number of statements not using a bind variable 
    will use up the expanded shared pool with another large number of statements not using a bind variable. You can also 
    set the CURSOR_SHARING= FORCE (or CURSOR_SHARING=SIMILAR in Oracle9i) initialization parameter to help fix this issue 
    and to reduce problems when bind variables are not used. But the shared pool and library cache latch issues also occur 
    when space is needed in the library cache if the cache it is set too small for the number of SQL statements that need 
    to be processed. While space is being freed up in order to load a SQL or PL/SQL statement, the latch is being held 
    exclusively and other users must wait. You can help reduce contention by increasing the shared pool or by pinning large
    SQL and PL/SQL statements in memory, using the DBMS_SHARED_POOL.KEEP procedures. 


Action : Use bind variables; adjust the SHARED_ POOL_SIZE
#-#library cache latches#-#
#-#library cache pin#-#

#-#row cache object##-#
The row cache objects latch is needed when the cached data dictionary values are being accessed. Contention for this latch can be reduced by increasing the SHARED_POOL_SIZE init.ora parameter.
#-#row cache object##-#

#-#cache buffers lru chain#-#
The cache buffers LRU chain latch is needed when the LRU chain containing all the dirty blocks in the buffer cache is scanned. Contention for this latch can be reduced by increasing the DB_BLOCK_BUFFERS and DB_BLOCK_WRITE_BATCH init.ora parameters.
Heavy contention for this latch is generally due to heavy buffer cache activity which can be caused:

      Sorting in buffer cache and not using SORT_DIRECT_WRITES
      Repeatedly scanning large unselective indexes

Individual block contention can show up as contention for one of these latches.  Each cache buffers chains latch covers a list of buffers in the buffer cache. If one or two child latches stand out from V$LATCH_CHILDREN then:

                SELECT dbafil,dbablk,class, state 
                       FROM x$bh 
                       WHERE hladdr='&ADDR_OF_CHILD_LATCH' ;

If this list contains lots of entries for the same dbafil, dbablk If this list is short (3 to 10 buffers) then one of the buffers in this list is probably very 'hot'; ie: suffers from lots of concurrent access attempts.
#-#cache buffers lru chain#-#


#-#log buffer space#-#

Waiting for space in the log buffer because the session is writing data into the log buffer faster than LGWR can write it
out. Consider making the log buffer bigger if it is small, or moving the log files to faster disks such as striped disks.

Wait Time: Usually 1 second, but 5 seconds if it is waiting for a Switch Logfile to complete

This event frequently occurs when the log buffers are filling faster than LGWR can write 
them to disk. The two obvious solutions to this problem are to either A> Increase the amount 
of log buffers or to B> Change your redo log layout and/or I/O strategy.

#-#log file switch/archive#-#
#-#switch logfile command#-#
There are several wait events which may indicate problems with the redo buffer and redo log 
throughput: For the "log buffer space" events: Increase the LOG_BUFFER size until there is no 
incremental benefit (sizes > 1Mb are unlikely to add any benefit) 

For all other waits:

 c) Ensure redo logs are on fast disks (NOT RAID5) 
 c) Ensure redo logs are large enough to give a sensible gap between log switches. 
    A 'rule-of-thumb' is to have one log switch every 15 to 30 minutes. 
 c) Ensure the ARCHiver process is running and keeping up. 


The session waits on the user command SWITCH LOGFILE to complete.
Wait Time: 5 seconds
Parameters: None

#-#log buffer space#-#
#-#log file switch/archive#-#
#-#switch logfile command#-#
#-#log file switch completion#-#

Waiting for a log switch to complete.

Wait Time: 1 second

Parameters: None
#-#log file switch completion#-#
#-#log file switch (clearing log file)#-#

Waiting for a log switch because the log is being cleared due to a CLEAR LOGFILE command or implicit
clear logfile executed by recovery.

Wait Time: 1 second

Parameters: None
#-#log file switch (clearing log file)#-#
#-#log file switch (archiving needed)#-#

Waiting for a log switch because the log that the LGWR will be switching into has not been archived yet.
Check the alert file to make sure that archiving has not stopped due to a failed archive write. To speed archiving,
consider adding more archive processes or putting the archive files on striped disks.

Wait Time: 1 second

Parameters: None
#-#log file switch (archiving needed)#-#
#-#log file switch (checkpoint incomplete)#-#
Waiting for a log switch because the session cannot wrap into the next log. Wrapping cannot be performed
because the checkpoint for that log has not completed.

Wait Time: 1 second

Parameters: None
#-#log file switch (checkpoint incomplete)#-#
#-#log file sync#-#
When a user session commits, the session's redo information needs to be flushed to the redo logfile. The user session will
post the LGWR to write the log buffer to the redo log file. When the LGWR has finished writing, it will post the user session

Wait Time: The wait time includes the writing of the log buffer and the post.

p1     buffer#      The number of the physical buffer in the redo log buffer that needs to be synchronized

This wait happens when a commit (or rollback) is issued and the session has to wait for the redo entry to be flushed 
to disk to guarantee that instance failure will not roll back the transaction. 

Actions :

The 2 ways to reduce waits for this are: 
    Where possible reduce the commit frequency. Eg: Commit at batch intervals and not per row. 
    Speed up redo writing (Eg: Do NOT use RAID 5, use fast disks etc..) , Tune LGWR

Typically, if you commit too often, then you will see 'log file sync' waits appearing.
#-#log file sync#-#

#-#_db_block_write_batch#-#
#-#write complete waits#-#

The session waits for a buffer to be written. The write is caused by normal aging or by a cross-instance call.

Wait Time: 1 second
p1   file#     The rollback segment id that contains the transaction that is being rolled back
p2   block#    The transaction flags (options) set for the transaction that is being rolled back
p3   id        Identifies the reason for waiting


This wait happens when a requested buffer is being written to disk, as we cannot use the buffer 
while it is being written. If the TIME spent waiting for buffers to be written is significant 
then note the "Average Write Queue Length".  If this too is large then the the cache aging rate 
is too high for the speed that DBWR is writing buffers to disk. 

Actions : This can be tackled from two angles: 

    a) Decrease the cache aging rate 
    b) Increase the throughput of DBWR 
    c) Add DBWR or use Asyncronious I/O (aio)

'free buffer waits' and 'write complete waits' are opposite types of DBWn problem.  Generally, the first indicates that 
the write bandwidth is too small, and the second indicates that Oracle internal write batch size (_db_block_write_batch) 
is too big. 


#-#_db_block_write_batch#-#
#-#write complete waits#-#

#-#ORA-600 2667#-#
 The 2667 error is raised by LGWR if its buffers have been corrupted. One known cause of this is the (re)compilation or (re)loading of a large package body. Look for an INVALID package body, and try to compile it to see if the error is reproduced. If so, breaking the package into two smaller ones is likely to workaround the problem.  
#-#ORA-600 2667#-#

#-#ORA-600 2103#-#
This is a timeout trying to get the controlfile enqueue to perform a control file transaction,  probably trying to put a tablespace into backup mode, or bring it out again. This could be an operating system or hardware problem, so check your diagnostic logs. Alternately this could happen in OPS if your DLM has crashed. And of course it could be an Oracle bug. If this is happening frequently, you can set _controlfile_enqueue_timeout in seconds (default 900) to make it timeout more quickly, so you can get going again.  
#-#ORA-600 2103#-#
#-#ORA-600 4026#-#
The 4036 error is happening when trying to terminate an active transaction (ktudax) because the SGA rollback segment array shows that there are no active transactions in that rollback segment. The corruption of the SGA rollback segment array may be due to bug 602492 or bug 967166. You will need to work with Oracle support to make further progress on this issue.
#-#ORA-600 4026#-#
#-#CPU used by this session#-#
This is the amount of CPU time (in 10s of milliseconds) used by a session between when a user call started and ended. Some user calls can complete within 10 milliseconds and as a result, the start and end user-call time can be the same. In this case, 0 milliseconds are added to the statistic. 
A similar problem can exist in the reporting by the operating system, especially on systems that suffer from many context switches. 
#-#CPU used by this session#-#
#-#CPU used when call started#-#
The CPU time used when the call is started. 
#-#CPU used when call started#-#
#-#CR blocks created#-#
A buffer in the buffer cache was cloned. The most common reason for cloning is that the buffer is held in a incompatible mode. 
#-#CR blocks created#-#
#-#Cached Commit SCN referenced#-#
The number of times cached Commit SCN is referenced. 
#-#Cached Commit SCN referenced#-#
#-#Commit SCN referenced#-#
The number of times Commit SCN is cached. 
#-#Commit SCN referenced#-#
#-#Current blocks converted for CR#-#
A CURRENT buffer (shared or exclusive) is made CR before it can be used. 
Current mode blocks represent the current disk image of the block, whereas consistent read mode blocks represent 
an earlier transaction consistent version of the block. Only current mode blocks can be dirty 
#-#Current blocks converted for CR#-#
#-#DBWR buffers scanned#-#
The total number of buffers looked at when scanning each LRU set for dirty buffers to clean. This count includes both dirty and clean buffers. Divide by DBWR lru scans to find the average number of buffers scanned. 
#-#DBWR buffers scanned#-#
#-#DBWR checkpoint buffers written#-#
The number of buffers that were written for checkpoints. 
#-#DBWR checkpoint buffers written#-#
#-#DBWR checkpoints#-#
Number of times the DBWR was asked to scan the cache and write all blocks marked for a checkpoint. 
#-#DBWR checkpoints#-#
#-#DBWR forced writes#-#
DFS only: count of the number of blocks forced written. 
#-#DBWR forced writes#-#
#-#DBWR free buffers found#-#
The number of buffers that DBWR found to be clean when it was requested to make free buffers. Divide by DBWR make free requests to find the average number of reusable buffers at the end of each LRU. 
#-#DBWR free buffers found#-#
#-#DBWR lru scans#-#
The number of times that DBWR does a scan of the LRU queue looking for buffers to write. This includes times when the scan is to fill a batch being written for another purpose such as a checkpoint. This statistic is always greater than or equal to DBWR make free requests. 
#-#DBWR lru scans#-#
#-#DBWR make free requests#-#
Number of messages received requesting DBWR to make some more free buffers for the LRU. 
#-#DBWR make free requests#-#
#-#DBWR revisited being-written buffer#-#
The number of times that dbwr tried to save a buffer for writing and found that it was already in the write batch. This statistic is a measure of the amount of "useless" work that DBWR had to do in trying to fill the batch. This can occur because many sources contribute to a write batch. If the same buffer from different sources is considered for adding to the write batch, then all but the first attempt will be "useless" since the buffer is already marked as being written. 
#-#DBWR revisited being-written buffer#-#
#-#DBWR skip hot writes#-#
The number of times DBWR skipped writing "hot" buffers. 
#-#DBWR skip hot writes#-#
#-#DBWR summed scan depth#-#
The current scan depth (number of buffers examined by DBWR) is added to this statistic every time DBWR scans the LRU for dirty buffers. Divide by DBWR lru scans to find the average scan depth. 
#-#DBWR summed scan depth#-#
#-#DBWR undo block writes#-#
The number of transaction table blocks written by DBWR. It is an indication of how many "hot" buffers were written, leading to write complete waits. 
#-#DBWR undo block writes#-#
#-#DDL statements parallelized#-#
The number of DDL statements that were parallelized. 
#-#DDL statements parallelized#-#
#-#DML statements parallelized#-#
The number of DML statements that were parallelized. 
#-#DML statements parallelized#-#
#-#PX local messages recv'd#-#
The number of local messages received for Parallel Executions. 
#-#PX local messages recv'd#-#
#-#PX local messages sent#-#
The number of local messages send for Parallel Executions. 
#-#PX local messages sent#-#
#-#PX remote messages recv'd#-#
The number of remote messages received for Parallel Executions. 
#-#PX remote messages recv'd#-#
#-#PX remote messages sent#-#
The number of remote messages sent for Parallel Executions. 
#-#PX remote messages sent#-#
#-#SQLNet roundtrips to/from client#-#
Total number of Net8 messages sent to and received from the client. 
#-#SQLNet roundtrips to/from client#-#
#-#SQLNet roundtrips to/from dblink#-#
Total number of Net8 messages sent over and received from a database link. 
#-#SQLNet roundtrips to/from dblink#-#
#-#Switch current to new buffer#-#
The number of times the current version moved to a different buffer, leaving CR. 
#-#Switch current to new buffer#-#
#-#Unnecessary process cleanup for SCN batching#-#
The total number of times that the process cleanup was performed unnecessarily because the session/process did not get the next batched SCN. The next batched SCN went to another session instead. 
#-#Unnecessary process cleanup for SCN batching#-#
#-#background checkpoints completed#-#
The number of checkpoints completed by the background. This statistic is incremented when the background successfully advances the thread checkpoint
#-#background checkpoints completed#-#
#-#background checkpoints started#-#
The number of checkpoints started by the background. It can be larger than the number completed if a new checkpoint overrides an incomplete checkpoint. This only includes checkpoints of the thread, not individual file checkpoints for operations such as offline or begin backup. This statistic does not include the checkpoints performed in the foreground, such as ALTER SYSTEM CHECKPOINT LOCAL. 
#-#background checkpoints started#-#
#-#bytes received via SQL*Net from client#-#
The total number of bytes received from the client over Net8. 
#-#bytes received via SQL*Net from client#-#
#-#bytes received via SQL*Net from dblink#-#
The total number of bytes received from a database link over Net8. 
#-#bytes received via SQL*Net from dblink#-#
#-#bytes sent via SQL*Net to client#-#
The total number of bytes sent to the client from the foreground process(es). 
#-#bytes sent via SQL*Net to client#-#
#-#bytes sent via SQL*Net to dblink#-#
The total number of bytes sent over a database link. 
#-#bytes sent via SQL*Net to dblink#-#
#-#calls to get snapshot scn: kcmgss#-#
The number of times a snap System Change Number (SCN) was allocated. The SCN is allocated at the start of a transaction. 
#-#calls to get snapshot scn: kcmgss#-#
#-#change write time#-#
The elapsed time for redo write for changes made to CURRENT blocks in 10s of milliseconds. 
#-#change write time#-#
#-#cleanouts and rollbacks - consistent read gets#-#
#-#delayed_logging_block_cleanout#-#
Belongs to: init.ora 	Default value: TRUE         Range of Values : TRUE/FALSE

Description:
------------

-Setting this TRUE means no delay in block cleanout. 
-Setting this to FALSE means perform block cleanouts as in pre-7.3 releases (delay block cleanout until another user requests the block). 

This parameter turns on or off the delayed block cleanout feature, which reduces pinging in an Oracle Parallel Server.  Keeping this feature set to TRUE sets a fast path, not logging block cleanout at commit time.  Logging the block cleanout occurs at the time of a subsequent change to the block.  This generally improves Oracle Parallel Server performance, particularly if block pings are a problem.        

When Oracle commits a transaction, each block that the transaction changed is not immediately marked with the commit time.  This is done later, upon demand--when the block is read or updated.  This is called <block cleanout>. When block cleanout is done during an update to a current block, the cleanout changes and the redo records are piggybacked with those of the update.

In previous releases, when block cleanout was needed during a read to a current block, extra cleanout redo records were generated and the block was dirtied. This has been changed.        


As of release 7.3, when a transaction commits, all blocks changed by the transaction are cleaned out immediately (if they are in the buffer cache) - see below.  This cleanout performed at commit time is a "fast version" which does not generate redo log records (<delayed logging>) and does not repin the block. Most blocks will be cleaned out in this way, with the exception of blocks changed by long running transactions.        

During queries, therefore, the data block's transaction information is normally up-to-date and the frequency of needing block cleanout is much reduced. Regular block cleanouts are still needed when querying a block where the transactions are still truly active, or when querying a block which was not cleaned out during commit.

Note 1) In long-running transactions, block cleanouts will not be performed during the transaction. If the transaction is not long running, block cleanout will be performed and the block cleanout is logged at the change of block.

Note 2)   As of Oracle Server release 7.3, performing a SELECT COUNT (*) no longer does a block cleanout if this feature is in use. During changes (INSERT, DELETE, UPDATE), the cleanout redo log records are generated and piggyback with the redo of the changes.        
note 3 ) If the transaction accesses 10% of the buffer cache it will be considered a long running transaction. A long transaction will leave the blocks 'dirty' for future access to cleanup. 

#-#delayed_logging_block_cleanout#-#
#-#ITL - Interested Transaction List#-#
History and pourpose of ITL
---------------------------
Prior to 7.3, whenever a transaction was committed Oracle would not immediately "clean" the block that contained the committed, changed rows. Each block has an ITL, which stands for Interested Transaction List. 

Each ITL entry is about 24-28 bytes in length and contains things like the ITL number, the number of rows in the block locked by this transaction, the scn, the uba (undo block address), and the tid (transaction id, which is made up of undo_segment#.slot#.wrap#). The tid is what points readers to the rollback segment containing the before image changes. When a transaction commits, the ITL is not immediately cleaned up by the transaction doing the commit. Things like the number of rows locked, the scn, and the lock byte for each row in the block that was changed are left as they were. 

The next person to read or change rows in the block must "clean out" the block. This involves using the tid to goto the rollback segment to make sure the transaction is committed, update the scn, and clear out the lock byte information. The tid really points to the transaction table in the undo header. The slot# piece of the tid tells what row of the transaction table the transaction belongs to. There are fields in the transaction table that indicate whether or not the transaction is committed. 

All this also causes the block to be dirtied again by the reader who "cleans out" the block, generating redo. 

From 7.3 onwards, a new init.ora parameter was introduced called delayed_logging_block_cleanout, which defaults to true. Basically, this parameter tells Oracle to do a "fast commit", which means that upon commit the transaction doing the committing will record the scn in the block. Subsequent reads of the block will not have to do the extensive cleanout as before. The idea is that the redo generated from the cleanout will now be piggybacked onto the redo that gets generated from the next change to the block from a DML command. However, readers still use the tid to goto the rollback segment. The rollback segments are constantly being accessed because of this. 

This will explain why, if you ever do a tkprof or run autotrace in sqlplus, you almost always see a lot more reads in the query or consistent gets columns. Transactions that are committed days ago still access the rollback segment. The rollback segment blocks are constantly being accessed, thus they are susceptible to busy waits. 50 different people could read from 50 different tables, which at one point may have all used the same rollback segment to store undo. Subsequent readers are still going to access that rollback segment, even though the transactions are already committed. Oracle recognizes that rollback segments are very inefficient. 

It wouldn't be surprising if in a future release, they yield to a more efficient way of handling read consistency. 

Physical implementation of ITL
------------------------------
An Interested Transaction List is simply a list of transaction slots in a block. The number of slots defined in the ITL is defined by the initrans and maxtrans parameters. As you are probably aware, these parameters affect the number of concurrent transactions that can exist for a particular block in a table or index. The default for initrans is 1 for tables and 2 for indexes. The default for maxtrans is 255. 

Most people don't set these parameters or understand how they work. If initrans is 2 when you create a table, then the blocks for the segment are formatted with 2 transaction slots in the ITL. This means that up to 2 transactions can be modifying different rows in the same block at the same time. 

If a 3rd transaction happens to need to modify data in the same block, then a 3rd transaction slot will be dynamically allocated to the ITL for that block. But, the space for this 3rd transaction slot is taken out of the free space in the block. In other words, it comes out of the space reserved by PCTFREE. 

Subsequent allocations of transaction slots work the same way. So it's important to try and accurately specify appropriate values for initrans (and maxtrans) because it can play an important part of how space is used within your blocks, as well as impacting number of concurrent transactions. Also, if a block within a segment is full and further transaction slots cannot be allocated, a transaction trying to change a row in the block will get enqueued. Technically speaking, there is only 1 ITL per block. But, there can be multiple transaction slots in the ITL. Often times when the acronym "ITL" is used, it's meant to refer to an individual transaction slot within the entire list. 

For more information on block behaviour, look for 'block cleanout'.
#-#ITL - Interested Transaction List#-#
#-#block cleanouts#-#
Consider a transaction that updates a million row table. This obviously visits a large number of database blocks to make the change to the data. When the user commits the transaction Oracle does NOT go back and revisit these blocks to make the change permanent. It is left for the next transaction that visits any block affected by the update to 'tidy up' the block (hence the term 'delayed block cleanout').

Whenever Oracle changes a database block (index, table, cluster) it stores a pointer in the header of the data block which identifies the rollback segment used to hold the rollback information for the changes made by the transaction. (This is required if the user later elects to not commit the changes and wishes to 'undo' the changes made.)

Upon commit, the database simply marks the relevant rollback segment header entry as committed. Now, when one of the changed blocks is revisited Oracle examines the header of the data block which indicates that it has been changed at some point. The database needs to confirm whether the change has been committed or whether it is currently uncommitted. To do this, Oracle determines the rollback segment used for the previous transaction (from the block's header) and then determines whether the rollback header indicates whether it has been committed or not.

If it is found  that the block is committed then the header of the data block is updated so that subsequent accesses to the block do not incur this processing.

This behaviour is illustrated in a very simplified way below. Here we walk through the stages involved in updating a data block. 

STAGE 1 - No changes made

Description: 
------------
This is the starting point. At the top of the data block we have an area used to link active transactions to a rollback segment (the 'tx' part), and the rollback segment header has a table that stores information upon all the latest transactions that have used that rollback segment. In our example, we have two active transaction slots (01 and 02) and the next free slot is slot 03. (Since we are free to overwrite committed transactions.)


      Data Block 500                   Rollback Segment Header 5
      +----+--------------+            +----------------------+---------+
      | tx | None         |            | transaction entry 01 |ACTIVE   |
      +----+--------------+            | transaction entry 02 |ACTIVE   |
      | row 1             |            | transaction entry 03 |COMMITTED|
      | row 2             |            | transaction entry 04 |COMMITTED|
      | ... ..            |            |     ...     ...   .. |  ...    |
      | row n             |            | transaction entry nn |COMMITTED|
      +------------------+             +--------------------------------+

 STAGE 2 - Row 2 is updated
 Description: We have now updated row 2 of block 500. Note that the data block
              header is updated to point to the rollback segment 5, transaction
              slot 3 (5.3) and that it is marked uncommitted (Active). 

      Data Block 500                   Rollback Segment Header 5
      +----+--------------+            +----------------------+---------+
      | tx |5.3uncommitted|-----+      | transaction entry 01 |ACTIVE   |
      +----+--------------+     |      | transaction entry 02 |ACTIVE   |
      | row 1             |     +----->| transaction entry 03 |ACTIVE   |
      | row 2 *changed*   |            | transaction entry 04 |COMMITTED|
      | ... ..            |            |     ...     ...   .. |  ...    |
      | row n             |            | transaction entry nn |COMMITTED|
      +------------------+             +--------------------------------+

 STAGE 3 - The user issues a commit
 Description: Next the user hits commit. Note that all that this does is it
              updates the rollback segment header's corresponding transaction
              slot as committed. It does *nothing* to the data block.

      Data Block 500                   Rollback Segment Header 5
      +----+--------------+            +----------------------+---------+
      | tx |5.3uncommitted|-----+      | transaction entry 01 |ACTIVE   |
      +----+--------------+     |      | transaction entry 02 |ACTIVE   |
      | row 1             |     +----->| transaction entry 03 |COMMITTED|
      | row 2 *changed*   |            | transaction entry 04 |COMMITTED|
      | ... ..            |            |     ...     ...   .. |  ...    |
      | row n             |            | transaction entry nn |COMMITTED|
      +------------------+             +--------------------------------+

 STAGE 4 - Another user selects data block 500
 Description: Some time later another user (or the same user) revisits data
              block 500. We can see that there is an uncommitted change in the
              data block according to the data block's header.
              Oracle then uses the data block header to look up the 
              corresponding rollback segment transaction table slot, sees that
              it has been committed, and changes data block 500 to reflect the
              true state of the datablock. (i.e. it performs delayed cleanout).

      Data Block 500                   Rollback Segment Header 5
      +----+--------------+            +----------------------+---------+
      | tx | None         |            | transaction entry 01 |ACTIVE   |
      +----+--------------+            | transaction entry 02 |ACTIVE   |
      | row 1             |            | transaction entry 03 |COMMITTED|
      | row 2             |            | transaction entry 04 |COMMITTED|
      | ... ..            |            |     ...     ...   .. |  ...    |
      | row n             |            | transaction entry nn |COMMITTED|
      +------------------+             +--------------------------------+

Now, how does Oracle determines that a transaction slots is valid or, on contrary, has been overwritten by another process is considered proprietary by Oracle Corps.

#-#block cleanouts#-#
The number of times CR gets require both block rollbacks, and block cleanouts.
#-#cleanouts and rollbacks - consistent read gets#-# 
#-#cleanouts only - consistent read gets#-#
The number of times CR gets require only block cleanouts, no rollbacks. 
#-#cleanouts only - consistent read gets#-#
#-#cluster key scan block gets#-#
The number of blocks obtained in a cluster scan. 
#-#cluster key scan block gets#-#
#-#cluster key scans#-#
The number of cluster scans that were started. 
#-#cluster key scans#-#
#-#commit cleanout failures: block lost#-#
The number of times a cleanout at commit was attempted and could not find the correct block due to forced write, replacement, or switch CURRENT. 
#-#commit cleanout failures: block lost#-#
#-#commit cleanout failures: buffer being written#-#
The number of times a cleanout at commit was attempted but the buffer was currently being written. 
#-#commit cleanout failures: buffer being written#-#
#-#commit cleanout failures: callback failure#-#
The number of times the cleanout callback function returns FALSE. 
#-#commit cleanout failures: callback failure#-#
#-#commit cleanout failures: cannot pin#-#
The total number of times a commit cleanout was performed but failed because the block could not be pinned. 
#-#commit cleanout failures: cannot pin#-#
#-#commit cleanout failures: hot backup in progress#-#
The number of times cleanout at commit was attempted during hot backup. The image of the block needs to be logged before the buffer can be made dirty. 
#-#commit cleanout failures: hot backup in progress#-#
#-#commit cleanout failures: write disabled#-#
The number of times that a cleanout at commit time was performed but the writes to the database had been temporarily disabled. 
#-#commit cleanout failures: write disabled#-#
#-#commit cleanouts#-#
The total number of times the cleanout block at commit time function was performed. 
#-#commit cleanouts#-#
#-#commit cleanouts successfully completed#-#
The number of times the cleanout block at commit time function successfully completed. 
#-#commit cleanouts successfully completed#-#
#-#consistent changes#-#
The number of times a database block has applied rollback entries to perform a consistent read on the block. Work loads that produce a great deal of consistent changes can consume a great deal of resources. 
#-#consistent changes#-#
#-#consistent gets#-#
#-#consistent gets - examination#-#

This stat is a subset of consistent gets. It is the number of consistent gets that could be immediately performed without
pinning the buffer. Usually apply to indexes and require only one latch. See 'no work - consistent read gets' for tables.
It may be also accesses to undo record in order to reconstruct CR blocks. The undo records come from individual accesses 
(which are of the cheaper .consistent gets . examination. type that only need a single get on the cache buffers chains latch) 
to undo blocks, following the UBA (undo block address) pointer in the relevant ITL entry of the table block

#-#consistent gets - examination#-#
The number of times a consistent read was requested for a block. See also consistent changes . 
#-#consistent gets#-#
#-#data blocks consistent reads - undo records applied#-#
The number of undo records applied to CR rollback data blocks. 
#-#data blocks consistent reads - undo records applied#-#
#-#db block changes#-#
Closely related to consistent changes, this statistics counts the total number of changes that were made to all blocks in the SGA that were part of an update or delete operation. These are changes that are generating redo log entries and hence will be permanent changes to the database if the transaction is committed. 
This statistic is a rough indication of total database work. This statistic indicates (possibly on a per-transaction level) the rate at which buffers are being dirtied. 
#-#db block changes#-#
#-#db block gets#-#
This statistic tracks the number of blocks obtained in CURRENT mode. 
#-#db block gets#-#
#-#deferred (CURRENT) block cleanout applications#-#
The number of times cleanout records are deferred, piggyback with changes, always current get. 
#-#deferred (CURRENT) block cleanout applications#-#
#-#dirty buffers inspected#-#
The number of dirty buffers found by the foreground while the foreground is looking for a buffer to reuse. Dirty buffers inspected is symptomatic of a lazy DBWn. Oracle manual suggests to increasing the db_block_buffers value.
#-#dirty buffers inspected#-#
#-#enqueue conversions#-#
The total number of enqueue converts. 
#-#enqueue conversions#-#
#-#enqueue deadlocks#-#
The total number of enqueue deadlocks between different sessions. 
#-#enqueue deadlocks#-#
#-#enqueue releases#-#
The total number of enqueue releases
#-#enqueue releases#-#
#-#enqueue requests#-#
The total number of enqueue gets. 
#-#enqueue requests#-#
#-#enqueue timeouts#-#
The total number of enqueue operations (get and convert) that timed out before they could complete. 
#-#enqueue timeouts#-#
#-#enqueue waits#-#
The total number of waits that happened during an enqueue convert or get because the enqueue could not be granted right away. 
#-#enqueue waits#-#
#-#exchange deadlocks#-#
The number of times that a process detected a potential deadlock when exchanging two buffers and raised an internal, restartable error. Index scans are currently the only operations which perform exchanges. 
#-#exchange deadlocks#-#
#-#execute count#-#
The total number of calls (user and recursive) that execute SQL statements. 
#-#execute count#-#
#-#free buffer inspected#-#
The number of buffers skipped over from the end of an LRU queue in order to find a reusable buffer. The difference between this statistic and dirty buffers inspected is the number of buffers that could not be used because they were busy, needed to be written after rapid aging out, or they have a user, a waiter, or are being read/written. For more information, see "dirty buffers inspected". 
#-#free buffer inspected#-#
#-#free buffer requested#-#
The count of the number of times a reusable buffer or a free buffer was requested to create or load a block. 
#-#free buffer requested#-#
#-#global cache defers#-#
The number of times a ping request was deferred until later. 
#-#global cache defers#-#
#-#global cache freelist waits#-#
The number of pings for free lock elements (when all releasable locks are in use) 
#-#global cache freelist waits#-#
#-#global lock convert time#-#
The total elapsed time of all synchronous (non-asynchronous) global lock converts in 10s of milliseconds. 
#-#global lock convert time#-#
#-#global lock converts (async)#-#
The total number of asynchronous global lock converts. 
#-#global lock converts (async)#-#
#-#global lock converts (non async)#-#
The total number of synchronous global lock converts. 
#-#global lock converts (non async)#-#
#-#global lock get time#-#
The total elapsed time of all synchronous (non-asynchronous) global lock gets in 10s of milliseconds. 
#-#global lock get time#-#
#-#global lock gets (async)#-#
The total number of asynchronous global lock gets. 
#-#global lock gets (async)#-#
#-#global lock gets (non async)#-#
The total number of synchronous global lock gets. 
#-#global lock gets (non async)#-#
#-#global lock releases#-#
The total number of synchronous global lock releases. 
#-#global lock releases#-#
#-#hot buffers moved to head of LRU#-#
When a hot buffer reaches the tail of its replacement list, it is moved back to the head of the list. This is what keeps hot buffers from being reused. This statistic indicates how often that happens. 
#-#hot buffers moved to head of LRU#-#
#-#immediate (CR) block cleanout applications#-#
The number of times cleanout records are applied immediately during CR gets. 
#-#immediate (CR) block cleanout applications#-#
#-#immediate (CURRENT) block cleanout applications#-#
The number of times cleanout records are applied immediately during current gets. 
#-#immediate (CURRENT) block cleanout applications#-#
#-#kcmccs called get current scn#-#
The number of times the kernel got the CURRENT SCN when there was a need to casually confirm the SCN. 
#-#kcmccs called get current scn#-#
#-#kcmccs read scn without going to DLM#-#
The number of times the kernel casually confirmed the SCN without going to the LM. 
#-#kcmccs read scn without going to DLM#-#
#-#kcmgss waited for batching#-#
The number of times the kernel waited on a snapshot SCN. 
#-#kcmgss waited for batching#-#
#-#index fetch by key#-#
This stat will be incremented for each "INDEX (UNIQUE SCAN)". 
This also applies to all DML statements which has "INDEX(UNIQUE SCAN)" in the execution plan. 
#-#index fetch by key#-#
#-#index scans kdiixs1#-#
This stat is incremented for each index range scan operation, except 
for index fat full scans, index full scan, and index unique scan. 
KDIIXS, KDISPO, KDIFXS, KDIRLS are routines that do a range scan 
kdiixs initializes the kdi (Kernel Data layer Index) state for an index scan
#-#index scans kdiixs1#-#
#-#logons cumulative#-#
The total number of logons since the instance started. This statistic is useful only in V$SYSSTAT. 
It gives an instance overview of all processes that logged on. 
#-#logons cumulative#-#
#-#logons current#-#
The total number of current logons. This statistic is useful only in V$SYSSTAT. 
#-#logons current#-#
#-#Native hash arithmetic execute#-#
Incremented when the native arithmetic runtime engine is invoked. 
#-#Native hash arithmetic execute#-#
#-#Native hash arithmetic fail#-#
Incremented when the runtime engine encounters an overflow condition. 
#-#Native hash arithmetic fail#-#
#-#Next scns gotten without going to DLM#-#
The number of SCNs (System Change Numbers) obtained without going to the DLM. 
#-#Next scns gotten without going to DLM#-#
#-#no work - consistent read gets#-#
The number of times CR gets could be done without requiring rollback or cleanout. generaly apply to tables . It means that the block was available for immediate read withtout needs to be rebuild using apply of redo.
and require 2 latches. It is a sub part of consistent gets
#-#no work - consistent read gets#-#
#-#opened cursors cumulative#-#
The total number of opened cursors since the instance has started (in V$SYSSTAT). In V$SESSTAT, this statistic shows 
the total number of cursors opened since the start of the session. 
#-#opened cursors cumulative#-#
#-#opened cursors current#-#
The total number of current open cursors. 
#-#opened cursors current#-#
#-#session_cached_cursors#-#
The session_cached_cursors parameter is used to reduce the amount of parsing with SQL statements that use host variables. 
The session_cached_cursors parameter has a default value of 50, and increasing the value of session_cached_cursors will 
requires a larger shared_pool_size to cache the cursors.  
#-#session_cached_cursors#-#
#-#opens of replaced files#-#
The total number of files that needed to be reopened because they were no longer in the process file cache. 
#-#opens of replaced files#-#
#-#opens requiring cache replacement#-#
The total number of file opens that caused a current file to be closed in the process file cache. 
#-#opens requiring cache replacement#-#
#-#parse count (hard)#-#
The total number of parse calls (real parses). A hard parse means allocating a workheap and other memory structures, and then building a parse tree. A hard parse is a very expensive operation in terms of memory use. 
In summary,

   1. Perform syntax check
   2. Perform semantic check
   3. Perform hash function
   4. Perform library cache lookup
   5. If hash value found then
   6. .....If command is identical to existing one in cache then
   7. ..........If the objects referenced in the cached command are the same as the ones in the new command then
   8. ...............This is a soft parse, go to step 11
   9. This is a hard parse, build parse tree
  10. Build execution plan
  11. Execute plan.

The building of the parse tree and execution plan are the two most expensive parts of the parsing, and if these have to be done, then we have a hard parse.

#-#parse count (hard)#-#
#-#parse count (total)#-#
Total number of parse calls (hard and soft). A soft parse is a check to make sure that the permissions on the underlying object have not changed. 
#-#parse count (total)#-#
#-#parse time cpu#-#
The total CPU time used for parsing (hard and soft) in 10s of milliseconds. 
#-#parse time cpu#-#
#-#parse time elapsed#-#
The total elapsed time for parsing in 10s of milliseconds. By subtracting parse time cpu from the this statistic, the total waiting time for parse resources is determined. For more information see parse time cpu . 
#-#parse time elapsed#-#
#-#physical reads#-#
The total number of data blocks read from disk. This equals the number of "physical reads direct" plus all reads into buffer cache. 
#-#physical reads#-#
#-#physical reads direct#-#
The number of reads directly read from disk bypassing the buffer cache. For example, in high bandwidth, data-intensive operations such as parallel query, reads of disk blocks bypass the buffer cache to maximize transfer rates and to prevent the premature aging of shared data blocks resident in the buffer cache. 
#-#physical reads direct#-#
#-#physical writes#-#
The total number of data blocks written to disk. This equals the number of "physical writes direct" plus all writes from buffer cache. 
#-#physical writes#-#
#-#physical writes direct#-#
The number of writes directly written to disk bypassing the buffer cache (as in a direct load operation). 
#-#physical writes direct#-#
#-#physical writes non-checkpoint#-#
The number of writes that would occur were checkpointing turned off. Note that this is a theoretical number because checkpointing will always be required for log switches. 
#-#physical writes non-checkpoint#-#
#-#buffer is not pinned count#-#
Number of pin-able buffers not pinned by this session when visited. It is a number of logical io. 
Number of buffers visited = buffer is not pinned count + buffer is pinned count

no buffer to keep pinned count : Number of times a visit to a buffer attempted, but the buffer was not found where expected. 
Like "buffer is not pinned count" and "buffer is pinned count", this statistic is useful only for internal debugging purposes.

The number of buffers you can pin for a query is limited by the parameter _cusor_db_buffers_pinned 
and this has the default value of MAX[(buffers/processes-2),2]


Basically, not pin count just means it is a new buffer that as just been loaded after a disk read, 
but was not properly referenced


#-#buffer is not pinned count#-#
#-#buffer is pinned count#-#
Number of buffers already pinned by this session when visited
Number of buffers visited = buffer is not pinned count + buffer is pinned count
#-#buffer pinning#-#
Oracle uses pinning to reduce the number of logical I/O. If buffer will be accessed again by the statement, it is pinned 
in the buffer cache. It is frequently used with index scans and is only used by consistents gets, not current gets.
#-#buffer pinning#-#
#-#buffer is pinned count#-#
#-#pinned buffers inspected#-#
The number of times a foreground encountered a cold buffer that was pinned or had a waiter that was about to pin it when 
the foreground is scanning the tail of the replacement list looking for a buffer to reuse. It should be uncommon because 
a cold buffer should not be pinned very often. 
#-#pinned buffers inspected#-#
#-#queries parallelized#-#
The number of SELECT statements that got parallelized. 
#-#queries parallelized#-#
#-#recovery array read time#-#
The elapsed time of I/O while doing recovery. 
#-#recovery array read time#-#
#-#recovery array reads#-#
The number of reads performed during recovery. 
#-#recovery array reads#-#
#-#recovery blocks read#-#
The number of blocks read during recovery. 
#-#recovery blocks read#-#
#-#recursive calls#-#
Oracle maintains tables used for internal processing. When Oracle needs to make a change to these tables, it internally generates a SQL statement. These internal SQL statements generate recursive calls. 

or 

Sometimes to execute a SQL statement issued by a user, Oracle must issue additional statements. Such statements are called 'recursive calls' or 'recursive SQL statements'. For example, if you insert a row into a table that does not have enough space to hold that row, Oracle makes recursive calls to allocate the space dynamically. Recursive calls are also generated when data dictionary information is not available in the data dictionary cache and must be retrieved from disk.
#-#recursive calls#-#
#-#recursive cpu usage#-#
The total CPU time used by non-user calls (recursive calls). Subtract this value from CPU used by this session to determine how much CPU time was used by the user calls. 
#-#recursive cpu usage#-#
#-#redo entries#-#
This statistic increments each time redo entries are copied into the redo log buffer. 
#-#redo entries#-#
#-#redo log space requests#-#
The active log file is full and Oracle is waiting for disk space to be allocated for the redo log entries. Space is created by performing a log switch. Small Log files in relation to the size of the SGA or the commit rate of the work load can cause problems. When the log switch occurs, Oracle must ensure that all committed dirty buffers are written to disk before switching to a new log file. If you have a large SGA full of dirty buffers and small redo log files, a log switch must wait for DBWR to write dirty buffers to disk before continuing. Also examine the log file space and log file space switch wait events in V$SESSION_WAIT. 
#-#redo log space requests#-#
#-#redo log space wait time#-#
The total elapsed time of waiting for redo log space request in 10s of milliseconds. 
#-#redo log space wait time#-#
#-#redo log switch interrupts#-#
The number of times that another instance asked this instance to advance to the next log file. 
#-#redo log switch interrupts#-#
#-#redo ordering marks#-#
The number of times that an SCN had to be allocated to force a redo record to have an higher SCN than a record generated in another thread using the same block. 
#-#redo ordering marks#-#
#-#redo size#-#
The total amount of redo generated in bytes. 
#-#redo size#-#
#-#redo synch time#-#
The elapsed time of all redo sync writes calls in 10s of milliseconds. 
#-#redo synch time#-#
#-#redo sync writes#-#
Usually, redo that is generated and copied into the log buffer need not be flushed out to disk immediately. The log buffer is a circular buffer that LGWR periodically flushes. Redo sync writes increments when changes being applied must be written out to disk due to a commit. 
#-#redo sync writes#-#
#-#redo wastage#-#
Number of bytes wasted because redo blocks needed to be written before they are completely full. 
Early writing may be needed to commit transactions, to be able to write a database buffer or to switch logs. 
#-#redo wastage#-#
#-#redo write time#-#
The total elapsed time of the write from the redo log buffer to the current redo log file in 10s of milliseconds. 
#-#redo write time#-#
#-#redo writer latching time#-#
The elapsed time need by LWGR to obtain and release each copy latch in 10s of milliseconds. This is only used if the initialization parameter LOG_SIMULTANEOUS_COPIES > 0.
#-#redo writer latching time#-#
#-#redo writes#-#
Count of the total number of writes by LGWR to the redo log files. 
#-#redo writes#-#
#-#remote instance undo block writes#-#
The number of times this instance wrote a dirty undo block so that another instance could read it. 
#-#remote instance undo block writes#-#
#-#remote instance undo header writes#-#
The number of times this instance wrote a dirty undo header block so that another instance could read it. 
#-#remote instance undo header writes#-#
#-#rollback changes - undo records applied#-#
The number of undo records applied to rollback (real) changes. 
#-#rollback changes - undo records applied#-#
#-#rollbacks only - consistent read gets#-#
The number of times CR gets require only block rollbacks, no block cleanouts. 
#-#rollbacks only - consistent read gets#-#
#-#serializable aborts#-#
The number of times a SQL statement in serializable isolation level had to abort. 
#-#serializable aborts#-#
#-#session connect time#-#
The connect time for the session in 1/100 seconds. This value is useful only in V$SESSTAT. It is the wall clock time of when the logon to this session occurred. 
#-#session connect time#-#
#-#session cursor cache count#-#
The total number of cursor cached. This is only incremented if SESSION_CACHED_CURSORS > 0. This statistic is the most useful in V$SESSTAT. If the value for this statistic in V$SESSTAT is close to the setting of the initialization parameter SESSION_CACHED_CURSORS, the value of the initialization parameter should be increased. 
#-#session cursor cache count#-#
#-#session cursor cache hits#-#
The count of the number of hits in the session cursor cache. A hit means that the SQL statement did not have to be reparsed. By subtracting this statistic from parse count (total) one can determine the real number of parses that happened. 
#-#session cursor cache hits#-#
#-#session pga memory#-#
This statistic shows the current PGA size for a session. This statistic is useful only in V$SESSTAT; it has no meaning in V$SYSSTAT. 
#-#session pga memory#-#
#-#session pga memory max#-#
This statistic shows the peak PGA size for a session. This statistic is useful only in V$SESSTAT; it has no meaning in V$SYSSTAT
#-#session pga memory max#-#
#-#session stored procedure space#-#
This statistic shows the amount of memory that this session is using for stored procedures. 
#-#session stored procedure space#-#
#-#session uga memory#-#
This statistic shows the current UGA size for a session. This statistic is useful only in V$SESSTAT; it has no meaning in V$SYSSTAT. 
#-#session uga memory#-#
#-#session uga memory max#-#
This statistic shows the peak UGA size for a session. This statistic is useful only in V$SESSTAT; it has no meaning in V$SYSSTAT. 
#-#session uga memory max#-#
#-#sorts (disk)#-#
If the number of disk writes is non-zero for a given sort operation, then this statistic is incremented. Sorts that require I/O to disk are quite resource intensive. Try increasing the size of the initialization parameter SORT_AREA_SIZE. For more information.
#-#sorts (disk)#-#
#-#sorts (memory)#-#
If the number of disk writes is zero, then the sort was performed completely in memory and this statistic is incremented. This is more an indication of sorting activity in the application work load. You cannot do much better than memory sorts, except maybe no sorts at all. Sorting is usually caused by selection criteria specifications within table join SQL operations. 
#-#sorts (memory)#-#
#-#sorts (rows)#-#
The total number of rows sorted. 
#-#sorts (rows)#-#
#-#summed dirty queue length#-#
The sum of the dirty LRU queue length after every write request. Divide by write requests to get the average queue length after write completion. 
#-#summed dirty queue length#-#
#-#table fetch by rowid#-#
When rows are fetched using a ROWID (usually recovered from an index), each row returned increments this counter. This statistic is an indication of row fetch operations being performed with the aid of an index. Because doing table scans usually indicates either non-optimal queries or tables without indexes, this statistic should increase as the above issues have been addressed in the application. 
#-#table fetch by rowid#-#
#-#table fetch continued row#-#
When a row that spans more than one block is encountered during a fetch, this statistic is incremented. Retrieving rows 
that span more than one block increases the logical I/O by a factor that corresponds to the number of blocks than need to 
be accessed. Exporting and re-importing may eliminate this problem. Taking a closer look at the STORAGE parameters 
PCT_FREE and PCT_USED. This problem cannot be fixed if rows are larger than database blocks (for example, if the LONG 
datatype is used and the rows are extremely large). 
#-#table fetch continued row#-#
#-#table scan blocks gotten#-#
During scanning operations, each row is retrieved sequentially by Oracle. Each block encountered during the scan increments this statistic. 
This statistic informs you of the number of database blocks that you had to get from the buffer cache for the purpose of scanning. Compare the value of this parameter to the value of consistent gets to get a feeling for how much of the consistent read activity can be attributed to scanning. For more information, see "consistent gets". 
#-#table scan blocks gotten#-#
#-#table scan rows gotten#-#
This statistic is collected during a scan operation, but instead of counting the number of database blocks, it counts the rows being processed. 
#-#table scan rows gotten#-#
#-#table scans (cache partitions)#-#
Count of range scans on tables that have the CACHE option enabled. 
#-#table scans (cache partitions)#-#
#-#table scans (direct read)#-#
Count of table scans performed with direct read (bypassing the buffer cache). 
#-#table scans (direct read)#-#
#-#table scans (long tables)#-#
Long (or conversely short) tables can be defined as tables that do not meet the short table criteria as described in table scans (short tables). 
#-#table scans (long tables)#-#
#-#table scans (rowid ranges)#-#
Count of table scans with specified ROWID endpoints. This is performed for Parallel Query. 
#-#table scans (rowid ranges)#-#
#-#table scans (short tables)#-#
Long (or conversely short) tables can be defined by optimizer hints coming down into the row source access layer of Oracle. The table must have the CACHE option set. 
#-#table scans (short tables)#-#
#-#total file opens#-#
The total number of file opens being performed by the instance. Each process needs a number of files (control file, log file, database file) in order to work against the database. 
#-#total file opens#-#
#-#transaction rollbacks#-#
The number of transactions being successfully rolled back. 
#-#transaction tables consistent read rollbacks#-#
The number of times transaction tables are CR rolled back. 
#-#transaction tables consistent read rollbacks#-#
#-#transaction tables consistent reads - undo records applied#-#
The number of undo records applied to CR rollback transaction tables. some blocks have been cloned to create the appropriate version.
#-#transaction tables consistent reads - undo records applied#-#
#-#user calls#-#
Oracle allocates resources (Call State Objects) to keep track of relevant user call data structures every time you log in, parse, or execute. 
When determining activity, the ratio of user calls to RPI calls, give you an indication of how much internal work gets generated as a result of the type of requests the user is sending to Oracle. 
#-#user calls#-#
#-#user commits#-#
When a user commits a transaction, the redo generated that reflects the changes made to database blocks must be written to disk. Commits often represent the closest thing to a user transaction rate. 
#-#user commits#-#
#-#user rollbacks#-#
This statistic stores the number of times users manually issue the ROLLBACK statement or an error occurs during users' transactions. 
#-#user rollbacks#-#
#-#shared pool_size#-#
This parameter specifies the size of the shared pool in bytes 
#-#shared pool_size#-#
#-#alter system set dispatcher#-#

A session has issued a statement ALTER SYSTEM SET DISPATCHER = string and is waiting for the dispatchers to get started.

Wait Time: The session will wait 1 / 100 of a second and check to see if the new dispatchers have started
else the session will wait again

p1 waited Number of times that the session has waited 1 / 100 of a second

#-#alter system set dispatcher#-#
#-#batched allocate scn lock request#-#

A session is waiting on another process to allocate a system change number (SCN). If the foreground timed out waiting on a process to get the SCN, the foreground will get the SCN.

Wait Time: The wait time is 1 second on the assumption that an SCN allocation should normally need much less than that

Parameters: None
#-#batched allocate scn lock request#-#
#-#BFILE check if exists#-#

The session waits to check if an external large object (LOB) exists.

Wait Time: The total elapsed time for the exists call
p1 session#
p2 waited

#-#BFILE check if exists#-#
#-#BFILE check if open#-#

The session waits for an external large object (LOB) to open.

Wait Time: The total elapsed time for the isopen call
p1 session#
pé waited

#-#BFILE check if open#-#
#-#BFILE closure#-#

The session waits for an external large object (LOB) to close.

Wait Time: The total elapsed time for the close call
p1 session#
p2 waited

#-#BFILE closure#-#
#-#BFILE get length#-#

The session waits on a call to check the size of an external large object (LOB).

Wait Time: The total elapsed time for the call to check the LOB size
p1 session#
p2 waited

#-#BFILE get length#-#
#-#BFILE get name object#-#

The session waits on a call to find or generate the external name of a external large object.

Wait Time: The total elapse time for make external file name to complete
p1 session#
p2 waited

#-#BFILE get name object#-#
#-#BFILE get path object#-#

The session is waiting on a call to find or generate the external path name of an external large object (LOB).

Wait Time: The total elapsed time for make external path to complete
p1 session#
p2 waited

#-#BFILE get path object#-#
#-#BFILE open#-#

The session waits for an external large object (LOB) to open.

Wait Time: The total elapsed time for the isopen call
p1 session#
p2 waited

#-#BFILE open#-#
#-#broadcast mesg queue transition#-#

Processes enter "wait for broadcast mesg queue transition" when cleaning up a publisher channel handle to a RELIABLE
broadcast channel. The publisher is responsible for moving the message to the free queue, but it cannot do so until
the message is in the done queue. If the message is still not in the done queue, process enters this wait. This wait
event will most likely show up when an Oracle process is about to exit normally, or when PMON cleans up a dead process.

Wait Time: Varies

p1 channel handle publisher channel handle pointer
p2 message broadcast message pointer
p3 location A number indicating the function in KSR where the process is waiting

#-#broadcast mesg queue transition#-#
#-#broadcast mesg recovery queue transition#-#

Processes enter "wait for broadcast mesg recovery queue transition" when cleaning up a publisher channel handle
to a RELIABLE broadcast channel. The broadcasted message is in the recovery queue of another channel handle
(for example, ch2). Process enters this wait, if the message is yet to be removed from the recovery queue of the
ch2 channel handle. This wait event will most likely show up when an Oracle process is about to exit normally,
or when PMON cleans up a dead process.

Wait Time: Varies

p1 channel handle Publisher channel handle pointer
p2 message Broadcast message pointer
p3 location A number indicating the function in KSR where the process is waiting

#-#broadcast mesg recovery queue transition#-#
#-#buffer deadlock#-#

Oracle does not really wait on this event; the foreground only yields the CPU. Thus, the chances of catching this event are very low. This is not an application induced deadlock, but an assumed deadlock by the cache layer. The cache layer cannot get a buffer in a certain mode within a certain amount of time.

Wait Time: 0 seconds. The foreground process only yields the CPU and will usually be placed at the end of the CPU run queue.
p1 class The class of the block describes how the contents of the block are used.
For example, class 1 represents data block, and class 4 represents segment header.
select chr(bitand(p1,-16777216)/16777215)|| chr(bitand(p1, 16711680)/65535) "class"
from v$session_wait where event = 'buffer deadlock';

p1 mode select (bitand(65535) "Mode" from v$session_wait where event = 'buffer deadlock';

p2 flag The flag points to the internal flags used by the session to get this block
p3 dba The initials "dba" represents the data block address, which consists of a file number and a block number.

#-#buffer deadlock#-#
#-#buffer latch#-#

The session waits on the buffer hash chain latch. Primarily used in the dump routines.

Wait Time: 1 second
p1 latch addr The virtual address in the SGA where this latch is located. Use the following statement to find
the name of this latch:
select cpu_distribution_asdb.txt db_buffer_catg_asdb.txt db_buffer_distrib_poolasdb.txt ff.1 ff.2 ff.org fil_tmp.txt img_dr.pl list_init_param.txt resource_waits_asdb_042815.txt sample_delta_w_POLDB1.04191426 sample_sql_w_POLDB1.04191426 sample_sys_w_POLDB1.04191426 sample_w_txt_POLDB1.04191426 sem_sql_w_asdb.txt shared_pool_free_list_asdb.txt slp_asdb.txt system_event_asdb_050216.txt xx from v$latch a, v$latchname b where addr = latch addr and a.latch# = b.latch#;

p2 chain# The index into array of buffer hash chains. When the chain is 0xfffffff,
the foreground waits on the LRU latch.

#-#buffer latch#-#
#-#buffer read retry#-#

This event occurs only if the instance is mounted in shared mode (Oracle Real Application Cluster). During the read of the buffer, the contents changed. This means that either:

* The version number, dba, or the incarnation and sequence number stored in the block no longer match
* The checksum on the block does not match the checksum in the block

The block will be re-read (this may fail up to 3 times), then corruption is assumed and the corrupt block is dumped in the trace file.

Wait Time: The wait time is the elapsed time of the read
p1 file#
p2 block#

#-#buffer read retry#-#
#-#checkpoint completed#-#

A session waits for a checkpoint to complete. This could happen, for example, during a close database or a local checkpoint.

Wait Time: 5 seconds

Parameters: None
#-#checkpoint completed#-#
#-#cleanup of aborted processes#-#

When a process spawn is aborted while the process spawning background is in the middle of spawning, the current session must wait until the pid of the new process is filled in. Once the pid is filled in, then the process spawn can be actually aborted.

Wait Time: Usually 3 seconds
p1 location Location of the wait

#-#cleanup of aborted processes#-#
#-#control file parallel write#-#

This event occurs while the session is writing physical blocks to all control files. This happens when:

* The session starts a control file transaction (to make sure that the control files are up to date in case
the session crashes before committing the control file transaction)
* The session commits a transaction to a control file
* Changing a generic entry in the control file, the new value is being written to all control files

Wait Time: The wait time is the time it takes to finish all writes to all control files
p1   files    The number of control files to which the session is writing
p2   blocks   The number of blocks that the session is writing to the control file
p3   requests The number of I/O requests which the session wants to write

#-#control file parallel write#-#
#-#control file sequential read#-#

Reading from the control file. This happens in many cases. For example, while:

* Making a backup of the control files
* Sharing information (between instances) from the control file
* Reading other blocks from the control files
* Reading the header block

Wait Time: The wait time is the elapsed time of the read
p1 file# The control file from which the session is reading
p2 block# Block number in the control file from where the session starts to read. The block size is
the physical block size of the port (usually 512 bytes, some UNIX ports have 1 or 2 Kilobytes).
p3 blocks The number of blocks that the session is trying to read

#-#control file sequential read#-#
#-#control file single write#-#

This wait is signaled while the control file's shared information is written to disk. This is an atomic operation protected by an enqueue (CF), so that only one session at a time can write to the entire database.

Wait Time: The wait time is the elapsed time of the write
p1 file# This identifies the control file to which the session is currently writing
p2 block# Block number in the control file where the write begins. The block size is the as the physical block size
, of the port (usually 512 bytes, some UNIX ports have 1 or 2 Kilobytes).
p3 blocks The number of blocks that the session is trying to read

#-#control file single write#-#
#-#cursor: mutex S#-#

A session waits on this event when it is requesting a mutex in shared mode, when another session is currently holding a this mutex in exclusive mode on the same cursor object.

P1 Hash value of cursor
P2 Mutex value (top 2 bytes contain SID holding mutex in exclusive mode, and bottom two bytes usually hold the value 0)
P3 Mutex where (an internal code locator) OR'd with Mutex Sleeps

#-#cursor: mutex S#-#
#-#cursor: mutex X#-#

The session requests the mutex for a cursor object in exclusive mode, and it must wait because the resource is busy. The mutex is busy because either the mutex is being held in exclusive mode by another session or the mutex is being held shared by one or more sessions. The existing mutex holder(s) must release the mutex before the mutex can be granted exclusively.

P1 Hash value of cursor
P2 Mutex value (top 2 bytes contain SID holding mutex in exclusive mode, and bottom two bytes usually hold the value 0)
P3 Mutex where (an internal code locator) OR'd with Mutex Sleeps

#-#cursor: mutex X#-#
#-#cursor: pin S#-#

A session waits on this event when it wants to update a shared mutex pin and another session is currently in the process of updating a shared mutex pin for the same cursor object. This wait event should rarely be seen because a shared mutex pin update is very fast.

Wait Time: Microseconds

P1 Hash value of cursor
P2 Mutex value (top 2 bytes contains SID holding mutex in exclusive mode, and bottom two bytes usually hold the value 0)
P3 Mutex where (an internal code locator) OR'd with Mutex Sleeps

#-#cursor: pin S#-#
#-#cursor: pin S wait on X#-#

A session waits for this event when it is requesting a shared mutex pin and another session is holding an exclusive mutex pin on the same cursor object.

Wait Time: Microseconds

P1 Hash value of cursor
P2 Mutex value (top 2 bytes contains SID holding mutex in exclusive mode, and bottom two bytes usually hold the value 0)
P3 Mutex where (an internal code locator) OR'd with Mutex Sleeps

#-#cursor: pin S wait on X#-#
#-#cursor: pin X#-#

A session waits on this event when it is requesting an exclusive mutex pin for a cursor object and it must wait because the resource is busy. The mutex pin for a cursor object can be busy either because a session is already holding it exclusive, or there are one or more sessions which are holding shared mutex pin(s). The exclusive waiter must wait until all holders of the pin for that cursor object have released it, before it can be granted.

Wait Time: Microseconds

P1 Hash value of cursor
P2 Mutex value (top 2 bytes contains SID holding mutex in exclusive mode, and bottom two bytes usually hold the value 0)

select chr(bitand(p1,-16777216)/16777215)|| chr(bitand(p1,16711680)/65535) "sid locking" from v$session_wait
where event = 'cursor: pin X';

P3 Mutex where (an internal code locator) OR'd with Mutex Sleeps

#-#cursor: pin X#-#
#-#Data Guard: process clean up#-#

During Data Guard process termination, Data Guard will wait for one second for process cleanup to complete.
Data Guard: process exit

During Data Guard process termination, Data Guard will wait for a process to exit before attempting any process cleanup that may be required. It will sleep for one second between each check for process exit.
Data Guard Broker: single instance

The Data Guard Broker (DMON) process waits for the other instances in this cluster to complete shutdown before continuing with the broker operation.

Wait Time: Depends on the number of instances, but not exceeding 30 seconds times the number of instances
#-#Data Guard: process clean up#-#
#-#db file parallel read#-#

This happens during recovery. It can also happen during buffer prefetching, as an optimization (rather than performing multiple single-block reads). Database blocks that need to be changed as part of recovery are read in parallel from the database.

Wait Time: Wait until all of the I/Os are completed

p1 files This indicates the number of files to which the session is reading
p2 blocks This indicates the total number of blocks to be read
p3 requests This indicates the total number of I/O requests, which will be the same as blocks

#-#db file parallel read#-#
#-#db file parallel write#-#

This event occurs in the DBWR. It indicates that the DBWR is performing a parallel write to files and blocks. When the last I/O has gone to disk, the wait ends.

Wait Time: Wait until all of the I/Os are completed
p1 requests This indicates the total number of I/O requests, which will be the same as blocks
p2 interrupt xx
p3 timeout This indicates the timeout value in centiseconds to wait for the IO completion.

#-#db file parallel write#-#
#-#db file single write#-#

This event is used to wait for the writing of the file headers.

Wait Time: The wait time is the actual time it takes to do the I/O
p1 file#
p2 block#
p3 blocks This is the number of blocks that the session is trying to write in file# starting at block#

#-#db file single write#-#
#-#DFS db file lock#-#

This event occurs only for the DBWR in the Oracle Real Application Cluster. Each DBWR of every instance holds a global lock on each file in shared mode. The instance that is trying to offline the file will escalate the global lock from shared to exclusive. This signals the other instances to synchronize their SGAs with the control file before the file can be taken offline. The name of this lock is DF

Wait Time: 1 second in loop. The DBWR is waiting in a loop (sleep, check) for the other instances to downgrade to NULL mode. During this time, the DBWR cannot perform other tasks such as writing buffers.
p1 file

#-#DFS db file lock#-#
#-#DFS lock handle#-#

The session waits for the lock handle of a global lock request. The lock handle identifies a global lock. With this lock handle, other operations can be performed on this global lock (to identify the global lock in future operations such as conversions or release). The global lock is maintained by the DLM.

Wait Time: The session waits in a loop until it has obtained the lock handle from the DLM.
Inside the loop there is a wait of 0.5 seconds.

p1 name The name or "type" of the enqueue or global lock can be determined by looking at the two high order bytes of P1
select chr(bitand(p1,-16777216)/16777215)|| chr(bitand(p1,16711680)/65535) "Lock" from v$session_wait
where event = 'DFS enqueue lock acquisition';
p1 mode select chr(bitand(p1,-16777216)/16777215)|| chr(bitand(p1, 16711680)/65535) "Lock", bitand(p1, 65535) "Mode"
from v$session_wait where event = 'DFS enqueue lock acquisition';
p2 id1 The first identifier (id1) of the enqueue or global lock takes its value
p3 id2 The second identifier (id2) of the enqueue or global lock takes its value from P3

The meaning of the identifier id1 and id2 depends on the name (P1).


The session needs to get the lock handle.
#-#DFS lock handle#-#
#-#direct path read#-#

During Direct Path operations the data is asynchronously read from the database files. At some stage the session needs to make sure that all outstanding asynchronous I/O have been completed to disk. This can also happen if during a direct read no more slots are available to store outstanding load requests (a load request could consist of multiple I/Os).

Wait Time: 10 seconds. The session will be posted by the completing asynchronous I/O. It will never wait the entire 10 seconds. The session waits in a tight loop until all outstanding I/Os have completed.

p1 descriptor address This is a pointer to the I/O context of outstanding direct I/Os on which the session
is currently waiting
p2 first dba The dba of the oldest I/O in the context referenced by the descriptor address
p3 block cnt Number of valid buffers in the context referenced by the descriptor address

#-#direct path read#-#
#-#direct path write#-#

During Direct Path operations, the data is asynchronously written to the database files. At some stage the session needs to make sure that all outstanding asynchronous I/O have been completed to disk. This can also happen if, during a direct write, no more slots are available to store outstanding load requests (a load request could consist of multiple I/Os).

Wait Time: 10 seconds. The session will be posted by the completing asynchronous I/O. It will never wait
the entire 10 seconds. The session waits in a tight loop until all outstanding I/Os have completed.

p1 descriptor address This is a pointer to the I/O context of outstanding direct I/Os on which
the session is currently waiting
p2 first dba The dba of the oldest I/O in the context referenced by the descriptor address
p3 block cnt Number of valid buffers in the context referenced by the descriptor address

#-#direct path write#-#
#-#dispatcher shutdown#-#

During shutdown immediate or normal, the shutdown process must wait for all the dispatchers to shutdown. As each dispatcher is signaled, the session that causes the shutdown is waits on this event until the requested dispatcher is no longer alive.

Wait Time: 1 second
waited Indicates the cumulative wait time. After 5 minutes, the session writes to the alert and trace files
to indicate that there might be a problem.

#-#dispatcher shutdown#-#
#-#dispatcher timer#-#

This basically means that the dispatcher is idle and waiting for some work to arrive.

Wait Time: 60 seconds
p1 sleep time The intended sleep time. The dispatcher will return to work sooner if it is posted by either
data arriving on the network or by a post from a shared server process to send data back to the client.

#-#dispatcher timer#-#
#-#duplicate cluster key#-#

It is possible for a race condition to occur when creating a new cluster key. If it is found that another process has put the cluster key into the data/index block, then the session waits and retries. The retry should then find a valid cluster key.

Wait Time: 0.01 seconds
p1 dba The dba of the block into which the session is trying to insert a cluster key

#-#duplicate cluster key#-#
#-#enq: OW - initialization#-#

A session will wait on this event if it is trying to initialize the database wallet, and another session has already begun an initialization.

Wait Time: Total time necessary to initialize the wallet context

Parameters: None
#-#enq: OW - initialization#-#
#-#enq: OW - termination#-#

A session will wait on this event if it is trying to terminate the database wallet, and another session has already begun a termination.

Wait Time: Total time necessary to deallocate memory used by the wallet context and terminate the context.

Parameters: None
#-#enq: OW - termination#-#
#-#flashback buf free by RVWR#-#

This wait event only occurs when Flashback Database is turned on. A session waits for recovery writer (RVWR) to write flashback data to the flashback logs on disk because the buffers are full. Until RVWR can free up the buffers, the session may need to wait.

If this event becomes a top wait event for the database, it is typically because the file system or storage system for the Flash Recovery Area does not support enough bandwidth for Oracle to write the flashback database logs. Refer to the Flashback Database section in Oracle Database Backup and Recovery Basics for tuning considerations.

Wait Time: 1 second

Parameters: None
#-#flashback buf free by RVWR#-#
#-#free global transaction table entry#-#

The session is waiting for a free slot in the global transaction table (used by the Distributed Database option).
It will wait for 1 second and try again.

Wait Time: 1 second

p1 tries The number of times the session tried to find a free slot in the global transaction table

#-#free global transaction table entry#-#
#-#free process state object#-#

Used during the creation of a process. The session will scan the process table and look for a free process slot.
If none can be found, PMON is posted to check if all the processes currently in the process table are still alive.
If there are dead processes, then PMON will clean them and make the process slot available to new processes.
The waiting process will then rescan the process table to find the new slot.

Wait Time: 1 second

Parameters: None
#-#free process state object#-#
#-#GCS lock open S#-#

The session waits for a resource get in SHARED mode on the block identified by file# and block#.

Wait Time: 1 second

p1 file#
p2 block#
p3 class

#-#GCS lock open S#-#
#-#GCS lock open X#-#

The session waits for a resource get in EXCLUSIVE mode on the block identified by file# and block#.

Wait Time: 1 second

p1 file#
p2 block#
p3 lenum The relative index number into V$GC_ELEMENT.

#-#GCS lock open X#-#
#-#gcs remastering wait for drop pkey#-#

A session dropping an object waits on the lock manager daemon (LMD) to remove the object's affinity to an instance.

Wait Time: 20 centi-seconds

p1 pkey The object id of the database object being dropped

#-#gcs remastering wait for drop pkey#-#
#-#global cache busy#-#

The session waits to convert a buffer from Shared Current to Exclusive Current status.

Wait Time: 1 second

p1 file#
p2 block#

#-#global cache busy#-#
#-#global cache lock cleanup#-#

PMON is waiting for an LCK process to cleanup the lock context after a foreground process died
while doing a global cache lock operation.

Wait Time: 1 second

p1 file#
p2 block#

#-#global cache lock cleanup#-#
#-#global cache freelist#-#

All releasable locks are used and a new one has been requested. To make a resource element available,
a resource element is pinged.

Wait Time: The duration of the resource get operation to ping the resource element

Parameters: None
#-#global cache freelist#-#
#-#inactive session#-#

This event is used for two purposes:

* Switching sessions :
If a time-out period has been specified, then wait that amount of time for the session to be detached.

* Killing sessions : From either KILL SESSION or internal request. Having posted a session that it should kill itself,
wait for up to 1 minute for the session to terminate.

Wait Time: 1 second

p1 session#
p2 waited

#-#inactive session#-#
#-#inactive transaction branch#-#

The session waits for a transaction branch that is currently used by another session.

Wait Time: 1 second

p1 branch# The serial number of the transaction for which the session is waiting
p2 waited

#-#inactive transaction branch#-#
#-#index block split#-#

While trying to find an index key in an index block, Oracle noticed that the index block was being split. Oracle will wait for the split to finish and try to find the key again.

Wait Time: The session will yield the CPU, so there is no actual waiting time

p1 rootdba The root of the index
p2 level This is the level of the block that the session is trying to split in the index. The leaf blocks are
level 0. If the level is > 0, it is a branch block. (The root block can be considered a special
branch block).
p3 childdba The block that the session is trying to split

#-#index block split#-#
#-#instance state change#-#

The session waits for SMON to enable or disable cache or transaction recovery. This usually happens during
ALTER DATABASE OPEN or CLOSE.

Wait Time: Wait time depends on the amount of time the action takes (that is, the amount of recovery needed)

p1 layer This value can be 1 or 2. If 1, it means that the transaction layer wants transaction recovery to be
performed. If 2, it means that cache recovery will be performed.
p2 value This value can be 0 (disable) or 1 (enable)
p" waited The number of seconds waited so far

#-#instance state change#-#
#-#io done#-#

The session waits for an I/O to complete or it waits for a slave process to become available to submit the I/O request.
This event occurs on platforms that do not support asynchronous I/O.

Wait Time: 50 milliseconds

p1 msg ptr A pointer to the I/O request

#-#io done#-#
#-#kcl bg acks#-#

The session waits for the background LCK process(es) to finish what they are doing. For example:

* Lock recovery
* Initializing the locks (start up)
* Finalizing the locks (shut down)

Wait Time: 10 seconds

p1 count The number of LCK processes that have finished
p2 loops The number times the process had to wait for the LCK processes to finish what they were doing

#-#kcl bg acks#-#
#-#ksxr wait for mount shared#-#

The cross instance broadcast facility of this Oracle instance is waiting for the database mount in shared mode to complete.

Wait Time: The time taken for the instance to mount. An indefinite wait on this event implies that the instance startup is hanging.
#-#ksxr wait for mount shared#-#
#-#ktm: instance recovery#-#

The session waits for SMON to finish the instance, transaction recovery, or sort segment cleanup.

Wait Time: The wait time can vary and depends on the amount of recovery needed

p1 undo segment# If the value is 0, SMON is probably performing instance recovery.
If P1 > 0, use this query to find the undo segment:

select cpu_distribution_asdb.txt db_buffer_catg_asdb.txt db_buffer_distrib_poolasdb.txt ff.1 ff.2 ff.org fil_tmp.txt img_dr.pl list_init_param.txt resource_waits_asdb_042815.txt sample_delta_w_POLDB1.04191426 sample_sql_w_POLDB1.04191426 sample_sys_w_POLDB1.04191426 sample_w_txt_POLDB1.04191426 sem_sql_w_asdb.txt shared_pool_free_list_asdb.txt slp_asdb.txt system_event_asdb_050216.txt xx from v$rollstat where usn = undo segment#;


#-#ktm: instance recovery#-#
#-#latch activity#-#

This event is used as part of the process of determining whether a latch needs to be cleaned.

Wait Time: 0.05 to 0.1 seconds

p1 address The address of the latch that is being checked
p2 number The latch number of the latch that has activity. To find more information on the latch, use :

select cpu_distribution_asdb.txt db_buffer_catg_asdb.txt db_buffer_distrib_poolasdb.txt ff.1 ff.2 ff.org fil_tmp.txt img_dr.pl list_init_param.txt resource_waits_asdb_042815.txt sample_delta_w_POLDB1.04191426 sample_sql_w_POLDB1.04191426 sample_sys_w_POLDB1.04191426 sample_w_txt_POLDB1.04191426 sem_sql_w_asdb.txt shared_pool_free_list_asdb.txt slp_asdb.txt system_event_asdb_050216.txt xx from v$latchname where latch# = number;

p3 process# If this is 0, it is the first phase of the in-flux tests

#-#latch activity#-#
#-#library cache load lock#-#

The session tries to find the load lock for the database object so that it can load the object. The load lock is always
obtained in Exclusive mode, so that no other process can load the same object. If the load lock is busy the session will
wait on this event until the lock becomes available.

Wait Time: 3 seconds (1 second for PMON)

p1 object address Address of the object being loaded
p2 lock address Address of load lock being used
p3 mask Indicates which data pieces of the object that needs to be loaded

#-#library cache load lock#-#
#-#library cache lock#-#

This event controls the concurrency between clients of the library cache. It acquires a lock on the object handle
so that either:

* One client can prevent other clients from accessing the same object
* The client can maintain a dependency for a long time (for example, no other client can change the object)

This lock is also obtained to locate an object in the library cache.

Wait Time: 3 seconds (1 second for PMON)

p1    handle address       Address of the object being loaded
p2    lock address         Address of the load lock being used. This is not the same thing as a latch or an enqueue,
                           it is a State Object.
p3    mode                 Indicates the data pieces of the object which need to be loaded

#-#library cache lock#-#
#-#library cache shutdown#-#

The process shutting down the instance waits for sessions to complete before proceeding with library cache shutdown.
#-#library cache shutdown#-#
#-#LMON global data update#-#

The rolling migration operation is waiting for a response from LMON to acknowledge the global data was updated.

Wait Time: The time it takes for LMON to publish/retrieve the global data associated with a

Parameters: None
#-#LMON global data update#-#
#-#lock manager wait for remote message#-#

The lock manager waits for a message from a remote lock manager in the same configuration.

Wait Time: The elapsed time of the wait

p1 waittime The elapsed time of the actual wait

#-#lock manager wait for remote message#-#
#-#log file sequential read#-#

Waiting for the read from this logfile to return. This is used to read redo records from the log file.

Wait Time: Time it takes to complete the physical I/O (read)

p1 log# The relative sequence number of the logfiles within a log group (used only when dumping the logfiles)
p2 block#
p3 blocks The number of blocks to read

#-#log file sequential read#-#
#-#log file single write#-#

Waiting for the write to this logfile to complete. This event is used while updating the header of the logfile.
It is signaled when adding a log file member and when incrementing sequence numbers.

Wait Time: Time it takes for the physical I/O (write) to complete

p1 log# This is the number of the group/log to which the session is currently writing
p2 block#
p3 blocks The number of blocks to write

#-#log file single write#-#
#-#log file switch (private strand flush incomplete)#-#

User sessions trying to generate redo, wait on this event when LGWR waits for DBWR to complete flushing redo from IMU
buffers into the log buffer; when DBWR is complete LGWR can then finish writing the current log, and then switch log files.

Wait Time: 1 second

Parameters: None
#-#log file switch (private strand flush incomplete)#-#
#-#log switch/archive#-#

Used as part of the ALTER SYSTEM ARCHIVE LOG CHANGE scn statement.
The session waits for the current log from all open threads to be archived.

Wait Time: Wait for up to 10 seconds

p1 thread# The thread number of the thread that is currently archiving its current log

#-#log switch/archive#-#

#-#complex view log#-#
Complex views

A modifiable join view  or complex view is a view that contains more than one table 
in the top-level FROM clause of the SELECT statement, and that does not contain any of the following:

    * DISTINCT operator
    * Aggregate functions: AVG, COUNT, GLB, MAX, MIN, STDDEV, SUM, or VARIANCE
    * Set operations: UNION, UNION ALL, INTERSECT, MINUS
    * GROUP BY or HAVING clauses
    * START WITH or CONNECT BY clauses
    * ROWNUM pseudocolumn 


Complex views can be constructed on more than one base table. In particular, complex views can contain:

    * join conditions
    * a group by clause
    * a order by clause 

You cannot perfor DML against a complex view.  A general rule of thumb is that if a base table is key-preserved,
 DML can be performed against the view.

the following definition from resume : 

"If the primary key columns of the base table you want to update still have unique values in the view, 
[then] the base table is updatable." 

To enable DML operations on complex views one needs to write INSTEAD OF triggers 
to tell Oracle how the changes relate to the base table(s). 


Examples:

CREATE VIEW sample_complex_view AS
    SELECT emp.empno, emp.ename, emp.job, emp.deptno, dept.dname, dept.loc
      FROM emp, dept;

CREATE VIEW sample_complex_view AS
  SELECT emp.empno, emp.ename, emp.job, emp.deptno, dept.dname, dept.loc
  FROM emp, dept
 WHERE emp.deptno = dept.deptno;

#-#complex view log#-#
#-#materialized view log#-#
When a materialized view log is created on a master table, Oracle creates a table named mlog$_<master_table_name>. This 
table is the materialized view log.  Oracle uses this table to store a record of each change made to the master table.  
When a materialized view that is mastered by that master table is refreshed in fast mode, it queries the change records 
stored in the materialized view log to determine which rows to pull from the master table and replace in the materialized 
view.  In order to find out what materialized view type(s) are supported by a materialized view log, use view 
dba_mview_logs or smenu 'mvw -l'

In Oracle8/Oracle9i, we can also use rowid materialized view log if the master table does not contain a Primary key.  
As the default in oracle8/oracle9i for materialized view log is primary key, creating materialized view log without the 
WITH ROWID option on a master table without a primary key will result ora-12014:

Using rowid materialized view log in summary management:
--------------------------------------------------------
Rowid materialized view logs in data warehouse/summary management are used to support fast refresh of join view (MJV), 
aggregate (MAV), and nested materialized views; this is the only materialized view log type supported in this environment. 
These materialized view logs are often created with filter columns. These columns are additional, non-primary key columns 
for which the materialized view log change record captures values.

In relation to materialized view logs, when creating a materialized view in a Datawarehouse environment and the materialized
view contains aggregates with a single table, a materialized view log must contain all columns referenced in the 
materialized view and must have been created with the INCLUDING NEW VALUES clause:

CREATE MATERIALIZED VIEW log on FACT   with rowid (store_key,time_key,dollar_sales)  including new values; 


Using Primary key materialized view log :
-----------------------------------------
When creating a primary key materialized view log, you must have a valid primary key on master table. In case you try 
to create a primary key materialized view when master table do not have primary key, error ORA-12014 will be raised.

  Name                                      Null?    Type
    ----------------------------------------- -------- ---------------
    EMPNO                                              NUMBER(4)  
    SNAPTIME$$                                         DATE
    DMLTYPE$$                                          VARCHAR2(1)
    OLD_NEW$$                                          VARCHAR2(1)
    CHANGE_VECTOR$$                                    RAW(255)
    
EMPNO is the primary of the master table. 

Since Oracle8 Primary key is the default for materialized view logs. In replication environments it should be used unless
any of the exceptions signalled at "Using rowid materialized view log in distributed environment" section. 
Primary key materialized view log do have applications on a summary management environments.


Using Primary key and rowid materialized view log
-----------------------------------------------------

We can create materialized view log with both primary key and rowid
 
 SQL>create materialized view log on dept with rowid,primary key;
 SQL> desc mlog$_dept;
 
    Column Name                    Null?    Type
    ------------------------------ -------- ----
    DEPTNO                                  NUMBER(2)
    M_ROW$$                                 VARCHAR2(255)
    SNAPTIME$$                              DATE
    DMLTYPE$$                               VARCHAR2(1)
    OLD_NEW$$                               VARCHAR2(1)
    CHANGE_VECTOR$$                         RAW(255)

We can see that both rowid and primary key of new/modified/deleted row will be recorded. This configuration may be used 
when we have  materialized view site in different version.

Types of Materialized Views
-------------------------------

There are different ways to distinguish one type of materialized views from another. One of this classification is based 
on the environment where the materialized view is involved and there we can distinguish different types:

- Distributed environments:
    
  * Primary Key: The materialized view includes the columns that conform the master table primary key. The materialized 
                 will identify rows modified at master site by their primary key.
    
  * Rowid      : The materialized view includes a column that  will stores master table rowid. The materialized view will 
                 identify rows modified at master site by their primary key.

- Datawarehousing environment:

  * Materialized Views with Aggregates (Aggregate): The columns that conforms the query used to create the materialized 
                 view contains aggregate.
                 
  * Materialized Views Containing Only Joins (Join View): The query used to create the query is a join used 
                 to precalculate costs joins.
                 
  * Nested Materialized Views (Complex) : A materialized view whose definition is based on another materialized view.

Materialized views in a distributed environment
---------------------------------------------------

When a materialized view is created, several additional mechanisms are created at the materialized view site to support 
the materialized view. Specifically, a base table, at least one index, and possibly a view are created. If you create an
updatable materialized view, then an internal trigger and a local log (the updatable materialized view log) are also 
created at the materialized view site.  In addition to this an index called I_SNAP$_<materialized_view_name> will be
created for base table. 
If an updatable MV is created, an updatable materialized view log (USLOG$_<materialized_view_name>) is used to determine 
which rows must be overwritten or removed from a materialized view during a fast refresh.  A read-only MV does not create 
this log, and Oracle does not use this log during a complete refresh because, in this case, the entire MV is replaced.

Primary key materialized view in distributed environment
------------------------------------------------------------

For a fast refresh of a primary key materialized view, it is required that the materialized view log contains the primary 
key of the master table.  In case the materialized view log does not contain primary key information an error ORA-12031 
will be raised. 
The main benefit of primary key materialized views is that they allow the reorganization of the master tables without 
requiring a complete refresh from master tables after the reorganization, unlike the rowid materialized view. This is 
because the primary key record identifier does not change during master table reorganization, where as the rowid does.  
An example of master table reorganization with a primary key materialized view follows:

On distributed environments, rowid materialized views must be based on a single
table and cannot contain any of the following:

 - Distinct or aggregate functions
 - GROUP BY or CONNECT BY clauses
 - Subqueries
 - Joins
 - Set operations
#-#materialized view log#-#
#-#optimizer stats update retry#-#

When concurrent sessions try to update optimizer statistics for the same object, all of them except the one that successfully acquired all necessary locks/pins on the library/row cache entries, wait on this wait event and then retry locking after a short period of time. In addition to explicit statistics gathering and maintenance operations using the DBMS_STATS package, Oracle database itself may try to update statistics for some objects, either on behalf of the user or for its own maintenance purposes.

Wait Time: 10 ms

Parameters: None
#-#optimizer stats update retry#-#
#-#pending global transaction(s)#-#

This event should happen only during testing. The session waits for pending transactions to clear.

Wait Time: 30 seconds

p1 scans Number of times the session has scanned the PENDING_TRANS$ table

#-#pending global transaction(s)#-#
#-#pipe get#-#

The session waits for a message to be received on the pipe or for the pipe timer to expire.

Wait Time: There is a 5 second wake up (check) and the pipe timer set by the user
p1 handle address The library cache object handle for this pipe
p2 buffer length The length of the buffer
p3 timeout The pipe timer set by the user

#-#pipe get#-#
#-#pipe put#-#

The session waits for the pipe send timer to expire or for space to be made available in the pipe.

Wait Time: There is the 5 second wakeup (check) and the user-supplied timeout value
p1 handle address The library cache object handle for this pipe
p2 record length The length of the record or buffer that has been put into the pipe
p3 timeout The pipe timer set by the user

#-#pipe put#-#
#-#PL/SQL lock timer#-#

This event is called through the DBMSLOCK.SLEEP procedure or USERLOCK.SLEEP procedure. This event will most likely originate from procedures written by a user.

Wait Time: The wait time is in hundredths of seconds and is dependent on the user context

p1 duration The duration that the user specified in the DBMS_LOCK.SLEEP or USER_LOCK.SLEEP procedures

#-#PL/SQL lock timer#-#
#-#pmon timer#-#

This is the main wait event for PMON. When PMON is idle, it is waiting on this event.

Wait Time: Up to 3 seconds, if not posted before

p1 duration The actual amount of time that the PMON is trying to sleep

#-#pmon timer#-#
#-#prewarm transfer retry#-#

Release a hash latch, then wait under this event before attempting to re-acquire the hash latch.

Wait Time: 10ms

Parameters: None
#-#prewarm transfer retry#-#
#-#prior process spawner to be cleaned up#-#

When a prior process has died while spawning a background, the current process which is trying to spawn
new a background must wait until the prior process state is cleaned up.

Wait Time: Usually 3 - 10 seconds

p1 process_pid process identifier (see V$PROCESS.PID) of the process whose state needs to be cleaned up.
p2 process_sno process serial number (see V$PROCESS.SERIAL#) of the process whose state needs to be cleaned up.

#-#prior process spawner to be cleaned up#-#
#-#process startup#-#

Wait for a shared server, Dispatcher, or other background process to start.

Wait Time: Wait up to 1 second for a background process to start. If timed out, then re-wait until 5 minutes
have passed and signal an error. If the process has started, the event will acknowledge this.

p1 type The process type that was started
p2 process# The process number of the process being started
p3 waited Cumulative time waited for the process to start

#-#process startup#-#
#-#PX Deque wait#-#

The process is waiting for a message during a parallel execute.

Wait Time: The wait time depends on how quickly the message arrives. Wait times can vary, but it will normally be a short period of time.
p1 reason The reason for dequeuing
p2 sleeptime The amount of time that the session slept
p3 loop The total number of times that the session has slept

#-#PX Deque wait#-#
#-#PX qref latch#-#

Each parallel execution process has a parallel execution qref latch, which needs to be acquired before
the queue buffers can be manipulated.

Wait Time: Wait up to 1 second

p1 function Indicates the type of wait that the session is doing
p2 sleeptime The amount of time that the session waits (in hundredths of a second)
p3 qref The address of the process queue for which the session is waits

#-#PX qref latch#-#
#-#PX server shutdown#-#

During normal or immediate shutdown the parallel execution slaves are posted to shutdown cleanly. If any parallel execution slaves are still alive after 10 seconds, they are killed.

Wait Time: Wait up to 0.5 seconds

p1 nalive The number of parallel execution slaves that are still running
p2 sleeptime The total sleeptime since the session started to wait on this event
p3 loop The number of times the session waited for this event

#-#PX server shutdown#-#
#-#PX signal server#-#

This event occurs only in Exclusive mode. The query coordinator is signalling the Query Slaves that an error has occurred.

Wait Time: 0.5 seconds

p1 serial The serial number of the slave process queue
p2 error The error that has occurred
p3 nbusy The number of slave processes that are still busy

#-#PX signal server#-#
#-#Streams AQ: waiting for messages in the queue#-#

The session is waiting on an empty OLTP queue (Advanced Queuing) for a message to arrive so that the session
can dequeue that message.

Wait Time: The amount of time that the session wants to wait is determined by the parameter wait time

p1 queue id The ID of the OLTP queue for which this session is waiting
p2 process# The process number of the process in which this session runs
p3 wait time The intended wait time for this session

#-#Streams AQ: waiting for messages in the queue#-#
#-#rdbms ipc message#-#

The background processes (LGWR, DBWR, LMS0) use this event to indicate that they are idle and are waiting
for the foreground processes to send them an IPC message to do some work.

Wait Time: Up to 3 seconds. The parameter timeout shows the true sleep time.

p1 timeout The amount of time that the session waits for an IPC message

#-#rdbms ipc message#-#
#-#rdbms ipc message block#-#

This event indicates that all message blocks are in use and that the session had to wait for a message block
to become available.

Wait Time: Wait up to 60 seconds

Parameters: None
#-#rdbms ipc message block#-#
#-#rdbms ipc reply#-#

This event is used to wait for a reply from one of the background processes.

Wait Time: The wait time is specified by the user and is indicated by the parameter timeout.

p1 from_process The background process for which the session is waiting. The wait is for a reply to an IPC message
sent by the session.
p2 timeout The amount of time in seconds that this process will wait for a reply

#-#rdbms ipc reply#-#
#-#read by other session#-#

This event occurs when a session requests a buffer that is currently being read into the buffer cache by another session. Prior to release 10.1, waits for this event were grouped with the other reasons for waiting for buffers under the 'buffer busy wait' event

Wait Time: Time waited for the buffer to be read by the other session (in microseconds)

p1 file#
p2 block#
p3 class#

#-#read by other session#-#
#-#resmgr: become active#-#

The session is waiting for a resource manager active session slot. This event occurs when the resource manager is enabled and the number of active sessions in the session's current consumer group exceeds the current resource plan's active session limit for the consumer group. To reduce the occurrence of this wait event, increase the active session limit for the session's current consumer group.

Wait Time: The time the session waited to be allocated an active session slot

p1 location location of the wait

#-#resmgr: become active#-#
#-#resmgr: cpu quantum#-#

The session is waiting to be allocated a quantum of cpu. This event occurs when the resource manager is enabled and is throttling CPU consumption. To reduce the occurrence of this wait event, increase the CPU allocation for the sessions's current consumer group.

Wait Time: The time the session waited to acquire a CPU quantum

p1 location Location of the wait

#-#resmgr: cpu quantum#-#
#-#rolling migration: cluster quisce#-#

This is the wait event that instances wait on when cluster is about to start a rolling migration. The instances are waiting for any privileged operations that blocks rolling migration to complete before allowing rolling migration.

Wait Time: 1 second

p1 location Its value will be 1 if the wait is for completion of the privileged operations so that
a rolling upgrade/downgrade can start.
Its value will be 2 if the wait is for completion of the rolling upgrade/downgrade on all
the nodes in the cluster.
P1 waits The number of seconds spent waiting at the current location.

#-#rolling migration: cluster quisce#-#
#-#row cache lock#-#

The session is trying to get a data dictionary lock.

Wait Time: Wait up to 60 seconds.

p1 cache id The CACHE# column value in the V$ROWCACHE view
p2 mode 1 Null mode
2 Sub-Share
3 Sub-Exclusive
4 Share
5 Share/Sub-Exclusive
6 Exclusive
select bithand(p2,65535) from v$session_wait where event = 'row cache lock';
p3 request The pipe timer set by the user

#-#row cache lock#-#
#-#sbtbufinfo#-#

This function is called when Oracle needs to discover the size, and number, of I/O buffers that have been allocated
by the SBT layer. It should be very fast and never block.

Wait Time: Less than one millisecond

Parameters: None
#-#sbtbufinfo#-#
#-#sbtgetbuf#-#

This function obtains one I/O buffer that Oracle will use for I/O during a backup job.

Wait Time: Less than one millisecond

Parameters: None
#-#sbtgetbuf#-#
#-#sbtmapbuf#-#

This is an internal function used to facilitate multi-process buffer management. It should be very fast and never block.

Wait Time: Less than one millisecond

Parameters: None
#-#sbtmapbuf#-#
#-#sbtrelbuf#-#

This function releases an I/O buffer that has been already processed during a restore job, so that the SBT layer can fill it with more data. It should be very fast and never block.

Wait Time: Less than one millisecond

Parameters: None
#-#sbtrelbuf#-#
#-#scginq AST call#-#

Called by the session to find the highest lock mode that is held on a resource.

Wait Time: Wait up to 0.2 seconds, but the wait will continue until the NULL mode Acquisition AST has fired.

Parameters: None
#-#scginq AST call#-#
#-#SGA: allocation forcing component growth#-#

Process waiting on an immediate mode memory transfer with auto-tune SGA after a 4031 for MMAN to get the memory and post it.

Wait Time: 10 msec

Parameters: None
#-#SGA: allocation forcing component growth#-#
#-#SGA: MMAN sleep for component shrink#-#

MMAN to wait and post itself for satisfying an auto-tuned memory request while trying to fully free a component's quiesced granules. In Release 10.1, the name of this event was 'wait for SGA component shrink'.

Wait Time: 10 msec

P1 component_id (corresponding to the memory pool)
P2 Current size in granules
P3 Target size in granules

#-#SGA: MMAN sleep for component shrink#-#
#-#MEMORY_SIZE#-#
#-#SGA 11g#-#
For 11g, here is how internally the memory management parameters controls the memory structure if MEMORY_TARGET is set to a non-zero value:

    -If SGA_TARGET and PGA_AGGREGATE_TARGET are not set, it will distribute the total server memory 
        in a fixed ratio as 60% and 40% and assign it to SGA_TARGET and PGA_AGGREGATE_TARGET respectively.

    -If SGA_TARGET and PGA_AGGREGATE_TARGET are set, they will be considered the minimum values for 
        the sizes of SGA and the PGA respectively (But sum of SGA_TARGET and PGA_AGGREGATE_TARGET 
        should be less than or equal to MEMORY_TARGET).

    -If SGA_TARGET is set and PGA_AGGREGATE_TARGET is not set, we will still auto-tune both parameters. 
        PGA_AGGREGATE_TARGET will be initialized to a value of (MEMORY_TARGET-SGA_TARGET).

    -If PGA_AGGREGATE_TARGET is set and SGA_TARGET is not set, we will still auto-tune both parameters. 
        SGA_TARGET will be initialized to a value of min(MEMORY_TARGET-PGA_AGGREGATE_TARGET, SGA_MAX_SIZE 
        (if set by the user)).

Note: MEMORY_TARGET can be dynamically increased until MEMORY_MAX_TARGET without bouncing the instance. 
      Regarding reducing the size of MEMORY_TARGET, it is just a request to Oracle server 
      which will be honoured in the course of time.
#-#SGA 11g#-#
#-#MEMORY_SIZE#-#
#-#KGH: NO ACCESS#-#
KGH: NO ACCESS : this is a case of shared pool granules partially freed for use by the db cache and waiting for the rest 
of the granule content to be unpinned so that the entire granule can become a cache granule.

Use the following query to seem how much of the shared pool is not usable by library objects :

     "select sum(bytes)/1048576 MB from v$sgastat where pool = 'shared pool' and name = 'KGH: NO ACCESS';"

You can also dump the granule distribution with the following:

    "alter session set events 'immediate trace name DUMP_ALL_COMP_GRANULE_ADDRS level 1'; "


#-#KGH: NO ACCESS#-#
#-#SGA: sga_target resize#-#
Memory resize requests wait while sga target is being resized.In Release 10.1, the name of this event was 'wait for sga_target resize'.

Wait Time: 10 msec

Parameters: None
single-task message

When running single task, this event indicates that the session waits for the client side of the executable.

Wait Time: Total elapsed time that this session spent in the user application

Parameters: None
#-#SGA: sga_target resize#-#
#-#smon timer#-#

This is the main idle event for SMON. SMON will be waiting on this event most of the time until it times out or is posted by another process.

Wait Time: 5 minutes (300 seconds)

p1 sleeptime The amount of time that SMON tries to wait on this event in seconds
p2 failed The number of times SMON was posted when there some kind of error

#-#smon timer#-#
#-#SQL*Net message from client#-#

The server process (foreground process) waits for a message from the client process to arrive.

Wait Time: The time it took for a message to arrive from the client since the last message was sent to the client

p1 driver id The address of the disconnect function of the driver that is currently being used.
p2 #bytes The number of bytes received by the server (foreground process) from the client.

#-#SQL*Net message from client#-#
#-#SQL*Net message from dblink#-#

The session waits while the server process (foreground process) receives messages over a database link from another server process.

Wait Time: The time it took for a message to arrive from another server (foreground process) since a message was sent to the other foreground process.
p1 driver id The address of the disconnect function of the driver that is currently being used.
p2 #bytes The number of bytes received by the server (foreground process) from another foreground process
over a database link.

#-#SQL*Net message from dblink#-#
#-#SQL*Net more data from client#-#

The server is performing another send to the client. The previous operation was also a send to the client.

p1 driver id The address of the disconnect function of the driver that is currently being used.
p2 Wait Time: The time waited depends on the time it took to receive the data (including the waiting time)
p3 #bytes The number of bytes received from the client

#-#SQL*Net more data from client#-#
#-#SQL*Net more data from dblink#-#

The foreground process is expecting more data from a data base link.

p1 driver id The address of the disconnect function of the driver that is currently being used.
p2 Wait Time: The total time it takes to read the data from the database link (including the waiting time
for the data to arrive)
p3 #bytes The number of bytes received

#-#SQL*Net more data from dblink#-#
#-#timer in sksawat#-#

The session waits for the Archiver (ARCH) asynchronous I/O to complete.

Wait Time: 0.01 seconds

Parameters: None
#-#timer in sksawat#-#
#-#transaction#-#

Wait for a blocking transaction to be rolled back. Continue waiting until the transaction has been rolled back.

Wait Time: 1 second
p1 undo seg# The rollback segment ID
select chr(bitand(p1,-16777216)/16777215)|| chr(bitand(p1,16711680)/65535) "undo"
from v$session_wait where event = 'transaction'
p1 slot# The slot ID inside the rollback segment
select bithand(p1,65535) from v$session_wait where event = 'transaction'

p2 wrap# The sequence number that is incremented for each transaction
p3 count The number of times that the session has waited on this transaction

#-#transaction#-#
#-#unbound tx#-#

The session waits to see if there are any transactions that have been started but do not have a Rollback Segment
associated with them.

Wait Time: 1 second

Parameters: None
#-#unbound tx#-#
#-#undo_retention publish retry#-#

This wait can occur for two reasons. A session issuing an ALTER SYSTEM SET UNDO_RETENTION may wait on this event wait while a cluster reconfiguration takes place. Or the background process MMNL may wait for cluster reconfiguration while attempting to determine the max UNDO_RETENTION.

Wait time: 1 second

P1 Identifies where the retry is happening.
Id = 1 retry while publishing into the max undo_retention namespace.
Id = 2 retry while iterator accessing the max undo_retention namespace
P2 Retry count (maximum number of retries is 5)

#-#undo_retention publish retry#-#
#-#undo segment recovery#-#

PMON is rolling back a dead transaction. The wait continues until rollback finishes.

Wait Time: 3 seconds
p1 segment# The ID of the rollback segment that contains the transaction that is being rolled back
p2 tx flags The transaction flags (options) set for the transaction that is being rolled back

#-#undo segment recovery#-#
#-#undo segment tx slot#-#

Wait for a transaction slot to become available within the selected rollback segment.
Continue waiting until the slot is available.

Wait Time: 1 second

segment# The ID of the rollback segment that contains the transaction that is being rolled back

#-#undo segment tx slot#-#
#-#virtual circuit status#-#

The session waits for a virtual circuit to return a message type indicated by status.

Wait Time: 30 seconds

p1 circuit# Indicates the virtual circuit# being waited on
p2 status Indicates what the session is waiting for

#-#virtual circuit status#-#
#-#WMON goes to sleep#-#

WMON is the UNIX-specific Wait Monitor, that can be used to reduce the number of system calls related to setting timers for posting or waiting in Oracle. You need to set an initialization parameter that enables the WMON process.

Wait Time: Depends on the next timeout

Parameters: None
#-#WMON goes to sleep#-#
#-#writes stopped by instance recovery or database suspension#-#

The session is blocked until the instance that started Instance Recovery is finished.

Wait Time: 5 seconds
p1 bythread# The rollback segment id that contains the transaction that is being rolled back
p2 ourthread# The current instance thread number
#-#writes stopped by instance recovery or database suspension#-#
#-#selectivity#-#
Basic Selectivity formula:
~~~~~~~~~~~~~~~~~~~~~~~~~~

	        Number of records satisfying a condition
Selectivity =	-----------------------------------------
	              Total Number of records 

By default, column selectivity is based on the high and low values and the number of values in the column with 
an assumption of even distribution of data between these two points. 


ssary of Terms:
~~~~~~~~~~~~~~~~~~

NDV		Number of Distinct Values
Cardinality	Number of rows 
Selectivity	Proportion of a dataset returned by a particular predicate(or
		group of predicates)

In the following illustrations there are 2 tables (T1 & T2) with columns (c1)

Selectivities:
~~~~~~~~~~~~~~
Without histograms 
~~~~~~~~~~~~~~~~~~
c1 = '4076'              1/NDV 
c1 > '4076'              1 - (High - Value / High - Low) 
c1 >= '4076'             1 - (High - Value / High - Low) + 1/NDV
c1 like '4076'           1/NDV

Join selectivity
~~~~~~~~~~~~~~~~

The selectivity of a join is defined as the selectivity of the most selective 
join column adjusted by the proportion of not null values in each join column.


 Sel = 1/max[NDV(t1.c1),NDV(t2.c2)] * 
	 	 	 ( (Card t1 - # t1.c1 NULLs) / Card t1) * 
	 	 	 ( (Card t2 - # t2.c2 NULLs) / Card t2)

Bind Variable selectivity
~~~~~~~~~~~~~~~~~~~~~~~~~

Bind variables present a special case because the optimizer has no idea what the bind variable value is prior 
to query optimization. This does not present a problem with equality predicates since a uniform distribution 
of data is assumed and the selectivity is taken as 1/NDV for the column. However for range predicates it presen
ts a major issue because the optimizer does not know where the range starts or stops. Because of this 
the optimizer has to make some assumptions as follows:

c1 =    :bind1           1/NDV 
c1 >    :bind1           Default of 5%
c1 >=   :bind1           Default of 5%
c1 like :bind1           Default of 25%

Selectivity With Histograms
~~~~~~~~~~~~~~~~~~~~~~~~~~~
Histograms provide additional information about column selectivity for columns whose distribution is non uniform. 
Histograms store information about column data value ranges. Each range is stored in a single row and is often 
called a 'bucket'. There are 2 different methods for storing histograms in Oracle. If there are a small number 
of distinct column values (i.e. less than the number of buckets), the column value and the count of that value 
is stored. If not then a series of endpoints are stored to enable more accurate selectivity to be determined.

The first method allows the accurate figures to be used. However with inexact histograms the terms popular and 
non-popular value are introduced and are used to help determine selectivity. A popular value is a value that
spans multiple endpoints whereas a non-popular value does not. 

Exact histograms
~~~~~~~~~~~~~~~~
c1 = '4706'         count of value '4076' / Total Number of Rows 
c1 > value          count of values > '4076' / Total Number of Rows 

InExact Histograms
~~~~~~~~~~~~~~~~~~
col = pop value         # popular buckets / # buckets 
col = non pop           (Density)
col > value             # buckets > value / # buckets


Rules for combining selectivity
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Let P1 and P2 be 2 distinct predicates of query Q

 P1 AND P2
       S(P1&P2) = S(P1) * S(P2)
 P1 OR P2
       S(P1|P2) = S(P1) + S(P2) -[S(P1) * S(P2)]

Index Selectivity for concatenated indexes
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Starting with 10.2, when a concatenated index, with all its columns having equality predicates, is used 
as an access path, the optimizer uses 1/NDK as the selectivity (where NDK is the number of distinct keys in the index).
In 10.2 adjustments will be made to the selectivity to account for nulls in the index keys. 
#-#selectivity#-#
#-#cardinality#-#
Cardinality is the expected number of rows that will be retrieved from a row source. 
Cardinality is useful in determining nested loop join and sort costs.
#-#cardinality#-#
#-#explain plan#-#
#-#explain#-#
#-#plan#-#

This is what is needed if the explain plan format is wrong

	set linesize 150
	 
	column parent_id_plus_exp   format 999
	column id_plus_exp      format 990
	column plan_plus_exp        format a120
	column other_plus_exp       format a120
	column other_tag_plus_exp   format a29
	column object_node_plus_exp format a14

#-#plan#-#
#-#explain#-#
#-#explain plan#-#
#-#HASH_MATCH_FAILED#-#

HASH_MATCH_FAILED (in v$sql_shared_cursor) covers the "unsafe binds due histograms with cursor_sharing=similar"

Comment from Randolf Geist : 

    Without any statistics and enabled dynamic sampling with 
    CURSOR_SHARING=SIMILAR, one could argument that every distinct literal value 
    passed potentially leads to a different execution plan due to the dynamic 
    sampling performed, therefore this cursor is marked as unsafe to share and 
    you'll get a different child cursor per different literal value passed.

    So CURSOR_SHARING=SIMILAR and dynamic sampling will cause a lot of child 
    cursors, since it's by definition unsafe to share. Note that CURSOR_SHARING 
    similar doesn't mean that you get only a new child cursor if the plans are 
    actually different. You get different child cursors since you *potentially* get 
    different execution plans. It's perfectly valid with CURSOR_SHARING=similar to 
    have dozens of child cursors that share the same plan.

    What you're looking for is (partly) implemented by the Adaptive Cursor Sharing 
    (ACS) introduced in 11g, that attempts to minimize the number of child cursors 
    generated. In fact, with Adaptive Cursor Sharing it's recommended to use 
    CURSOR_SHARING=FORCE instead of SIMILAR to minimize the number of child cursor 
    generated.

    Note however that the ACS doesn't work very well if you have dramatic 
    differences in execution runtime and high aging rate of the SQLs as Kerry 
    Osborne reports here:

    http://kerryosborne.oracle-guy.com/2009/06/oracle-11g-adaptive-cursor-sharing-acs/

    Its current implementation might however work very well if the SQLs stay in the 
    shared pool and you don't suffer from "killer queries" that are using the "wrong" plans.

#-#HASH_MATCH_FAILED#-#
